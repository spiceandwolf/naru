Device cuda
Loading csv... done, took 20.0s
Parsing... done, took 13.7s
Entropy of DMV([Column(Record Type, distribution_size=4), Column(Registration Class, distribution_size=73), Column(State, distribution_size=83), Column(County, distribution_size=63), Column(Body Type, distribution_size=58), Column(Fuel Type, distribution_size=9), Column(Reg Valid Date, distribution_size=3238), Column(Color, distribution_size=227), Column(Scofflaw Indicator, distribution_size=2), Column(Suspension Indicator, distribution_size=2), Column(Revocation Indicator, distribution_size=2)]): 19.5477 bits
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 12620081 entries, 0 to 12620080
Data columns (total 11 columns):
Record Type             object
Registration Class      object
State                   object
County                  object
Body Type               object
Fuel Type               object
Reg Valid Date          datetime64[ns]
Color                   object
Scofflaw Indicator      object
Suspension Indicator    object
Revocation Indicator    object
dtypes: datetime64[ns](1), object(10)
memory usage: 1.0+ GB
None
fixed_ordering None seed 0 natural_ordering True
encoded_bins (output) [4, 32, 32, 32, 32, 9, 32, 32, 2, 2, 2]
encoded_bins (input) [4, 32, 32, 32, 32, 9, 32, 32, 2, 2, 2]
Number of model parameters: 950178 (~= 3.6MB)
MADE(
  (net): Sequential(
    (0): MaskedLinear(in_features=211, out_features=512, bias=True)
    (1): ReLU(inplace)
    (2): MaskedLinear(in_features=512, out_features=256, bias=True)
    (3): ReLU(inplace)
    (4): MaskedLinear(in_features=256, out_features=512, bias=True)
    (5): ReLU(inplace)
    (6): MaskedLinear(in_features=512, out_features=128, bias=True)
    (7): ReLU(inplace)
    (8): MaskedLinear(in_features=128, out_features=1024, bias=True)
    (9): ReLU(inplace)
    (10): MaskedLinear(in_features=1024, out_features=211, bias=True)
  )
  (embeddings): ModuleList(
    (0): None
    (1): Embedding(73, 32)
    (2): Embedding(83, 32)
    (3): Embedding(63, 32)
    (4): Embedding(58, 32)
    (5): None
    (6): Embedding(3238, 32)
    (7): Embedding(227, 32)
    (8): None
    (9): None
    (10): None
  )
  (unk_embeddings): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 1x4 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 1x32 (GPU 0)]
      (2): Parameter containing: [torch.cuda.FloatTensor of size 1x32 (GPU 0)]
      (3): Parameter containing: [torch.cuda.FloatTensor of size 1x32 (GPU 0)]
      (4): Parameter containing: [torch.cuda.FloatTensor of size 1x32 (GPU 0)]
      (5): Parameter containing: [torch.cuda.FloatTensor of size 1x9 (GPU 0)]
      (6): Parameter containing: [torch.cuda.FloatTensor of size 1x32 (GPU 0)]
      (7): Parameter containing: [torch.cuda.FloatTensor of size 1x32 (GPU 0)]
      (8): Parameter containing: [torch.cuda.FloatTensor of size 1x2 (GPU 0)]
      (9): Parameter containing: [torch.cuda.FloatTensor of size 1x2 (GPU 0)]
      (10): Parameter containing: [torch.cuda.FloatTensor of size 1x2 (GPU 0)]
  )
  (direct_io_layer): MaskedLinear(in_features=211, out_features=211, bias=True)
)
Applying InitWeight()
Discretizing table... done, took 5.9s
Epoch 0 Iter 0, train entropy gap 32.5237 bits (loss 52.071, data 19.548) 0.00000 lr
Epoch 0 Iter 200, train entropy gap 32.1274 bits (loss 51.675, data 19.548) 0.00003 lr
Epoch 0 Iter 400, train entropy gap 18.1488 bits (loss 37.697, data 19.548) 0.00005 lr
Epoch 0 Iter 600, train entropy gap 7.9269 bits (loss 27.475, data 19.548) 0.00008 lr
Epoch 0 Iter 800, train entropy gap 5.2912 bits (loss 24.839, data 19.548) 0.00011 lr
Epoch 0 Iter 1000, train entropy gap 4.9719 bits (loss 24.520, data 19.548) 0.00013 lr
Epoch 0 Iter 1200, train entropy gap 4.6305 bits (loss 24.178, data 19.548) 0.00016 lr
Epoch 0 Iter 1400, train entropy gap 4.5432 bits (loss 24.091, data 19.548) 0.00019 lr
Epoch 0 Iter 1600, train entropy gap 4.2047 bits (loss 23.752, data 19.548) 0.00022 lr
Epoch 0 Iter 1800, train entropy gap 3.4761 bits (loss 23.024, data 19.548) 0.00024 lr
Epoch 0 Iter 2000, train entropy gap 3.2807 bits (loss 22.828, data 19.548) 0.00027 lr
Epoch 0 Iter 2200, train entropy gap 2.8593 bits (loss 22.407, data 19.548) 0.00030 lr
Epoch 0 Iter 2400, train entropy gap 3.2762 bits (loss 22.824, data 19.548) 0.00032 lr
Epoch 0 Iter 2600, train entropy gap 3.3385 bits (loss 22.886, data 19.548) 0.00035 lr
Epoch 0 Iter 2800, train entropy gap 2.8123 bits (loss 22.360, data 19.548) 0.00038 lr
Epoch 0 Iter 3000, train entropy gap 2.1824 bits (loss 21.730, data 19.548) 0.00040 lr
Epoch 0 Iter 3200, train entropy gap 2.5555 bits (loss 22.103, data 19.548) 0.00043 lr
Epoch 0 Iter 3400, train entropy gap 1.7890 bits (loss 21.337, data 19.548) 0.00046 lr
Epoch 0 Iter 3600, train entropy gap 2.2401 bits (loss 21.788, data 19.548) 0.00048 lr
Epoch 0 Iter 3800, train entropy gap 2.4892 bits (loss 22.037, data 19.548) 0.00051 lr
Epoch 0 Iter 4000, train entropy gap 1.9124 bits (loss 21.460, data 19.548) 0.00054 lr
Epoch 0 Iter 4200, train entropy gap 1.7210 bits (loss 21.269, data 19.548) 0.00056 lr
Epoch 0 Iter 4400, train entropy gap 1.6145 bits (loss 21.162, data 19.548) 0.00059 lr
Epoch 0 Iter 4600, train entropy gap 1.2436 bits (loss 20.791, data 19.548) 0.00062 lr
Epoch 0 Iter 4800, train entropy gap 2.7460 bits (loss 22.294, data 19.548) 0.00065 lr
Epoch 0 Iter 5000, train entropy gap 1.9230 bits (loss 21.471, data 19.548) 0.00067 lr
Epoch 0 Iter 5200, train entropy gap 1.8577 bits (loss 21.405, data 19.548) 0.00070 lr
Epoch 0 Iter 5400, train entropy gap 1.3654 bits (loss 20.913, data 19.548) 0.00073 lr
Epoch 0 Iter 5600, train entropy gap 1.9220 bits (loss 21.470, data 19.548) 0.00075 lr
Epoch 0 Iter 5800, train entropy gap 1.7601 bits (loss 21.308, data 19.548) 0.00078 lr
Epoch 0 Iter 6000, train entropy gap 1.4508 bits (loss 20.999, data 19.548) 0.00081 lr
epoch 0 train loss 16.8988 nats / 24.3798 bits
time since start: 139.0 secs
Epoch 1 Iter 0, train entropy gap 2.8422 bits (loss 22.390, data 19.548) 0.00083 lr
Epoch 1 Iter 200, train entropy gap 2.0698 bits (loss 21.618, data 19.548) 0.00086 lr
Epoch 1 Iter 400, train entropy gap 1.1865 bits (loss 20.734, data 19.548) 0.00088 lr
Epoch 1 Iter 600, train entropy gap 1.1785 bits (loss 20.726, data 19.548) 0.00091 lr
Epoch 1 Iter 800, train entropy gap 1.9673 bits (loss 21.515, data 19.548) 0.00094 lr
Epoch 1 Iter 1000, train entropy gap 1.8382 bits (loss 21.386, data 19.548) 0.00096 lr
Epoch 1 Iter 1200, train entropy gap 1.6933 bits (loss 21.241, data 19.548) 0.00099 lr
Epoch 1 Iter 1400, train entropy gap 2.5009 bits (loss 22.049, data 19.548) 0.00102 lr
Epoch 1 Iter 1600, train entropy gap 1.9003 bits (loss 21.448, data 19.548) 0.00104 lr
Epoch 1 Iter 1800, train entropy gap 1.5592 bits (loss 21.107, data 19.548) 0.00107 lr
Epoch 1 Iter 2000, train entropy gap 2.1831 bits (loss 21.731, data 19.548) 0.00110 lr
Epoch 1 Iter 2200, train entropy gap 1.0876 bits (loss 20.635, data 19.548) 0.00112 lr
Epoch 1 Iter 2400, train entropy gap 1.6011 bits (loss 21.149, data 19.548) 0.00115 lr
Epoch 1 Iter 2600, train entropy gap 1.0405 bits (loss 20.588, data 19.548) 0.00118 lr
Epoch 1 Iter 2800, train entropy gap 1.2681 bits (loss 20.816, data 19.548) 0.00121 lr
Epoch 1 Iter 3000, train entropy gap 1.4843 bits (loss 21.032, data 19.548) 0.00123 lr
Epoch 1 Iter 3200, train entropy gap 2.2933 bits (loss 21.841, data 19.548) 0.00126 lr
Epoch 1 Iter 3400, train entropy gap 1.4634 bits (loss 21.011, data 19.548) 0.00129 lr
Epoch 1 Iter 3600, train entropy gap 1.6998 bits (loss 21.247, data 19.548) 0.00131 lr
Epoch 1 Iter 3800, train entropy gap 2.4001 bits (loss 21.948, data 19.548) 0.00134 lr
Epoch 1 Iter 4000, train entropy gap 2.5269 bits (loss 22.075, data 19.548) 0.00137 lr
Epoch 1 Iter 4200, train entropy gap 2.5005 bits (loss 22.048, data 19.548) 0.00139 lr
Epoch 1 Iter 4400, train entropy gap 1.7072 bits (loss 21.255, data 19.548) 0.00142 lr
Epoch 1 Iter 4600, train entropy gap 1.3779 bits (loss 20.926, data 19.548) 0.00145 lr
Epoch 1 Iter 4800, train entropy gap 1.5318 bits (loss 21.080, data 19.548) 0.00147 lr
Epoch 1 Iter 5000, train entropy gap 1.2066 bits (loss 20.754, data 19.548) 0.00150 lr
Epoch 1 Iter 5200, train entropy gap 1.5451 bits (loss 21.093, data 19.548) 0.00153 lr
Epoch 1 Iter 5400, train entropy gap 1.6843 bits (loss 21.232, data 19.548) 0.00156 lr
Epoch 1 Iter 5600, train entropy gap 1.3345 bits (loss 20.882, data 19.548) 0.00158 lr
Epoch 1 Iter 5800, train entropy gap 3.0335 bits (loss 22.581, data 19.548) 0.00161 lr
Epoch 1 Iter 6000, train entropy gap 1.9122 bits (loss 21.460, data 19.548) 0.00160 lr
epoch 1 train loss 14.8256 nats / 21.3888 bits
time since start: 279.9 secs
Epoch 2 Iter 0, train entropy gap 1.3965 bits (loss 20.944, data 19.548) 0.00159 lr
Epoch 2 Iter 200, train entropy gap 1.3494 bits (loss 20.897, data 19.548) 0.00158 lr
Epoch 2 Iter 400, train entropy gap 2.2270 bits (loss 21.775, data 19.548) 0.00157 lr
Epoch 2 Iter 600, train entropy gap 2.0939 bits (loss 21.642, data 19.548) 0.00155 lr
Epoch 2 Iter 800, train entropy gap 1.3020 bits (loss 20.850, data 19.548) 0.00154 lr
Epoch 2 Iter 1000, train entropy gap 1.8829 bits (loss 21.431, data 19.548) 0.00153 lr
Epoch 2 Iter 1200, train entropy gap 1.2492 bits (loss 20.797, data 19.548) 0.00152 lr
Epoch 2 Iter 1400, train entropy gap 1.8092 bits (loss 21.357, data 19.548) 0.00151 lr
Epoch 2 Iter 1600, train entropy gap 2.0684 bits (loss 21.616, data 19.548) 0.00150 lr
Epoch 2 Iter 1800, train entropy gap 1.9839 bits (loss 21.532, data 19.548) 0.00149 lr
Epoch 2 Iter 2000, train entropy gap 2.8575 bits (loss 22.405, data 19.548) 0.00148 lr
Epoch 2 Iter 2200, train entropy gap 2.6177 bits (loss 22.165, data 19.548) 0.00147 lr
Epoch 2 Iter 2400, train entropy gap 2.5169 bits (loss 22.065, data 19.548) 0.00146 lr
Epoch 2 Iter 2600, train entropy gap 1.8952 bits (loss 21.443, data 19.548) 0.00145 lr
Epoch 2 Iter 2800, train entropy gap 1.7829 bits (loss 21.331, data 19.548) 0.00144 lr
Epoch 2 Iter 3000, train entropy gap 1.4934 bits (loss 21.041, data 19.548) 0.00143 lr
Epoch 2 Iter 3200, train entropy gap 1.1520 bits (loss 20.700, data 19.548) 0.00142 lr
Epoch 2 Iter 3400, train entropy gap 2.3895 bits (loss 21.937, data 19.548) 0.00141 lr
Epoch 2 Iter 3600, train entropy gap 1.7432 bits (loss 21.291, data 19.548) 0.00140 lr
Epoch 2 Iter 3800, train entropy gap 1.7247 bits (loss 21.272, data 19.548) 0.00139 lr
Epoch 2 Iter 4000, train entropy gap 2.0518 bits (loss 21.600, data 19.548) 0.00138 lr
Epoch 2 Iter 4200, train entropy gap 2.7085 bits (loss 22.256, data 19.548) 0.00138 lr
Epoch 2 Iter 4400, train entropy gap 2.0891 bits (loss 21.637, data 19.548) 0.00137 lr
Epoch 2 Iter 4600, train entropy gap 1.5613 bits (loss 21.109, data 19.548) 0.00136 lr
Epoch 2 Iter 4800, train entropy gap 1.9184 bits (loss 21.466, data 19.548) 0.00135 lr
Epoch 2 Iter 5000, train entropy gap 0.8453 bits (loss 20.393, data 19.548) 0.00134 lr
Epoch 2 Iter 5200, train entropy gap 1.3937 bits (loss 20.941, data 19.548) 0.00134 lr
Epoch 2 Iter 5400, train entropy gap 1.7599 bits (loss 21.308, data 19.548) 0.00133 lr
Epoch 2 Iter 5600, train entropy gap 1.4448 bits (loss 20.993, data 19.548) 0.00132 lr
Epoch 2 Iter 5800, train entropy gap 1.3289 bits (loss 20.877, data 19.548) 0.00131 lr
Epoch 2 Iter 6000, train entropy gap 1.0883 bits (loss 20.636, data 19.548) 0.00131 lr
epoch 2 train loss 14.7855 nats / 21.3310 bits
time since start: 420.6 secs
Epoch 3 Iter 0, train entropy gap 1.8878 bits (loss 21.436, data 19.548) 0.00130 lr
Epoch 3 Iter 200, train entropy gap 1.3460 bits (loss 20.894, data 19.548) 0.00129 lr
Epoch 3 Iter 400, train entropy gap 2.4259 bits (loss 21.974, data 19.548) 0.00129 lr
Epoch 3 Iter 600, train entropy gap 2.1873 bits (loss 21.735, data 19.548) 0.00128 lr
Epoch 3 Iter 800, train entropy gap 2.0085 bits (loss 21.556, data 19.548) 0.00127 lr
Epoch 3 Iter 1000, train entropy gap 2.9434 bits (loss 22.491, data 19.548) 0.00127 lr
Epoch 3 Iter 1200, train entropy gap 1.5315 bits (loss 21.079, data 19.548) 0.00126 lr
Epoch 3 Iter 1400, train entropy gap 1.8509 bits (loss 21.399, data 19.548) 0.00125 lr
Epoch 3 Iter 1600, train entropy gap 1.7403 bits (loss 21.288, data 19.548) 0.00125 lr
Epoch 3 Iter 1800, train entropy gap 1.2801 bits (loss 20.828, data 19.548) 0.00124 lr
Epoch 3 Iter 2000, train entropy gap 1.7520 bits (loss 21.300, data 19.548) 0.00123 lr
Epoch 3 Iter 2200, train entropy gap 2.5652 bits (loss 22.113, data 19.548) 0.00123 lr
Epoch 3 Iter 2400, train entropy gap 2.2153 bits (loss 21.763, data 19.548) 0.00122 lr
Epoch 3 Iter 2600, train entropy gap 1.9693 bits (loss 21.517, data 19.548) 0.00122 lr
Epoch 3 Iter 2800, train entropy gap 1.3853 bits (loss 20.933, data 19.548) 0.00121 lr
Epoch 3 Iter 3000, train entropy gap 0.8646 bits (loss 20.412, data 19.548) 0.00121 lr
Epoch 3 Iter 3200, train entropy gap 1.4551 bits (loss 21.003, data 19.548) 0.00120 lr
Epoch 3 Iter 3400, train entropy gap 1.7939 bits (loss 21.342, data 19.548) 0.00119 lr
Epoch 3 Iter 3600, train entropy gap 2.3951 bits (loss 21.943, data 19.548) 0.00119 lr
Epoch 3 Iter 3800, train entropy gap 3.1505 bits (loss 22.698, data 19.548) 0.00118 lr
Epoch 3 Iter 4000, train entropy gap 2.6238 bits (loss 22.172, data 19.548) 0.00118 lr
Epoch 3 Iter 4200, train entropy gap 1.5999 bits (loss 21.148, data 19.548) 0.00117 lr
Epoch 3 Iter 4400, train entropy gap 1.9152 bits (loss 21.463, data 19.548) 0.00117 lr
Epoch 3 Iter 4600, train entropy gap 2.3610 bits (loss 21.909, data 19.548) 0.00116 lr
Epoch 3 Iter 4800, train entropy gap 3.1052 bits (loss 22.653, data 19.548) 0.00116 lr
Epoch 3 Iter 5000, train entropy gap 1.1980 bits (loss 20.746, data 19.548) 0.00115 lr
Epoch 3 Iter 5200, train entropy gap 1.7798 bits (loss 21.328, data 19.548) 0.00115 lr
Epoch 3 Iter 5400, train entropy gap 1.4382 bits (loss 20.986, data 19.548) 0.00114 lr
Epoch 3 Iter 5600, train entropy gap 1.1241 bits (loss 20.672, data 19.548) 0.00114 lr
Epoch 3 Iter 5800, train entropy gap 1.2696 bits (loss 20.817, data 19.548) 0.00113 lr
Epoch 3 Iter 6000, train entropy gap 0.7175 bits (loss 20.265, data 19.548) 0.00113 lr
epoch 3 train loss 14.7667 nats / 21.3039 bits
time since start: 561.7 secs
Epoch 4 Iter 0, train entropy gap 1.3722 bits (loss 20.920, data 19.548) 0.00113 lr
Epoch 4 Iter 200, train entropy gap 1.0336 bits (loss 20.581, data 19.548) 0.00112 lr
Epoch 4 Iter 400, train entropy gap 3.3077 bits (loss 22.855, data 19.548) 0.00112 lr
Epoch 4 Iter 600, train entropy gap 2.0950 bits (loss 21.643, data 19.548) 0.00111 lr
Epoch 4 Iter 800, train entropy gap 2.7839 bits (loss 22.332, data 19.548) 0.00111 lr
Epoch 4 Iter 1000, train entropy gap 1.8347 bits (loss 21.382, data 19.548) 0.00110 lr
Epoch 4 Iter 1200, train entropy gap 1.6700 bits (loss 21.218, data 19.548) 0.00110 lr
Epoch 4 Iter 1400, train entropy gap 1.8162 bits (loss 21.364, data 19.548) 0.00110 lr
Epoch 4 Iter 1600, train entropy gap 1.4051 bits (loss 20.953, data 19.548) 0.00109 lr
Epoch 4 Iter 1800, train entropy gap 1.2683 bits (loss 20.816, data 19.548) 0.00109 lr
Epoch 4 Iter 2000, train entropy gap 1.3878 bits (loss 20.936, data 19.548) 0.00108 lr
Epoch 4 Iter 2200, train entropy gap 2.3494 bits (loss 21.897, data 19.548) 0.00108 lr
Epoch 4 Iter 2400, train entropy gap 1.5250 bits (loss 21.073, data 19.548) 0.00107 lr
Epoch 4 Iter 2600, train entropy gap 2.1643 bits (loss 21.712, data 19.548) 0.00107 lr
Epoch 4 Iter 2800, train entropy gap 1.4057 bits (loss 20.953, data 19.548) 0.00107 lr
Epoch 4 Iter 3000, train entropy gap 2.2161 bits (loss 21.764, data 19.548) 0.00106 lr
Epoch 4 Iter 3200, train entropy gap 2.8235 bits (loss 22.371, data 19.548) 0.00106 lr
Epoch 4 Iter 3400, train entropy gap 1.2926 bits (loss 20.840, data 19.548) 0.00106 lr
Epoch 4 Iter 3600, train entropy gap 1.2558 bits (loss 20.804, data 19.548) 0.00105 lr
Epoch 4 Iter 3800, train entropy gap 1.2332 bits (loss 20.781, data 19.548) 0.00105 lr
Epoch 4 Iter 4000, train entropy gap 1.8843 bits (loss 21.432, data 19.548) 0.00104 lr
Epoch 4 Iter 4200, train entropy gap 1.9700 bits (loss 21.518, data 19.548) 0.00104 lr
Epoch 4 Iter 4400, train entropy gap 1.8897 bits (loss 21.437, data 19.548) 0.00104 lr
Epoch 4 Iter 4600, train entropy gap 2.6277 bits (loss 22.175, data 19.548) 0.00103 lr
Epoch 4 Iter 4800, train entropy gap 1.3376 bits (loss 20.885, data 19.548) 0.00103 lr
Epoch 4 Iter 5000, train entropy gap 2.3167 bits (loss 21.864, data 19.548) 0.00103 lr
Epoch 4 Iter 5200, train entropy gap 1.3187 bits (loss 20.866, data 19.548) 0.00102 lr
Epoch 4 Iter 5400, train entropy gap 2.1511 bits (loss 21.699, data 19.548) 0.00102 lr
Epoch 4 Iter 5600, train entropy gap 2.6944 bits (loss 22.242, data 19.548) 0.00102 lr
Epoch 4 Iter 5800, train entropy gap 1.0680 bits (loss 20.616, data 19.548) 0.00101 lr
Epoch 4 Iter 6000, train entropy gap 1.1114 bits (loss 20.659, data 19.548) 0.00101 lr
epoch 4 train loss 14.7613 nats / 21.2961 bits
time since start: 703.0 secs
Epoch 5 Iter 0, train entropy gap 1.2410 bits (loss 20.789, data 19.548) 0.00101 lr
Epoch 5 Iter 200, train entropy gap 2.1210 bits (loss 21.669, data 19.548) 0.00100 lr
Epoch 5 Iter 400, train entropy gap 1.7246 bits (loss 21.272, data 19.548) 0.00100 lr
Epoch 5 Iter 600, train entropy gap 2.0643 bits (loss 21.612, data 19.548) 0.00100 lr
Epoch 5 Iter 800, train entropy gap 3.2002 bits (loss 22.748, data 19.548) 0.00099 lr
Epoch 5 Iter 1000, train entropy gap 1.8252 bits (loss 21.373, data 19.548) 0.00099 lr
Epoch 5 Iter 1200, train entropy gap 1.5727 bits (loss 21.120, data 19.548) 0.00099 lr
Epoch 5 Iter 1400, train entropy gap 1.6991 bits (loss 21.247, data 19.548) 0.00098 lr
Epoch 5 Iter 1600, train entropy gap 3.2162 bits (loss 22.764, data 19.548) 0.00098 lr
Epoch 5 Iter 1800, train entropy gap 1.1275 bits (loss 20.675, data 19.548) 0.00098 lr
Epoch 5 Iter 2000, train entropy gap 1.2151 bits (loss 20.763, data 19.548) 0.00098 lr
Epoch 5 Iter 2200, train entropy gap 2.8994 bits (loss 22.447, data 19.548) 0.00097 lr
Epoch 5 Iter 2400, train entropy gap 1.8337 bits (loss 21.381, data 19.548) 0.00097 lr
Epoch 5 Iter 2600, train entropy gap 2.2862 bits (loss 21.834, data 19.548) 0.00097 lr
Epoch 5 Iter 2800, train entropy gap 1.8295 bits (loss 21.377, data 19.548) 0.00096 lr
Epoch 5 Iter 3000, train entropy gap 1.7714 bits (loss 21.319, data 19.548) 0.00096 lr
Epoch 5 Iter 3200, train entropy gap 1.3367 bits (loss 20.884, data 19.548) 0.00096 lr
Epoch 5 Iter 3400, train entropy gap 1.5646 bits (loss 21.112, data 19.548) 0.00096 lr
Epoch 5 Iter 3600, train entropy gap 1.8782 bits (loss 21.426, data 19.548) 0.00095 lr
Epoch 5 Iter 3800, train entropy gap 1.9264 bits (loss 21.474, data 19.548) 0.00095 lr
Epoch 5 Iter 4000, train entropy gap 1.4643 bits (loss 21.012, data 19.548) 0.00095 lr
Epoch 5 Iter 4200, train entropy gap 1.7396 bits (loss 21.287, data 19.548) 0.00094 lr
Epoch 5 Iter 4400, train entropy gap 1.5084 bits (loss 21.056, data 19.548) 0.00094 lr
Epoch 5 Iter 4600, train entropy gap 2.3021 bits (loss 21.850, data 19.548) 0.00094 lr
Epoch 5 Iter 4800, train entropy gap 2.4104 bits (loss 21.958, data 19.548) 0.00094 lr
Epoch 5 Iter 5000, train entropy gap 2.3600 bits (loss 21.908, data 19.548) 0.00093 lr
Epoch 5 Iter 5200, train entropy gap 0.9808 bits (loss 20.529, data 19.548) 0.00093 lr
Epoch 5 Iter 5400, train entropy gap 2.1986 bits (loss 21.746, data 19.548) 0.00093 lr
Epoch 5 Iter 5600, train entropy gap 0.9142 bits (loss 20.462, data 19.548) 0.00093 lr
Epoch 5 Iter 5800, train entropy gap 1.9897 bits (loss 21.537, data 19.548) 0.00092 lr
Epoch 5 Iter 6000, train entropy gap 1.9236 bits (loss 21.471, data 19.548) 0.00092 lr
epoch 5 train loss 14.7567 nats / 21.2894 bits
time since start: 844.4 secs
Epoch 6 Iter 0, train entropy gap 2.6879 bits (loss 22.236, data 19.548) 0.00092 lr
Epoch 6 Iter 200, train entropy gap 2.3144 bits (loss 21.862, data 19.548) 0.00092 lr
Epoch 6 Iter 400, train entropy gap 1.1809 bits (loss 20.729, data 19.548) 0.00091 lr
Epoch 6 Iter 600, train entropy gap 1.2496 bits (loss 20.797, data 19.548) 0.00091 lr
Epoch 6 Iter 800, train entropy gap 2.5185 bits (loss 22.066, data 19.548) 0.00091 lr
Epoch 6 Iter 1000, train entropy gap 3.1750 bits (loss 22.723, data 19.548) 0.00091 lr
Epoch 6 Iter 1200, train entropy gap 1.7193 bits (loss 21.267, data 19.548) 0.00090 lr
Epoch 6 Iter 1400, train entropy gap 1.5350 bits (loss 21.083, data 19.548) 0.00090 lr
Epoch 6 Iter 1600, train entropy gap 1.9939 bits (loss 21.542, data 19.548) 0.00090 lr
Epoch 6 Iter 1800, train entropy gap 1.6056 bits (loss 21.153, data 19.548) 0.00090 lr
Epoch 6 Iter 2000, train entropy gap 2.5169 bits (loss 22.065, data 19.548) 0.00090 lr
Epoch 6 Iter 2200, train entropy gap 2.4221 bits (loss 21.970, data 19.548) 0.00089 lr
Epoch 6 Iter 2400, train entropy gap 1.7553 bits (loss 21.303, data 19.548) 0.00089 lr
Epoch 6 Iter 2600, train entropy gap 1.2818 bits (loss 20.830, data 19.548) 0.00089 lr
Epoch 6 Iter 2800, train entropy gap 2.1803 bits (loss 21.728, data 19.548) 0.00089 lr
Epoch 6 Iter 3000, train entropy gap 1.7905 bits (loss 21.338, data 19.548) 0.00088 lr
Epoch 6 Iter 3200, train entropy gap 2.7360 bits (loss 22.284, data 19.548) 0.00088 lr
Epoch 6 Iter 3400, train entropy gap 1.4322 bits (loss 20.980, data 19.548) 0.00088 lr
Epoch 6 Iter 3600, train entropy gap 1.7030 bits (loss 21.251, data 19.548) 0.00088 lr
Epoch 6 Iter 3800, train entropy gap 2.1349 bits (loss 21.683, data 19.548) 0.00088 lr
Epoch 6 Iter 4000, train entropy gap 2.1098 bits (loss 21.657, data 19.548) 0.00087 lr
Epoch 6 Iter 4200, train entropy gap 1.6768 bits (loss 21.225, data 19.548) 0.00087 lr
Epoch 6 Iter 4400, train entropy gap 0.9497 bits (loss 20.497, data 19.548) 0.00087 lr
Epoch 6 Iter 4600, train entropy gap 0.9428 bits (loss 20.491, data 19.548) 0.00087 lr
Epoch 6 Iter 4800, train entropy gap 1.5647 bits (loss 21.112, data 19.548) 0.00086 lr
Epoch 6 Iter 5000, train entropy gap 2.3532 bits (loss 21.901, data 19.548) 0.00086 lr
Epoch 6 Iter 5200, train entropy gap 1.9126 bits (loss 21.460, data 19.548) 0.00086 lr
Epoch 6 Iter 5400, train entropy gap 2.3993 bits (loss 21.947, data 19.548) 0.00086 lr
Epoch 6 Iter 5600, train entropy gap 1.5832 bits (loss 21.131, data 19.548) 0.00086 lr
Epoch 6 Iter 5800, train entropy gap 1.5665 bits (loss 21.114, data 19.548) 0.00085 lr
Epoch 6 Iter 6000, train entropy gap 1.7146 bits (loss 21.262, data 19.548) 0.00085 lr
epoch 6 train loss 14.7598 nats / 21.2938 bits
time since start: 985.1 secs
Epoch 7 Iter 0, train entropy gap 1.9356 bits (loss 21.483, data 19.548) 0.00085 lr
Epoch 7 Iter 200, train entropy gap 2.3312 bits (loss 21.879, data 19.548) 0.00085 lr
Epoch 7 Iter 400, train entropy gap 2.0763 bits (loss 21.624, data 19.548) 0.00085 lr
Epoch 7 Iter 600, train entropy gap 0.8315 bits (loss 20.379, data 19.548) 0.00085 lr
Epoch 7 Iter 800, train entropy gap 1.2133 bits (loss 20.761, data 19.548) 0.00084 lr
Epoch 7 Iter 1000, train entropy gap 1.3667 bits (loss 20.914, data 19.548) 0.00084 lr
Epoch 7 Iter 1200, train entropy gap 1.4623 bits (loss 21.010, data 19.548) 0.00084 lr
Epoch 7 Iter 1400, train entropy gap 2.0394 bits (loss 21.587, data 19.548) 0.00084 lr
Epoch 7 Iter 1600, train entropy gap 1.2722 bits (loss 20.820, data 19.548) 0.00084 lr
Epoch 7 Iter 1800, train entropy gap 1.5301 bits (loss 21.078, data 19.548) 0.00083 lr
Epoch 7 Iter 2000, train entropy gap 1.4182 bits (loss 20.966, data 19.548) 0.00083 lr
Epoch 7 Iter 2200, train entropy gap 2.5995 bits (loss 22.147, data 19.548) 0.00083 lr
Epoch 7 Iter 2400, train entropy gap 2.5534 bits (loss 22.101, data 19.548) 0.00083 lr
Epoch 7 Iter 2600, train entropy gap 0.9240 bits (loss 20.472, data 19.548) 0.00083 lr
Epoch 7 Iter 2800, train entropy gap 1.5868 bits (loss 21.135, data 19.548) 0.00082 lr
Epoch 7 Iter 3000, train entropy gap 0.8097 bits (loss 20.357, data 19.548) 0.00082 lr
Epoch 7 Iter 3200, train entropy gap 2.4564 bits (loss 22.004, data 19.548) 0.00082 lr
Epoch 7 Iter 3400, train entropy gap 1.5635 bits (loss 21.111, data 19.548) 0.00082 lr
Epoch 7 Iter 3600, train entropy gap 1.0369 bits (loss 20.585, data 19.548) 0.00082 lr
Epoch 7 Iter 3800, train entropy gap 2.8418 bits (loss 22.390, data 19.548) 0.00082 lr
Epoch 7 Iter 4000, train entropy gap 1.9269 bits (loss 21.475, data 19.548) 0.00081 lr
Epoch 7 Iter 4200, train entropy gap 1.9547 bits (loss 21.502, data 19.548) 0.00081 lr
Epoch 7 Iter 4400, train entropy gap 1.8401 bits (loss 21.388, data 19.548) 0.00081 lr
Epoch 7 Iter 4600, train entropy gap 1.8527 bits (loss 21.400, data 19.548) 0.00081 lr
Epoch 7 Iter 4800, train entropy gap 2.4033 bits (loss 21.951, data 19.548) 0.00081 lr
Epoch 7 Iter 5000, train entropy gap 1.1069 bits (loss 20.655, data 19.548) 0.00081 lr
Epoch 7 Iter 5200, train entropy gap 2.5721 bits (loss 22.120, data 19.548) 0.00080 lr
Epoch 7 Iter 5400, train entropy gap 1.7232 bits (loss 21.271, data 19.548) 0.00080 lr
Epoch 7 Iter 5600, train entropy gap 1.8882 bits (loss 21.436, data 19.548) 0.00080 lr
Epoch 7 Iter 5800, train entropy gap 1.2215 bits (loss 20.769, data 19.548) 0.00080 lr
Epoch 7 Iter 6000, train entropy gap 2.0329 bits (loss 21.581, data 19.548) 0.00080 lr
epoch 7 train loss 14.7494 nats / 21.2789 bits
time since start: 1125.8 secs
Epoch 8 Iter 0, train entropy gap 0.9109 bits (loss 20.459, data 19.548) 0.00080 lr
Epoch 8 Iter 200, train entropy gap 1.2811 bits (loss 20.829, data 19.548) 0.00079 lr
Epoch 8 Iter 400, train entropy gap 2.3792 bits (loss 21.927, data 19.548) 0.00079 lr
Epoch 8 Iter 600, train entropy gap 0.8264 bits (loss 20.374, data 19.548) 0.00079 lr
Epoch 8 Iter 800, train entropy gap 2.0763 bits (loss 21.624, data 19.548) 0.00079 lr
Epoch 8 Iter 1000, train entropy gap 1.0735 bits (loss 20.621, data 19.548) 0.00079 lr
Epoch 8 Iter 1200, train entropy gap 3.2475 bits (loss 22.795, data 19.548) 0.00079 lr
Epoch 8 Iter 1400, train entropy gap 1.4796 bits (loss 21.027, data 19.548) 0.00079 lr
Epoch 8 Iter 1600, train entropy gap 1.7684 bits (loss 21.316, data 19.548) 0.00078 lr
Epoch 8 Iter 1800, train entropy gap 1.5914 bits (loss 21.139, data 19.548) 0.00078 lr
Epoch 8 Iter 2000, train entropy gap 1.7150 bits (loss 21.263, data 19.548) 0.00078 lr
Epoch 8 Iter 2200, train entropy gap 1.1731 bits (loss 20.721, data 19.548) 0.00078 lr
Epoch 8 Iter 2400, train entropy gap 1.2774 bits (loss 20.825, data 19.548) 0.00078 lr
Epoch 8 Iter 2600, train entropy gap 1.0055 bits (loss 20.553, data 19.548) 0.00078 lr
Epoch 8 Iter 2800, train entropy gap 1.7437 bits (loss 21.291, data 19.548) 0.00077 lr
Epoch 8 Iter 3000, train entropy gap 2.1871 bits (loss 21.735, data 19.548) 0.00077 lr
Epoch 8 Iter 3200, train entropy gap 1.9148 bits (loss 21.462, data 19.548) 0.00077 lr
Epoch 8 Iter 3400, train entropy gap 2.2214 bits (loss 21.769, data 19.548) 0.00077 lr
Epoch 8 Iter 3600, train entropy gap 1.7526 bits (loss 21.300, data 19.548) 0.00077 lr
Epoch 8 Iter 3800, train entropy gap 1.8790 bits (loss 21.427, data 19.548) 0.00077 lr
Epoch 8 Iter 4000, train entropy gap 1.2229 bits (loss 20.771, data 19.548) 0.00077 lr
Epoch 8 Iter 4200, train entropy gap 1.6676 bits (loss 21.215, data 19.548) 0.00076 lr
Epoch 8 Iter 4400, train entropy gap 2.4154 bits (loss 21.963, data 19.548) 0.00076 lr
Epoch 8 Iter 4600, train entropy gap 1.3285 bits (loss 20.876, data 19.548) 0.00076 lr
Epoch 8 Iter 4800, train entropy gap 1.4972 bits (loss 21.045, data 19.548) 0.00076 lr
Epoch 8 Iter 5000, train entropy gap 1.5315 bits (loss 21.079, data 19.548) 0.00076 lr
Epoch 8 Iter 5200, train entropy gap 1.4263 bits (loss 20.974, data 19.548) 0.00076 lr
Epoch 8 Iter 5400, train entropy gap 2.1642 bits (loss 21.712, data 19.548) 0.00076 lr
Epoch 8 Iter 5600, train entropy gap 1.8512 bits (loss 21.399, data 19.548) 0.00075 lr
Epoch 8 Iter 5800, train entropy gap 1.9420 bits (loss 21.490, data 19.548) 0.00075 lr
Epoch 8 Iter 6000, train entropy gap 2.0102 bits (loss 21.558, data 19.548) 0.00075 lr
epoch 8 train loss 14.7473 nats / 21.2759 bits
time since start: 1267.1 secs
Epoch 9 Iter 0, train entropy gap 2.5253 bits (loss 22.073, data 19.548) 0.00075 lr
Epoch 9 Iter 200, train entropy gap 1.4063 bits (loss 20.954, data 19.548) 0.00075 lr
Epoch 9 Iter 400, train entropy gap 1.6368 bits (loss 21.185, data 19.548) 0.00075 lr
Epoch 9 Iter 600, train entropy gap 2.1449 bits (loss 21.693, data 19.548) 0.00075 lr
Epoch 9 Iter 800, train entropy gap 1.0344 bits (loss 20.582, data 19.548) 0.00075 lr
Epoch 9 Iter 1000, train entropy gap 1.3276 bits (loss 20.875, data 19.548) 0.00074 lr
Epoch 9 Iter 1200, train entropy gap 0.8002 bits (loss 20.348, data 19.548) 0.00074 lr
Epoch 9 Iter 1400, train entropy gap 2.3446 bits (loss 21.892, data 19.548) 0.00074 lr
Epoch 9 Iter 1600, train entropy gap 1.3589 bits (loss 20.907, data 19.548) 0.00074 lr
Epoch 9 Iter 1800, train entropy gap 1.2802 bits (loss 20.828, data 19.548) 0.00074 lr
Epoch 9 Iter 2000, train entropy gap 1.9206 bits (loss 21.468, data 19.548) 0.00074 lr
Epoch 9 Iter 2200, train entropy gap 1.4793 bits (loss 21.027, data 19.548) 0.00074 lr
Epoch 9 Iter 2400, train entropy gap 1.4023 bits (loss 20.950, data 19.548) 0.00073 lr
Epoch 9 Iter 2600, train entropy gap 1.6312 bits (loss 21.179, data 19.548) 0.00073 lr
Epoch 9 Iter 2800, train entropy gap 1.7089 bits (loss 21.257, data 19.548) 0.00073 lr
Epoch 9 Iter 3000, train entropy gap 1.9577 bits (loss 21.505, data 19.548) 0.00073 lr
Epoch 9 Iter 3200, train entropy gap 2.3710 bits (loss 21.919, data 19.548) 0.00073 lr
Epoch 9 Iter 3400, train entropy gap 1.2385 bits (loss 20.786, data 19.548) 0.00073 lr
Epoch 9 Iter 3600, train entropy gap 2.2911 bits (loss 21.839, data 19.548) 0.00073 lr
Epoch 9 Iter 3800, train entropy gap 1.5865 bits (loss 21.134, data 19.548) 0.00073 lr
Epoch 9 Iter 4000, train entropy gap 1.7424 bits (loss 21.290, data 19.548) 0.00072 lr
Epoch 9 Iter 4200, train entropy gap 2.3065 bits (loss 21.854, data 19.548) 0.00072 lr
Epoch 9 Iter 4400, train entropy gap 2.0980 bits (loss 21.646, data 19.548) 0.00072 lr
Epoch 9 Iter 4600, train entropy gap 3.0498 bits (loss 22.598, data 19.548) 0.00072 lr
Epoch 9 Iter 4800, train entropy gap 1.4507 bits (loss 20.998, data 19.548) 0.00072 lr
Epoch 9 Iter 5000, train entropy gap 2.0205 bits (loss 21.568, data 19.548) 0.00072 lr
Epoch 9 Iter 5200, train entropy gap 1.4382 bits (loss 20.986, data 19.548) 0.00072 lr
Epoch 9 Iter 5400, train entropy gap 2.3178 bits (loss 21.865, data 19.548) 0.00072 lr
Epoch 9 Iter 5600, train entropy gap 2.0293 bits (loss 21.577, data 19.548) 0.00072 lr
Epoch 9 Iter 5800, train entropy gap 1.0116 bits (loss 20.559, data 19.548) 0.00071 lr
Epoch 9 Iter 6000, train entropy gap 1.2095 bits (loss 20.757, data 19.548) 0.00071 lr
epoch 9 train loss 14.7484 nats / 21.2774 bits
time since start: 1408.2 secs
Epoch 10 Iter 0, train entropy gap 1.7361 bits (loss 21.284, data 19.548) 0.00071 lr
Epoch 10 Iter 200, train entropy gap 1.3849 bits (loss 20.933, data 19.548) 0.00071 lr
Epoch 10 Iter 400, train entropy gap 1.5718 bits (loss 21.120, data 19.548) 0.00071 lr
Epoch 10 Iter 600, train entropy gap 1.5242 bits (loss 21.072, data 19.548) 0.00071 lr
Epoch 10 Iter 800, train entropy gap 2.7518 bits (loss 22.300, data 19.548) 0.00071 lr
Epoch 10 Iter 1000, train entropy gap 1.6385 bits (loss 21.186, data 19.548) 0.00071 lr
Epoch 10 Iter 1200, train entropy gap 1.4564 bits (loss 21.004, data 19.548) 0.00071 lr
Epoch 10 Iter 1400, train entropy gap 1.3631 bits (loss 20.911, data 19.548) 0.00070 lr
Epoch 10 Iter 1600, train entropy gap 2.2595 bits (loss 21.807, data 19.548) 0.00070 lr
Epoch 10 Iter 1800, train entropy gap 2.1859 bits (loss 21.734, data 19.548) 0.00070 lr
Epoch 10 Iter 2000, train entropy gap 2.0810 bits (loss 21.629, data 19.548) 0.00070 lr
Epoch 10 Iter 2200, train entropy gap 1.7614 bits (loss 21.309, data 19.548) 0.00070 lr
Epoch 10 Iter 2400, train entropy gap 1.0930 bits (loss 20.641, data 19.548) 0.00070 lr
Epoch 10 Iter 2600, train entropy gap 2.0591 bits (loss 21.607, data 19.548) 0.00070 lr
Epoch 10 Iter 2800, train entropy gap 1.6012 bits (loss 21.149, data 19.548) 0.00070 lr
Epoch 10 Iter 3000, train entropy gap 0.8994 bits (loss 20.447, data 19.548) 0.00070 lr
Epoch 10 Iter 3200, train entropy gap 2.6867 bits (loss 22.234, data 19.548) 0.00069 lr
Epoch 10 Iter 3400, train entropy gap 2.2593 bits (loss 21.807, data 19.548) 0.00069 lr
Epoch 10 Iter 3600, train entropy gap 0.8612 bits (loss 20.409, data 19.548) 0.00069 lr
Epoch 10 Iter 3800, train entropy gap 1.2661 bits (loss 20.814, data 19.548) 0.00069 lr
Epoch 10 Iter 4000, train entropy gap 1.4108 bits (loss 20.959, data 19.548) 0.00069 lr
Epoch 10 Iter 4200, train entropy gap 1.4208 bits (loss 20.969, data 19.548) 0.00069 lr
Epoch 10 Iter 4400, train entropy gap 2.0402 bits (loss 21.588, data 19.548) 0.00069 lr
Epoch 10 Iter 4600, train entropy gap 2.2393 bits (loss 21.787, data 19.548) 0.00069 lr
Epoch 10 Iter 4800, train entropy gap 1.7749 bits (loss 21.323, data 19.548) 0.00069 lr
Epoch 10 Iter 5000, train entropy gap 1.4765 bits (loss 21.024, data 19.548) 0.00068 lr
Epoch 10 Iter 5200, train entropy gap 1.5724 bits (loss 21.120, data 19.548) 0.00068 lr
Epoch 10 Iter 5400, train entropy gap 1.0713 bits (loss 20.619, data 19.548) 0.00068 lr
Epoch 10 Iter 5600, train entropy gap 0.9298 bits (loss 20.478, data 19.548) 0.00068 lr
Epoch 10 Iter 5800, train entropy gap 2.2361 bits (loss 21.784, data 19.548) 0.00068 lr
Epoch 10 Iter 6000, train entropy gap 1.0369 bits (loss 20.585, data 19.548) 0.00068 lr
epoch 10 train loss 14.7401 nats / 21.2655 bits
time since start: 1548.8 secs
Epoch 11 Iter 0, train entropy gap 1.7052 bits (loss 21.253, data 19.548) 0.00068 lr
Epoch 11 Iter 200, train entropy gap 1.3486 bits (loss 20.896, data 19.548) 0.00068 lr
Epoch 11 Iter 400, train entropy gap 0.8832 bits (loss 20.431, data 19.548) 0.00068 lr
Epoch 11 Iter 600, train entropy gap 1.3531 bits (loss 20.901, data 19.548) 0.00068 lr
Epoch 11 Iter 800, train entropy gap 2.0772 bits (loss 21.625, data 19.548) 0.00067 lr
Epoch 11 Iter 1000, train entropy gap 1.9805 bits (loss 21.528, data 19.548) 0.00067 lr
Epoch 11 Iter 1200, train entropy gap 1.2125 bits (loss 20.760, data 19.548) 0.00067 lr
Epoch 11 Iter 1400, train entropy gap 2.2964 bits (loss 21.844, data 19.548) 0.00067 lr
Epoch 11 Iter 1600, train entropy gap 2.1910 bits (loss 21.739, data 19.548) 0.00067 lr
Epoch 11 Iter 1800, train entropy gap 1.5327 bits (loss 21.080, data 19.548) 0.00067 lr
Epoch 11 Iter 2000, train entropy gap 2.2827 bits (loss 21.830, data 19.548) 0.00067 lr
Epoch 11 Iter 2200, train entropy gap 1.9865 bits (loss 21.534, data 19.548) 0.00067 lr
Epoch 11 Iter 2400, train entropy gap 2.8675 bits (loss 22.415, data 19.548) 0.00067 lr
Epoch 11 Iter 2600, train entropy gap 1.0660 bits (loss 20.614, data 19.548) 0.00067 lr
Epoch 11 Iter 2800, train entropy gap 2.1736 bits (loss 21.721, data 19.548) 0.00067 lr
Epoch 11 Iter 3000, train entropy gap 2.2978 bits (loss 21.846, data 19.548) 0.00066 lr
Epoch 11 Iter 3200, train entropy gap 1.1413 bits (loss 20.689, data 19.548) 0.00066 lr
Epoch 11 Iter 3400, train entropy gap 1.2451 bits (loss 20.793, data 19.548) 0.00066 lr
Epoch 11 Iter 3600, train entropy gap 1.7401 bits (loss 21.288, data 19.548) 0.00066 lr
Epoch 11 Iter 3800, train entropy gap 1.2150 bits (loss 20.763, data 19.548) 0.00066 lr
Epoch 11 Iter 4000, train entropy gap 1.4887 bits (loss 21.036, data 19.548) 0.00066 lr
Epoch 11 Iter 4200, train entropy gap 2.2572 bits (loss 21.805, data 19.548) 0.00066 lr
Epoch 11 Iter 4400, train entropy gap 1.6856 bits (loss 21.233, data 19.548) 0.00066 lr
Epoch 11 Iter 4600, train entropy gap 1.2063 bits (loss 20.754, data 19.548) 0.00066 lr
Epoch 11 Iter 4800, train entropy gap 0.9603 bits (loss 20.508, data 19.548) 0.00066 lr
Epoch 11 Iter 5000, train entropy gap 1.7092 bits (loss 21.257, data 19.548) 0.00066 lr
Epoch 11 Iter 5200, train entropy gap 0.9672 bits (loss 20.515, data 19.548) 0.00065 lr
Epoch 11 Iter 5400, train entropy gap 1.2517 bits (loss 20.799, data 19.548) 0.00065 lr
Epoch 11 Iter 5600, train entropy gap 1.8727 bits (loss 21.420, data 19.548) 0.00065 lr
Epoch 11 Iter 5800, train entropy gap 1.1055 bits (loss 20.653, data 19.548) 0.00065 lr
Epoch 11 Iter 6000, train entropy gap 1.8663 bits (loss 21.414, data 19.548) 0.00065 lr
epoch 11 train loss 14.7415 nats / 21.2675 bits
time since start: 1689.7 secs
Epoch 12 Iter 0, train entropy gap 1.8891 bits (loss 21.437, data 19.548) 0.00065 lr
Epoch 12 Iter 200, train entropy gap 1.2790 bits (loss 20.827, data 19.548) 0.00065 lr
Epoch 12 Iter 400, train entropy gap 1.3335 bits (loss 20.881, data 19.548) 0.00065 lr
Epoch 12 Iter 600, train entropy gap 1.4127 bits (loss 20.960, data 19.548) 0.00065 lr
Epoch 12 Iter 800, train entropy gap 2.2783 bits (loss 21.826, data 19.548) 0.00065 lr
Epoch 12 Iter 1000, train entropy gap 1.9259 bits (loss 21.474, data 19.548) 0.00065 lr
Epoch 12 Iter 1200, train entropy gap 1.5141 bits (loss 21.062, data 19.548) 0.00064 lr
Epoch 12 Iter 1400, train entropy gap 1.2828 bits (loss 20.831, data 19.548) 0.00064 lr
Epoch 12 Iter 1600, train entropy gap 2.0437 bits (loss 21.591, data 19.548) 0.00064 lr
Epoch 12 Iter 1800, train entropy gap 1.9519 bits (loss 21.500, data 19.548) 0.00064 lr
Epoch 12 Iter 2000, train entropy gap 1.1162 bits (loss 20.664, data 19.548) 0.00064 lr
Epoch 12 Iter 2200, train entropy gap 1.6729 bits (loss 21.221, data 19.548) 0.00064 lr
Epoch 12 Iter 2400, train entropy gap 2.7160 bits (loss 22.264, data 19.548) 0.00064 lr
Epoch 12 Iter 2600, train entropy gap 1.7941 bits (loss 21.342, data 19.548) 0.00064 lr
Epoch 12 Iter 2800, train entropy gap 1.7511 bits (loss 21.299, data 19.548) 0.00064 lr
Epoch 12 Iter 3000, train entropy gap 1.1261 bits (loss 20.674, data 19.548) 0.00064 lr
Epoch 12 Iter 3200, train entropy gap 1.1201 bits (loss 20.668, data 19.548) 0.00064 lr
Epoch 12 Iter 3400, train entropy gap 2.7193 bits (loss 22.267, data 19.548) 0.00064 lr
Epoch 12 Iter 3600, train entropy gap 1.7954 bits (loss 21.343, data 19.548) 0.00063 lr
Epoch 12 Iter 3800, train entropy gap 1.8072 bits (loss 21.355, data 19.548) 0.00063 lr
Epoch 12 Iter 4000, train entropy gap 1.3187 bits (loss 20.866, data 19.548) 0.00063 lr
Epoch 12 Iter 4200, train entropy gap 1.6719 bits (loss 21.220, data 19.548) 0.00063 lr
Epoch 12 Iter 4400, train entropy gap 0.9751 bits (loss 20.523, data 19.548) 0.00063 lr
Epoch 12 Iter 4600, train entropy gap 2.2292 bits (loss 21.777, data 19.548) 0.00063 lr
Epoch 12 Iter 4800, train entropy gap 1.6351 bits (loss 21.183, data 19.548) 0.00063 lr
Epoch 12 Iter 5000, train entropy gap 1.6654 bits (loss 21.213, data 19.548) 0.00063 lr
Epoch 12 Iter 5200, train entropy gap 1.7849 bits (loss 21.333, data 19.548) 0.00063 lr
Epoch 12 Iter 5400, train entropy gap 0.9244 bits (loss 20.472, data 19.548) 0.00063 lr
Epoch 12 Iter 5600, train entropy gap 1.6147 bits (loss 21.162, data 19.548) 0.00063 lr
Epoch 12 Iter 5800, train entropy gap 2.0299 bits (loss 21.578, data 19.548) 0.00063 lr
Epoch 12 Iter 6000, train entropy gap 2.1618 bits (loss 21.710, data 19.548) 0.00063 lr
epoch 12 train loss 14.7464 nats / 21.2745 bits
time since start: 1830.9 secs
Epoch 13 Iter 0, train entropy gap 2.3246 bits (loss 21.872, data 19.548) 0.00062 lr
Epoch 13 Iter 200, train entropy gap 2.1287 bits (loss 21.676, data 19.548) 0.00062 lr
Epoch 13 Iter 400, train entropy gap 0.9454 bits (loss 20.493, data 19.548) 0.00062 lr
Epoch 13 Iter 600, train entropy gap 0.9161 bits (loss 20.464, data 19.548) 0.00062 lr
Epoch 13 Iter 800, train entropy gap 1.5251 bits (loss 21.073, data 19.548) 0.00062 lr
Epoch 13 Iter 1000, train entropy gap 1.6577 bits (loss 21.205, data 19.548) 0.00062 lr
Epoch 13 Iter 1200, train entropy gap 2.5563 bits (loss 22.104, data 19.548) 0.00062 lr
Epoch 13 Iter 1400, train entropy gap 1.8045 bits (loss 21.352, data 19.548) 0.00062 lr
Epoch 13 Iter 1600, train entropy gap 1.5667 bits (loss 21.114, data 19.548) 0.00062 lr
Epoch 13 Iter 1800, train entropy gap 1.4515 bits (loss 20.999, data 19.548) 0.00062 lr
Epoch 13 Iter 2000, train entropy gap 1.4050 bits (loss 20.953, data 19.548) 0.00062 lr
Epoch 13 Iter 2200, train entropy gap 1.6147 bits (loss 21.162, data 19.548) 0.00062 lr
Epoch 13 Iter 2400, train entropy gap 1.7701 bits (loss 21.318, data 19.548) 0.00062 lr
Epoch 13 Iter 2600, train entropy gap 2.0928 bits (loss 21.641, data 19.548) 0.00061 lr
Epoch 13 Iter 2800, train entropy gap 0.9217 bits (loss 20.469, data 19.548) 0.00061 lr
Epoch 13 Iter 3000, train entropy gap 1.4925 bits (loss 21.040, data 19.548) 0.00061 lr
Epoch 13 Iter 3200, train entropy gap 2.6786 bits (loss 22.226, data 19.548) 0.00061 lr
Epoch 13 Iter 3400, train entropy gap 1.8522 bits (loss 21.400, data 19.548) 0.00061 lr
Epoch 13 Iter 3600, train entropy gap 1.7612 bits (loss 21.309, data 19.548) 0.00061 lr
Epoch 13 Iter 3800, train entropy gap 1.5780 bits (loss 21.126, data 19.548) 0.00061 lr
Epoch 13 Iter 4000, train entropy gap 1.9214 bits (loss 21.469, data 19.548) 0.00061 lr
Epoch 13 Iter 4200, train entropy gap 1.2906 bits (loss 20.838, data 19.548) 0.00061 lr
Epoch 13 Iter 4400, train entropy gap 1.9453 bits (loss 21.493, data 19.548) 0.00061 lr
Epoch 13 Iter 4600, train entropy gap 1.6443 bits (loss 21.192, data 19.548) 0.00061 lr
Epoch 13 Iter 4800, train entropy gap 1.4036 bits (loss 20.951, data 19.548) 0.00061 lr
Epoch 13 Iter 5000, train entropy gap 2.1926 bits (loss 21.740, data 19.548) 0.00061 lr
Epoch 13 Iter 5200, train entropy gap 0.9579 bits (loss 20.506, data 19.548) 0.00061 lr
Epoch 13 Iter 5400, train entropy gap 2.2189 bits (loss 21.767, data 19.548) 0.00060 lr
Epoch 13 Iter 5600, train entropy gap 1.6655 bits (loss 21.213, data 19.548) 0.00060 lr
Epoch 13 Iter 5800, train entropy gap 1.3140 bits (loss 20.862, data 19.548) 0.00060 lr
Epoch 13 Iter 6000, train entropy gap 0.8799 bits (loss 20.428, data 19.548) 0.00060 lr
epoch 13 train loss 14.7469 nats / 21.2753 bits
time since start: 1971.9 secs
Epoch 14 Iter 0, train entropy gap 1.4657 bits (loss 21.013, data 19.548) 0.00060 lr
Epoch 14 Iter 200, train entropy gap 1.1948 bits (loss 20.742, data 19.548) 0.00060 lr
Epoch 14 Iter 400, train entropy gap 1.2662 bits (loss 20.814, data 19.548) 0.00060 lr
Epoch 14 Iter 600, train entropy gap 1.5907 bits (loss 21.138, data 19.548) 0.00060 lr
Epoch 14 Iter 800, train entropy gap 1.1545 bits (loss 20.702, data 19.548) 0.00060 lr
Epoch 14 Iter 1000, train entropy gap 1.4783 bits (loss 21.026, data 19.548) 0.00060 lr
Epoch 14 Iter 1200, train entropy gap 1.9842 bits (loss 21.532, data 19.548) 0.00060 lr
Epoch 14 Iter 1400, train entropy gap 0.7988 bits (loss 20.346, data 19.548) 0.00060 lr
Epoch 14 Iter 1600, train entropy gap 2.3710 bits (loss 21.919, data 19.548) 0.00060 lr
Epoch 14 Iter 1800, train entropy gap 0.8439 bits (loss 20.392, data 19.548) 0.00060 lr
Epoch 14 Iter 2000, train entropy gap 2.7858 bits (loss 22.333, data 19.548) 0.00059 lr
Epoch 14 Iter 2200, train entropy gap 2.5191 bits (loss 22.067, data 19.548) 0.00059 lr
Epoch 14 Iter 2400, train entropy gap 1.8713 bits (loss 21.419, data 19.548) 0.00059 lr
Epoch 14 Iter 2600, train entropy gap 1.5616 bits (loss 21.109, data 19.548) 0.00059 lr
Epoch 14 Iter 2800, train entropy gap 1.8472 bits (loss 21.395, data 19.548) 0.00059 lr
Epoch 14 Iter 3000, train entropy gap 1.3088 bits (loss 20.857, data 19.548) 0.00059 lr
Epoch 14 Iter 3200, train entropy gap 1.2191 bits (loss 20.767, data 19.548) 0.00059 lr
Epoch 14 Iter 3400, train entropy gap 2.4053 bits (loss 21.953, data 19.548) 0.00059 lr
Epoch 14 Iter 3600, train entropy gap 1.6447 bits (loss 21.192, data 19.548) 0.00059 lr
Epoch 14 Iter 3800, train entropy gap 1.9250 bits (loss 21.473, data 19.548) 0.00059 lr
Epoch 14 Iter 4000, train entropy gap 1.2343 bits (loss 20.782, data 19.548) 0.00059 lr
Epoch 14 Iter 4200, train entropy gap 1.9196 bits (loss 21.467, data 19.548) 0.00059 lr
Epoch 14 Iter 4400, train entropy gap 0.8263 bits (loss 20.374, data 19.548) 0.00059 lr
Epoch 14 Iter 4600, train entropy gap 1.4949 bits (loss 21.043, data 19.548) 0.00059 lr
Epoch 14 Iter 4800, train entropy gap 1.1998 bits (loss 20.748, data 19.548) 0.00059 lr
Epoch 14 Iter 5000, train entropy gap 1.6116 bits (loss 21.159, data 19.548) 0.00059 lr
Epoch 14 Iter 5200, train entropy gap 2.6424 bits (loss 22.190, data 19.548) 0.00058 lr
Epoch 14 Iter 5400, train entropy gap 1.1342 bits (loss 20.682, data 19.548) 0.00058 lr
Epoch 14 Iter 5600, train entropy gap 2.3759 bits (loss 21.924, data 19.548) 0.00058 lr
Epoch 14 Iter 5800, train entropy gap 1.4929 bits (loss 21.041, data 19.548) 0.00058 lr
Epoch 14 Iter 6000, train entropy gap 1.4513 bits (loss 20.999, data 19.548) 0.00058 lr
epoch 14 train loss 14.7327 nats / 21.2548 bits
time since start: 2112.8 secs
Epoch 15 Iter 0, train entropy gap 1.6066 bits (loss 21.154, data 19.548) 0.00058 lr
Epoch 15 Iter 200, train entropy gap 2.0183 bits (loss 21.566, data 19.548) 0.00058 lr
Epoch 15 Iter 400, train entropy gap 1.2236 bits (loss 20.771, data 19.548) 0.00058 lr
Epoch 15 Iter 600, train entropy gap 1.6022 bits (loss 21.150, data 19.548) 0.00058 lr
Epoch 15 Iter 800, train entropy gap 1.9960 bits (loss 21.544, data 19.548) 0.00058 lr
Epoch 15 Iter 1000, train entropy gap 2.7085 bits (loss 22.256, data 19.548) 0.00058 lr
Epoch 15 Iter 1200, train entropy gap 0.9885 bits (loss 20.536, data 19.548) 0.00058 lr
Epoch 15 Iter 1400, train entropy gap 2.6759 bits (loss 22.224, data 19.548) 0.00058 lr
Epoch 15 Iter 1600, train entropy gap 1.7713 bits (loss 21.319, data 19.548) 0.00058 lr
Epoch 15 Iter 1800, train entropy gap 2.2904 bits (loss 21.838, data 19.548) 0.00058 lr
Epoch 15 Iter 2000, train entropy gap 1.6388 bits (loss 21.186, data 19.548) 0.00058 lr
Epoch 15 Iter 2200, train entropy gap 2.1316 bits (loss 21.679, data 19.548) 0.00057 lr
Epoch 15 Iter 2400, train entropy gap 2.0054 bits (loss 21.553, data 19.548) 0.00057 lr
Epoch 15 Iter 2600, train entropy gap 2.3146 bits (loss 21.862, data 19.548) 0.00057 lr
Epoch 15 Iter 2800, train entropy gap 1.0138 bits (loss 20.562, data 19.548) 0.00057 lr
Epoch 15 Iter 3000, train entropy gap 2.2018 bits (loss 21.749, data 19.548) 0.00057 lr
Epoch 15 Iter 3200, train entropy gap 0.9534 bits (loss 20.501, data 19.548) 0.00057 lr
Epoch 15 Iter 3400, train entropy gap 1.7171 bits (loss 21.265, data 19.548) 0.00057 lr
Epoch 15 Iter 3600, train entropy gap 1.5155 bits (loss 21.063, data 19.548) 0.00057 lr
Epoch 15 Iter 3800, train entropy gap 1.4115 bits (loss 20.959, data 19.548) 0.00057 lr
Epoch 15 Iter 4000, train entropy gap 2.4253 bits (loss 21.973, data 19.548) 0.00057 lr
Epoch 15 Iter 4200, train entropy gap 1.4299 bits (loss 20.978, data 19.548) 0.00057 lr
Epoch 15 Iter 4400, train entropy gap 0.9094 bits (loss 20.457, data 19.548) 0.00057 lr
Epoch 15 Iter 4600, train entropy gap 1.4767 bits (loss 21.024, data 19.548) 0.00057 lr
Epoch 15 Iter 4800, train entropy gap 1.5038 bits (loss 21.052, data 19.548) 0.00057 lr
Epoch 15 Iter 5000, train entropy gap 1.4257 bits (loss 20.973, data 19.548) 0.00057 lr
Epoch 15 Iter 5200, train entropy gap 2.1348 bits (loss 21.683, data 19.548) 0.00057 lr
Epoch 15 Iter 5400, train entropy gap 1.5915 bits (loss 21.139, data 19.548) 0.00057 lr
Epoch 15 Iter 5600, train entropy gap 1.3569 bits (loss 20.905, data 19.548) 0.00056 lr
Epoch 15 Iter 5800, train entropy gap 2.3506 bits (loss 21.898, data 19.548) 0.00056 lr
Epoch 15 Iter 6000, train entropy gap 1.8178 bits (loss 21.366, data 19.548) 0.00056 lr
epoch 15 train loss 14.7371 nats / 21.2611 bits
time since start: 2253.7 secs
Epoch 16 Iter 0, train entropy gap 2.3786 bits (loss 21.926, data 19.548) 0.00056 lr
Epoch 16 Iter 200, train entropy gap 1.8766 bits (loss 21.424, data 19.548) 0.00056 lr
Epoch 16 Iter 400, train entropy gap 1.5286 bits (loss 21.076, data 19.548) 0.00056 lr
Epoch 16 Iter 600, train entropy gap 2.1185 bits (loss 21.666, data 19.548) 0.00056 lr
Epoch 16 Iter 800, train entropy gap 1.9226 bits (loss 21.470, data 19.548) 0.00056 lr
Epoch 16 Iter 1000, train entropy gap 2.2519 bits (loss 21.800, data 19.548) 0.00056 lr
Epoch 16 Iter 1200, train entropy gap 1.6949 bits (loss 21.243, data 19.548) 0.00056 lr
Epoch 16 Iter 1400, train entropy gap 2.1746 bits (loss 21.722, data 19.548) 0.00056 lr
Epoch 16 Iter 1600, train entropy gap 1.6901 bits (loss 21.238, data 19.548) 0.00056 lr
Epoch 16 Iter 1800, train entropy gap 1.1106 bits (loss 20.658, data 19.548) 0.00056 lr
Epoch 16 Iter 2000, train entropy gap 1.5321 bits (loss 21.080, data 19.548) 0.00056 lr
Epoch 16 Iter 2200, train entropy gap 2.4060 bits (loss 21.954, data 19.548) 0.00056 lr
Epoch 16 Iter 2400, train entropy gap 1.1937 bits (loss 20.741, data 19.548) 0.00056 lr
Epoch 16 Iter 2600, train entropy gap 1.4787 bits (loss 21.026, data 19.548) 0.00056 lr
Epoch 16 Iter 2800, train entropy gap 2.5132 bits (loss 22.061, data 19.548) 0.00056 lr
Epoch 16 Iter 3000, train entropy gap 0.9844 bits (loss 20.532, data 19.548) 0.00055 lr
Epoch 16 Iter 3200, train entropy gap 2.4321 bits (loss 21.980, data 19.548) 0.00055 lr
Epoch 16 Iter 3400, train entropy gap 1.6274 bits (loss 21.175, data 19.548) 0.00055 lr
Epoch 16 Iter 3600, train entropy gap 1.7189 bits (loss 21.267, data 19.548) 0.00055 lr
Epoch 16 Iter 3800, train entropy gap 1.1670 bits (loss 20.715, data 19.548) 0.00055 lr
Epoch 16 Iter 4000, train entropy gap 2.3315 bits (loss 21.879, data 19.548) 0.00055 lr
Epoch 16 Iter 4200, train entropy gap 2.2759 bits (loss 21.824, data 19.548) 0.00055 lr
Epoch 16 Iter 4400, train entropy gap 1.6947 bits (loss 21.242, data 19.548) 0.00055 lr
Epoch 16 Iter 4600, train entropy gap 1.3591 bits (loss 20.907, data 19.548) 0.00055 lr
Epoch 16 Iter 4800, train entropy gap 1.3901 bits (loss 20.938, data 19.548) 0.00055 lr
Epoch 16 Iter 5000, train entropy gap 2.0873 bits (loss 21.635, data 19.548) 0.00055 lr
Epoch 16 Iter 5200, train entropy gap 2.3119 bits (loss 21.860, data 19.548) 0.00055 lr
Epoch 16 Iter 5400, train entropy gap 0.8478 bits (loss 20.396, data 19.548) 0.00055 lr
Epoch 16 Iter 5600, train entropy gap 2.2980 bits (loss 21.846, data 19.548) 0.00055 lr
Epoch 16 Iter 5800, train entropy gap 1.4656 bits (loss 21.013, data 19.548) 0.00055 lr
Epoch 16 Iter 6000, train entropy gap 2.0372 bits (loss 21.585, data 19.548) 0.00055 lr
epoch 16 train loss 14.7393 nats / 21.2643 bits
time since start: 2394.6 secs
Epoch 17 Iter 0, train entropy gap 2.1339 bits (loss 21.682, data 19.548) 0.00055 lr
Epoch 17 Iter 200, train entropy gap 2.2551 bits (loss 21.803, data 19.548) 0.00055 lr
Epoch 17 Iter 400, train entropy gap 1.4936 bits (loss 21.041, data 19.548) 0.00055 lr
Epoch 17 Iter 600, train entropy gap 1.6661 bits (loss 21.214, data 19.548) 0.00054 lr
Epoch 17 Iter 800, train entropy gap 1.3993 bits (loss 20.947, data 19.548) 0.00054 lr
Epoch 17 Iter 1000, train entropy gap 1.7849 bits (loss 21.333, data 19.548) 0.00054 lr
Epoch 17 Iter 1200, train entropy gap 1.0665 bits (loss 20.614, data 19.548) 0.00054 lr
Epoch 17 Iter 1400, train entropy gap 2.2724 bits (loss 21.820, data 19.548) 0.00054 lr
Epoch 17 Iter 1600, train entropy gap 2.2168 bits (loss 21.765, data 19.548) 0.00054 lr
Epoch 17 Iter 1800, train entropy gap 2.3473 bits (loss 21.895, data 19.548) 0.00054 lr
Epoch 17 Iter 2000, train entropy gap 2.3890 bits (loss 21.937, data 19.548) 0.00054 lr
Epoch 17 Iter 2200, train entropy gap 2.0926 bits (loss 21.640, data 19.548) 0.00054 lr
Epoch 17 Iter 2400, train entropy gap 1.0040 bits (loss 20.552, data 19.548) 0.00054 lr
Epoch 17 Iter 2600, train entropy gap 2.2912 bits (loss 21.839, data 19.548) 0.00054 lr
Epoch 17 Iter 2800, train entropy gap 1.8984 bits (loss 21.446, data 19.548) 0.00054 lr
Epoch 17 Iter 3000, train entropy gap 1.8360 bits (loss 21.384, data 19.548) 0.00054 lr
Epoch 17 Iter 3200, train entropy gap 1.9411 bits (loss 21.489, data 19.548) 0.00054 lr
Epoch 17 Iter 3400, train entropy gap 2.9049 bits (loss 22.453, data 19.548) 0.00054 lr
Epoch 17 Iter 3600, train entropy gap 2.1198 bits (loss 21.667, data 19.548) 0.00054 lr
Epoch 17 Iter 3800, train entropy gap 1.3017 bits (loss 20.849, data 19.548) 0.00054 lr
Epoch 17 Iter 4000, train entropy gap 1.9577 bits (loss 21.505, data 19.548) 0.00054 lr
Epoch 17 Iter 4200, train entropy gap 1.9181 bits (loss 21.466, data 19.548) 0.00054 lr
Epoch 17 Iter 4400, train entropy gap 1.8114 bits (loss 21.359, data 19.548) 0.00054 lr
Epoch 17 Iter 4600, train entropy gap 2.1698 bits (loss 21.718, data 19.548) 0.00053 lr
Epoch 17 Iter 4800, train entropy gap 2.9439 bits (loss 22.492, data 19.548) 0.00053 lr
Epoch 17 Iter 5000, train entropy gap 3.0437 bits (loss 22.591, data 19.548) 0.00053 lr
Epoch 17 Iter 5200, train entropy gap 1.9197 bits (loss 21.467, data 19.548) 0.00053 lr
Epoch 17 Iter 5400, train entropy gap 1.1350 bits (loss 20.683, data 19.548) 0.00053 lr
Epoch 17 Iter 5600, train entropy gap 1.7422 bits (loss 21.290, data 19.548) 0.00053 lr
Epoch 17 Iter 5800, train entropy gap 1.1833 bits (loss 20.731, data 19.548) 0.00053 lr
Epoch 17 Iter 6000, train entropy gap 1.0583 bits (loss 20.606, data 19.548) 0.00053 lr
epoch 17 train loss 14.7424 nats / 21.2687 bits
time since start: 2535.4 secs
Epoch 18 Iter 0, train entropy gap 1.4276 bits (loss 20.975, data 19.548) 0.00053 lr
Epoch 18 Iter 200, train entropy gap 2.1129 bits (loss 21.661, data 19.548) 0.00053 lr
Epoch 18 Iter 400, train entropy gap 1.8643 bits (loss 21.412, data 19.548) 0.00053 lr
Epoch 18 Iter 600, train entropy gap 1.5502 bits (loss 21.098, data 19.548) 0.00053 lr
Epoch 18 Iter 800, train entropy gap 1.4320 bits (loss 20.980, data 19.548) 0.00053 lr
Epoch 18 Iter 1000, train entropy gap 1.1119 bits (loss 20.660, data 19.548) 0.00053 lr
Epoch 18 Iter 1200, train entropy gap 2.5106 bits (loss 22.058, data 19.548) 0.00053 lr
Epoch 18 Iter 1400, train entropy gap 1.0200 bits (loss 20.568, data 19.548) 0.00053 lr
Epoch 18 Iter 1600, train entropy gap 3.4339 bits (loss 22.982, data 19.548) 0.00053 lr
Epoch 18 Iter 1800, train entropy gap 1.7843 bits (loss 21.332, data 19.548) 0.00053 lr
Epoch 18 Iter 2000, train entropy gap 1.1826 bits (loss 20.730, data 19.548) 0.00053 lr
Epoch 18 Iter 2200, train entropy gap 1.0091 bits (loss 20.557, data 19.548) 0.00053 lr
Epoch 18 Iter 2400, train entropy gap 1.0111 bits (loss 20.559, data 19.548) 0.00053 lr
Epoch 18 Iter 2600, train entropy gap 1.0486 bits (loss 20.596, data 19.548) 0.00052 lr
Epoch 18 Iter 2800, train entropy gap 2.1793 bits (loss 21.727, data 19.548) 0.00052 lr
Epoch 18 Iter 3000, train entropy gap 1.1645 bits (loss 20.712, data 19.548) 0.00052 lr
Epoch 18 Iter 3200, train entropy gap 1.8603 bits (loss 21.408, data 19.548) 0.00052 lr
Epoch 18 Iter 3400, train entropy gap 1.6327 bits (loss 21.180, data 19.548) 0.00052 lr
Epoch 18 Iter 3600, train entropy gap 2.0477 bits (loss 21.595, data 19.548) 0.00052 lr
Epoch 18 Iter 3800, train entropy gap 1.5331 bits (loss 21.081, data 19.548) 0.00052 lr
Epoch 18 Iter 4000, train entropy gap 1.6379 bits (loss 21.186, data 19.548) 0.00052 lr
Epoch 18 Iter 4200, train entropy gap 1.7346 bits (loss 21.282, data 19.548) 0.00052 lr
Epoch 18 Iter 4400, train entropy gap 1.8185 bits (loss 21.366, data 19.548) 0.00052 lr
Epoch 18 Iter 4600, train entropy gap 2.1183 bits (loss 21.666, data 19.548) 0.00052 lr
Epoch 18 Iter 4800, train entropy gap 2.6572 bits (loss 22.205, data 19.548) 0.00052 lr
Epoch 18 Iter 5000, train entropy gap 2.1342 bits (loss 21.682, data 19.548) 0.00052 lr
Epoch 18 Iter 5200, train entropy gap 1.7671 bits (loss 21.315, data 19.548) 0.00052 lr
Epoch 18 Iter 5400, train entropy gap 2.2238 bits (loss 21.772, data 19.548) 0.00052 lr
Epoch 18 Iter 5600, train entropy gap 1.3310 bits (loss 20.879, data 19.548) 0.00052 lr
Epoch 18 Iter 5800, train entropy gap 2.7786 bits (loss 22.326, data 19.548) 0.00052 lr
Epoch 18 Iter 6000, train entropy gap 1.1840 bits (loss 20.732, data 19.548) 0.00052 lr
epoch 18 train loss 14.7395 nats / 21.2646 bits
time since start: 2675.9 secs
Epoch 19 Iter 0, train entropy gap 1.1626 bits (loss 20.710, data 19.548) 0.00052 lr
Epoch 19 Iter 200, train entropy gap 1.8063 bits (loss 21.354, data 19.548) 0.00052 lr
Epoch 19 Iter 400, train entropy gap 2.1267 bits (loss 21.674, data 19.548) 0.00052 lr
Epoch 19 Iter 600, train entropy gap 1.3088 bits (loss 20.856, data 19.548) 0.00052 lr
Epoch 19 Iter 800, train entropy gap 1.5392 bits (loss 21.087, data 19.548) 0.00051 lr
Epoch 19 Iter 1000, train entropy gap 0.9592 bits (loss 20.507, data 19.548) 0.00051 lr
Epoch 19 Iter 1200, train entropy gap 2.0695 bits (loss 21.617, data 19.548) 0.00051 lr
Epoch 19 Iter 1400, train entropy gap 1.2946 bits (loss 20.842, data 19.548) 0.00051 lr
Epoch 19 Iter 1600, train entropy gap 1.4840 bits (loss 21.032, data 19.548) 0.00051 lr
Epoch 19 Iter 1800, train entropy gap 2.3600 bits (loss 21.908, data 19.548) 0.00051 lr
Epoch 19 Iter 2000, train entropy gap 1.1041 bits (loss 20.652, data 19.548) 0.00051 lr
Epoch 19 Iter 2200, train entropy gap 1.4764 bits (loss 21.024, data 19.548) 0.00051 lr
Epoch 19 Iter 2400, train entropy gap 0.8762 bits (loss 20.424, data 19.548) 0.00051 lr
Epoch 19 Iter 2600, train entropy gap 1.2451 bits (loss 20.793, data 19.548) 0.00051 lr
Epoch 19 Iter 2800, train entropy gap 3.2518 bits (loss 22.800, data 19.548) 0.00051 lr
Epoch 19 Iter 3000, train entropy gap 1.9340 bits (loss 21.482, data 19.548) 0.00051 lr
Epoch 19 Iter 3200, train entropy gap 1.1274 bits (loss 20.675, data 19.548) 0.00051 lr
Epoch 19 Iter 3400, train entropy gap 1.8329 bits (loss 21.381, data 19.548) 0.00051 lr
Epoch 19 Iter 3600, train entropy gap 1.4087 bits (loss 20.956, data 19.548) 0.00051 lr
Epoch 19 Iter 3800, train entropy gap 2.2714 bits (loss 21.819, data 19.548) 0.00051 lr
Epoch 19 Iter 4000, train entropy gap 2.1127 bits (loss 21.660, data 19.548) 0.00051 lr
Epoch 19 Iter 4200, train entropy gap 1.2661 bits (loss 20.814, data 19.548) 0.00051 lr
Epoch 19 Iter 4400, train entropy gap 1.8578 bits (loss 21.406, data 19.548) 0.00051 lr
Epoch 19 Iter 4600, train entropy gap 1.2013 bits (loss 20.749, data 19.548) 0.00051 lr
Epoch 19 Iter 4800, train entropy gap 1.9681 bits (loss 21.516, data 19.548) 0.00051 lr
Epoch 19 Iter 5000, train entropy gap 2.0144 bits (loss 21.562, data 19.548) 0.00051 lr
Epoch 19 Iter 5200, train entropy gap 2.0744 bits (loss 21.622, data 19.548) 0.00051 lr
Epoch 19 Iter 5400, train entropy gap 1.6882 bits (loss 21.236, data 19.548) 0.00051 lr
Epoch 19 Iter 5600, train entropy gap 1.3821 bits (loss 20.930, data 19.548) 0.00050 lr
Epoch 19 Iter 5800, train entropy gap 1.4331 bits (loss 20.981, data 19.548) 0.00050 lr
Epoch 19 Iter 6000, train entropy gap 0.9269 bits (loss 20.475, data 19.548) 0.00050 lr
epoch 19 train loss 14.7360 nats / 21.2596 bits
time since start: 2816.7 secs
Epoch 20 Iter 0, train entropy gap 1.8717 bits (loss 21.419, data 19.548) 0.00050 lr
Epoch 20 Iter 200, train entropy gap 1.8806 bits (loss 21.428, data 19.548) 0.00050 lr
Epoch 20 Iter 400, train entropy gap 0.8416 bits (loss 20.389, data 19.548) 0.00050 lr
Epoch 20 Iter 600, train entropy gap 2.3582 bits (loss 21.906, data 19.548) 0.00050 lr
Epoch 20 Iter 800, train entropy gap 1.5634 bits (loss 21.111, data 19.548) 0.00050 lr
Epoch 20 Iter 1000, train entropy gap 2.5349 bits (loss 22.083, data 19.548) 0.00050 lr
Epoch 20 Iter 1200, train entropy gap 1.6975 bits (loss 21.245, data 19.548) 0.00050 lr
Epoch 20 Iter 1400, train entropy gap 0.6903 bits (loss 20.238, data 19.548) 0.00050 lr
Epoch 20 Iter 1600, train entropy gap 1.2703 bits (loss 20.818, data 19.548) 0.00050 lr
Epoch 20 Iter 1800, train entropy gap 1.5965 bits (loss 21.144, data 19.548) 0.00050 lr
Epoch 20 Iter 2000, train entropy gap 1.1997 bits (loss 20.747, data 19.548) 0.00050 lr
Epoch 20 Iter 2200, train entropy gap 1.8103 bits (loss 21.358, data 19.548) 0.00050 lr
Epoch 20 Iter 2400, train entropy gap 2.9970 bits (loss 22.545, data 19.548) 0.00050 lr
Epoch 20 Iter 2600, train entropy gap 1.9065 bits (loss 21.454, data 19.548) 0.00050 lr
Epoch 20 Iter 2800, train entropy gap 1.1723 bits (loss 20.720, data 19.548) 0.00050 lr
Epoch 20 Iter 3000, train entropy gap 1.5577 bits (loss 21.105, data 19.548) 0.00050 lr
Epoch 20 Iter 3200, train entropy gap 1.5768 bits (loss 21.125, data 19.548) 0.00050 lr
Epoch 20 Iter 3400, train entropy gap 0.9350 bits (loss 20.483, data 19.548) 0.00050 lr
Epoch 20 Iter 3600, train entropy gap 2.2760 bits (loss 21.824, data 19.548) 0.00050 lr
Epoch 20 Iter 3800, train entropy gap 1.7910 bits (loss 21.339, data 19.548) 0.00050 lr
Epoch 20 Iter 4000, train entropy gap 2.4857 bits (loss 22.033, data 19.548) 0.00050 lr
Epoch 20 Iter 4200, train entropy gap 0.9319 bits (loss 20.480, data 19.548) 0.00050 lr
Epoch 20 Iter 4400, train entropy gap 1.1525 bits (loss 20.700, data 19.548) 0.00049 lr
Epoch 20 Iter 4600, train entropy gap 1.6190 bits (loss 21.167, data 19.548) 0.00049 lr
Epoch 20 Iter 4800, train entropy gap 1.5757 bits (loss 21.123, data 19.548) 0.00049 lr
Epoch 20 Iter 5000, train entropy gap 2.5731 bits (loss 22.121, data 19.548) 0.00049 lr
Epoch 20 Iter 5200, train entropy gap 1.8725 bits (loss 21.420, data 19.548) 0.00049 lr
Epoch 20 Iter 5400, train entropy gap 1.2629 bits (loss 20.811, data 19.548) 0.00049 lr
Epoch 20 Iter 5600, train entropy gap 0.9360 bits (loss 20.484, data 19.548) 0.00049 lr
Epoch 20 Iter 5800, train entropy gap 1.0549 bits (loss 20.603, data 19.548) 0.00049 lr
Epoch 20 Iter 6000, train entropy gap 1.3393 bits (loss 20.887, data 19.548) 0.00049 lr
epoch 20 train loss 14.7392 nats / 21.2642 bits
time since start: 2957.9 secs
Epoch 21 Iter 0, train entropy gap 1.2500 bits (loss 20.798, data 19.548) 0.00049 lr
Epoch 21 Iter 200, train entropy gap 2.2375 bits (loss 21.785, data 19.548) 0.00049 lr
Epoch 21 Iter 400, train entropy gap 1.5241 bits (loss 21.072, data 19.548) 0.00049 lr
Epoch 21 Iter 600, train entropy gap 1.4244 bits (loss 20.972, data 19.548) 0.00049 lr
Epoch 21 Iter 800, train entropy gap 2.8006 bits (loss 22.348, data 19.548) 0.00049 lr
Epoch 21 Iter 1000, train entropy gap 2.3271 bits (loss 21.875, data 19.548) 0.00049 lr
Epoch 21 Iter 1200, train entropy gap 0.8687 bits (loss 20.416, data 19.548) 0.00049 lr
Epoch 21 Iter 1400, train entropy gap 0.8603 bits (loss 20.408, data 19.548) 0.00049 lr
Epoch 21 Iter 1600, train entropy gap 1.5209 bits (loss 21.069, data 19.548) 0.00049 lr
Epoch 21 Iter 1800, train entropy gap 1.1627 bits (loss 20.710, data 19.548) 0.00049 lr
Epoch 21 Iter 2000, train entropy gap 2.7198 bits (loss 22.267, data 19.548) 0.00049 lr
Epoch 21 Iter 2200, train entropy gap 1.4575 bits (loss 21.005, data 19.548) 0.00049 lr
Epoch 21 Iter 2400, train entropy gap 1.9970 bits (loss 21.545, data 19.548) 0.00049 lr
Epoch 21 Iter 2600, train entropy gap 1.5206 bits (loss 21.068, data 19.548) 0.00049 lr
Epoch 21 Iter 2800, train entropy gap 1.8404 bits (loss 21.388, data 19.548) 0.00049 lr
Epoch 21 Iter 3000, train entropy gap 1.6158 bits (loss 21.164, data 19.548) 0.00049 lr
Epoch 21 Iter 3200, train entropy gap 1.7322 bits (loss 21.280, data 19.548) 0.00049 lr
Epoch 21 Iter 3400, train entropy gap 1.9239 bits (loss 21.472, data 19.548) 0.00049 lr
Epoch 21 Iter 3600, train entropy gap 0.7838 bits (loss 20.332, data 19.548) 0.00048 lr
Epoch 21 Iter 3800, train entropy gap 1.1855 bits (loss 20.733, data 19.548) 0.00048 lr
Epoch 21 Iter 4000, train entropy gap 1.3868 bits (loss 20.935, data 19.548) 0.00048 lr
Epoch 21 Iter 4200, train entropy gap 1.3867 bits (loss 20.934, data 19.548) 0.00048 lr
Epoch 21 Iter 4400, train entropy gap 1.8731 bits (loss 21.421, data 19.548) 0.00048 lr
Epoch 21 Iter 4600, train entropy gap 1.2522 bits (loss 20.800, data 19.548) 0.00048 lr
Epoch 21 Iter 4800, train entropy gap 1.3337 bits (loss 20.881, data 19.548) 0.00048 lr
Epoch 21 Iter 5000, train entropy gap 2.3146 bits (loss 21.862, data 19.548) 0.00048 lr
Epoch 21 Iter 5200, train entropy gap 2.4836 bits (loss 22.031, data 19.548) 0.00048 lr
Epoch 21 Iter 5400, train entropy gap 0.9552 bits (loss 20.503, data 19.548) 0.00048 lr
Epoch 21 Iter 5600, train entropy gap 1.8010 bits (loss 21.349, data 19.548) 0.00048 lr
Epoch 21 Iter 5800, train entropy gap 1.8175 bits (loss 21.365, data 19.548) 0.00048 lr
Epoch 21 Iter 6000, train entropy gap 1.8029 bits (loss 21.351, data 19.548) 0.00048 lr
epoch 21 train loss 14.7340 nats / 21.2566 bits
time since start: 3099.2 secs
Epoch 22 Iter 0, train entropy gap 1.5113 bits (loss 21.059, data 19.548) 0.00048 lr
Epoch 22 Iter 200, train entropy gap 1.7984 bits (loss 21.346, data 19.548) 0.00048 lr
Epoch 22 Iter 400, train entropy gap 0.7172 bits (loss 20.265, data 19.548) 0.00048 lr
Epoch 22 Iter 600, train entropy gap 1.5690 bits (loss 21.117, data 19.548) 0.00048 lr
Epoch 22 Iter 800, train entropy gap 1.2165 bits (loss 20.764, data 19.548) 0.00048 lr
Epoch 22 Iter 1000, train entropy gap 2.0325 bits (loss 21.580, data 19.548) 0.00048 lr
Epoch 22 Iter 1200, train entropy gap 1.2171 bits (loss 20.765, data 19.548) 0.00048 lr
Epoch 22 Iter 1400, train entropy gap 2.4870 bits (loss 22.035, data 19.548) 0.00048 lr
Epoch 22 Iter 1600, train entropy gap 2.5460 bits (loss 22.094, data 19.548) 0.00048 lr
Epoch 22 Iter 1800, train entropy gap 2.4159 bits (loss 21.964, data 19.548) 0.00048 lr
Epoch 22 Iter 2000, train entropy gap 1.7486 bits (loss 21.296, data 19.548) 0.00048 lr
Epoch 22 Iter 2200, train entropy gap 1.0598 bits (loss 20.608, data 19.548) 0.00048 lr
Epoch 22 Iter 2400, train entropy gap 1.8238 bits (loss 21.371, data 19.548) 0.00048 lr
Epoch 22 Iter 2600, train entropy gap 1.6924 bits (loss 21.240, data 19.548) 0.00048 lr
Epoch 22 Iter 2800, train entropy gap 1.3498 bits (loss 20.898, data 19.548) 0.00048 lr
Epoch 22 Iter 3000, train entropy gap 2.6700 bits (loss 22.218, data 19.548) 0.00047 lr
Epoch 22 Iter 3200, train entropy gap 1.4853 bits (loss 21.033, data 19.548) 0.00047 lr
Epoch 22 Iter 3400, train entropy gap 2.1413 bits (loss 21.689, data 19.548) 0.00047 lr
Epoch 22 Iter 3600, train entropy gap 1.6434 bits (loss 21.191, data 19.548) 0.00047 lr
Epoch 22 Iter 3800, train entropy gap 1.4646 bits (loss 21.012, data 19.548) 0.00047 lr
Epoch 22 Iter 4000, train entropy gap 1.7843 bits (loss 21.332, data 19.548) 0.00047 lr
Epoch 22 Iter 4200, train entropy gap 3.3353 bits (loss 22.883, data 19.548) 0.00047 lr
Epoch 22 Iter 4400, train entropy gap 1.2224 bits (loss 20.770, data 19.548) 0.00047 lr
Epoch 22 Iter 4600, train entropy gap 2.1765 bits (loss 21.724, data 19.548) 0.00047 lr
Epoch 22 Iter 4800, train entropy gap 1.1845 bits (loss 20.732, data 19.548) 0.00047 lr
Epoch 22 Iter 5000, train entropy gap 0.6888 bits (loss 20.237, data 19.548) 0.00047 lr
Epoch 22 Iter 5200, train entropy gap 1.9452 bits (loss 21.493, data 19.548) 0.00047 lr
Epoch 22 Iter 5400, train entropy gap 2.0205 bits (loss 21.568, data 19.548) 0.00047 lr
Epoch 22 Iter 5600, train entropy gap 2.0438 bits (loss 21.591, data 19.548) 0.00047 lr
Epoch 22 Iter 5800, train entropy gap 1.2968 bits (loss 20.844, data 19.548) 0.00047 lr
Epoch 22 Iter 6000, train entropy gap 2.5148 bits (loss 22.063, data 19.548) 0.00047 lr
epoch 22 train loss 14.7359 nats / 21.2595 bits
time since start: 3240.0 secs
Epoch 23 Iter 0, train entropy gap 0.9305 bits (loss 20.478, data 19.548) 0.00047 lr
Epoch 23 Iter 200, train entropy gap 2.9895 bits (loss 22.537, data 19.548) 0.00047 lr
Epoch 23 Iter 400, train entropy gap 1.3784 bits (loss 20.926, data 19.548) 0.00047 lr
Epoch 23 Iter 600, train entropy gap 1.3882 bits (loss 20.936, data 19.548) 0.00047 lr
Epoch 23 Iter 800, train entropy gap 1.1268 bits (loss 20.674, data 19.548) 0.00047 lr
Epoch 23 Iter 1000, train entropy gap 1.6629 bits (loss 21.211, data 19.548) 0.00047 lr
Epoch 23 Iter 1200, train entropy gap 1.8677 bits (loss 21.415, data 19.548) 0.00047 lr
Epoch 23 Iter 1400, train entropy gap 1.4788 bits (loss 21.027, data 19.548) 0.00047 lr
Epoch 23 Iter 1600, train entropy gap 1.5591 bits (loss 21.107, data 19.548) 0.00047 lr
Epoch 23 Iter 1800, train entropy gap 0.7392 bits (loss 20.287, data 19.548) 0.00047 lr
Epoch 23 Iter 2000, train entropy gap 2.4401 bits (loss 21.988, data 19.548) 0.00047 lr
Epoch 23 Iter 2200, train entropy gap 1.8444 bits (loss 21.392, data 19.548) 0.00047 lr
Epoch 23 Iter 2400, train entropy gap 1.9986 bits (loss 21.546, data 19.548) 0.00047 lr
Epoch 23 Iter 2600, train entropy gap 1.3278 bits (loss 20.875, data 19.548) 0.00047 lr
Epoch 23 Iter 2800, train entropy gap 1.8655 bits (loss 21.413, data 19.548) 0.00046 lr
Epoch 23 Iter 3000, train entropy gap 1.9854 bits (loss 21.533, data 19.548) 0.00046 lr
Epoch 23 Iter 3200, train entropy gap 1.4949 bits (loss 21.043, data 19.548) 0.00046 lr
Epoch 23 Iter 3400, train entropy gap 1.7285 bits (loss 21.276, data 19.548) 0.00046 lr
Epoch 23 Iter 3600, train entropy gap 2.4995 bits (loss 22.047, data 19.548) 0.00046 lr
Epoch 23 Iter 3800, train entropy gap 0.7985 bits (loss 20.346, data 19.548) 0.00046 lr
Epoch 23 Iter 4000, train entropy gap 1.4234 bits (loss 20.971, data 19.548) 0.00046 lr
Epoch 23 Iter 4200, train entropy gap 1.4535 bits (loss 21.001, data 19.548) 0.00046 lr
Epoch 23 Iter 4400, train entropy gap 2.7101 bits (loss 22.258, data 19.548) 0.00046 lr
Epoch 23 Iter 4600, train entropy gap 2.0141 bits (loss 21.562, data 19.548) 0.00046 lr
Epoch 23 Iter 4800, train entropy gap 2.1866 bits (loss 21.734, data 19.548) 0.00046 lr
Epoch 23 Iter 5000, train entropy gap 2.1880 bits (loss 21.736, data 19.548) 0.00046 lr
Epoch 23 Iter 5200, train entropy gap 1.6270 bits (loss 21.175, data 19.548) 0.00046 lr
Epoch 23 Iter 5400, train entropy gap 2.2470 bits (loss 21.795, data 19.548) 0.00046 lr
Epoch 23 Iter 5600, train entropy gap 2.1682 bits (loss 21.716, data 19.548) 0.00046 lr
Epoch 23 Iter 5800, train entropy gap 1.5738 bits (loss 21.122, data 19.548) 0.00046 lr
Epoch 23 Iter 6000, train entropy gap 3.1397 bits (loss 22.687, data 19.548) 0.00046 lr
epoch 23 train loss 14.7320 nats / 21.2538 bits
time since start: 3380.5 secs
Epoch 24 Iter 0, train entropy gap 1.8762 bits (loss 21.424, data 19.548) 0.00046 lr
Epoch 24 Iter 200, train entropy gap 1.3709 bits (loss 20.919, data 19.548) 0.00046 lr
Epoch 24 Iter 400, train entropy gap 2.7935 bits (loss 22.341, data 19.548) 0.00046 lr
Epoch 24 Iter 600, train entropy gap 1.0745 bits (loss 20.622, data 19.548) 0.00046 lr
Epoch 24 Iter 800, train entropy gap 2.1852 bits (loss 21.733, data 19.548) 0.00046 lr
Epoch 24 Iter 1000, train entropy gap 2.3005 bits (loss 21.848, data 19.548) 0.00046 lr
Epoch 24 Iter 1200, train entropy gap 1.5785 bits (loss 21.126, data 19.548) 0.00046 lr
Epoch 24 Iter 1400, train entropy gap 1.8350 bits (loss 21.383, data 19.548) 0.00046 lr
Epoch 24 Iter 1600, train entropy gap 1.7967 bits (loss 21.344, data 19.548) 0.00046 lr
Epoch 24 Iter 1800, train entropy gap 1.8289 bits (loss 21.377, data 19.548) 0.00046 lr
Epoch 24 Iter 2000, train entropy gap 1.8000 bits (loss 21.348, data 19.548) 0.00046 lr
Epoch 24 Iter 2200, train entropy gap 2.1217 bits (loss 21.669, data 19.548) 0.00046 lr
Epoch 24 Iter 2400, train entropy gap 2.3148 bits (loss 21.862, data 19.548) 0.00046 lr
Epoch 24 Iter 2600, train entropy gap 1.1425 bits (loss 20.690, data 19.548) 0.00046 lr
Epoch 24 Iter 2800, train entropy gap 0.8883 bits (loss 20.436, data 19.548) 0.00046 lr
Epoch 24 Iter 3000, train entropy gap 1.3423 bits (loss 20.890, data 19.548) 0.00046 lr
Epoch 24 Iter 3200, train entropy gap 1.3775 bits (loss 20.925, data 19.548) 0.00045 lr
Epoch 24 Iter 3400, train entropy gap 2.0395 bits (loss 21.587, data 19.548) 0.00045 lr
Epoch 24 Iter 3600, train entropy gap 1.3900 bits (loss 20.938, data 19.548) 0.00045 lr
Epoch 24 Iter 3800, train entropy gap 1.0054 bits (loss 20.553, data 19.548) 0.00045 lr
Epoch 24 Iter 4000, train entropy gap 1.9373 bits (loss 21.485, data 19.548) 0.00045 lr
Epoch 24 Iter 4200, train entropy gap 1.3404 bits (loss 20.888, data 19.548) 0.00045 lr
Epoch 24 Iter 4400, train entropy gap 1.7638 bits (loss 21.311, data 19.548) 0.00045 lr
Epoch 24 Iter 4600, train entropy gap 1.8101 bits (loss 21.358, data 19.548) 0.00045 lr
Epoch 24 Iter 4800, train entropy gap 2.0040 bits (loss 21.552, data 19.548) 0.00045 lr
Epoch 24 Iter 5000, train entropy gap 1.5675 bits (loss 21.115, data 19.548) 0.00045 lr
Epoch 24 Iter 5200, train entropy gap 1.6090 bits (loss 21.157, data 19.548) 0.00045 lr
Epoch 24 Iter 5400, train entropy gap 1.9676 bits (loss 21.515, data 19.548) 0.00045 lr
Epoch 24 Iter 5600, train entropy gap 0.9727 bits (loss 20.520, data 19.548) 0.00045 lr
Epoch 24 Iter 5800, train entropy gap 2.1914 bits (loss 21.739, data 19.548) 0.00045 lr
Epoch 24 Iter 6000, train entropy gap 1.9216 bits (loss 21.469, data 19.548) 0.00045 lr
epoch 24 train loss 14.7341 nats / 21.2568 bits
time since start: 3521.1 secs
Epoch 25 Iter 0, train entropy gap 1.8321 bits (loss 21.380, data 19.548) 0.00045 lr
Epoch 25 Iter 200, train entropy gap 1.6010 bits (loss 21.149, data 19.548) 0.00045 lr
Epoch 25 Iter 400, train entropy gap 2.3145 bits (loss 21.862, data 19.548) 0.00045 lr
Epoch 25 Iter 600, train entropy gap 2.0253 bits (loss 21.573, data 19.548) 0.00045 lr
Epoch 25 Iter 800, train entropy gap 2.5190 bits (loss 22.067, data 19.548) 0.00045 lr
Epoch 25 Iter 1000, train entropy gap 1.3088 bits (loss 20.857, data 19.548) 0.00045 lr
Epoch 25 Iter 1200, train entropy gap 1.6745 bits (loss 21.222, data 19.548) 0.00045 lr
Epoch 25 Iter 1400, train entropy gap 1.8034 bits (loss 21.351, data 19.548) 0.00045 lr
Epoch 25 Iter 1600, train entropy gap 2.0412 bits (loss 21.589, data 19.548) 0.00045 lr
Epoch 25 Iter 1800, train entropy gap 1.9440 bits (loss 21.492, data 19.548) 0.00045 lr
Epoch 25 Iter 2000, train entropy gap 2.0963 bits (loss 21.644, data 19.548) 0.00045 lr
Epoch 25 Iter 2200, train entropy gap 0.9631 bits (loss 20.511, data 19.548) 0.00045 lr
Epoch 25 Iter 2400, train entropy gap 2.2131 bits (loss 21.761, data 19.548) 0.00045 lr
Epoch 25 Iter 2600, train entropy gap 1.1332 bits (loss 20.681, data 19.548) 0.00045 lr
Epoch 25 Iter 2800, train entropy gap 0.8977 bits (loss 20.445, data 19.548) 0.00045 lr
Epoch 25 Iter 3000, train entropy gap 2.3047 bits (loss 21.852, data 19.548) 0.00045 lr
Epoch 25 Iter 3200, train entropy gap 1.8249 bits (loss 21.373, data 19.548) 0.00045 lr
Epoch 25 Iter 3400, train entropy gap 1.7143 bits (loss 21.262, data 19.548) 0.00045 lr
Epoch 25 Iter 3600, train entropy gap 1.4098 bits (loss 20.958, data 19.548) 0.00045 lr
Epoch 25 Iter 3800, train entropy gap 2.4685 bits (loss 22.016, data 19.548) 0.00044 lr
Epoch 25 Iter 4000, train entropy gap 1.3607 bits (loss 20.908, data 19.548) 0.00044 lr
Epoch 25 Iter 4200, train entropy gap 2.7349 bits (loss 22.283, data 19.548) 0.00044 lr
Epoch 25 Iter 4400, train entropy gap 1.5912 bits (loss 21.139, data 19.548) 0.00044 lr
Epoch 25 Iter 4600, train entropy gap 1.8535 bits (loss 21.401, data 19.548) 0.00044 lr
Epoch 25 Iter 4800, train entropy gap 2.3852 bits (loss 21.933, data 19.548) 0.00044 lr
Epoch 25 Iter 5000, train entropy gap 1.5821 bits (loss 21.130, data 19.548) 0.00044 lr
Epoch 25 Iter 5200, train entropy gap 1.0030 bits (loss 20.551, data 19.548) 0.00044 lr
Epoch 25 Iter 5400, train entropy gap 1.6081 bits (loss 21.156, data 19.548) 0.00044 lr
Epoch 25 Iter 5600, train entropy gap 1.6350 bits (loss 21.183, data 19.548) 0.00044 lr
Epoch 25 Iter 5800, train entropy gap 1.9558 bits (loss 21.503, data 19.548) 0.00044 lr
Epoch 25 Iter 6000, train entropy gap 1.9810 bits (loss 21.529, data 19.548) 0.00044 lr
epoch 25 train loss 14.7366 nats / 21.2604 bits
time since start: 3662.0 secs
Epoch 26 Iter 0, train entropy gap 1.9941 bits (loss 21.542, data 19.548) 0.00044 lr
Epoch 26 Iter 200, train entropy gap 1.8199 bits (loss 21.368, data 19.548) 0.00044 lr
Epoch 26 Iter 400, train entropy gap 1.6636 bits (loss 21.211, data 19.548) 0.00044 lr
Epoch 26 Iter 600, train entropy gap 1.5148 bits (loss 21.062, data 19.548) 0.00044 lr
Epoch 26 Iter 800, train entropy gap 1.2790 bits (loss 20.827, data 19.548) 0.00044 lr
Epoch 26 Iter 1000, train entropy gap 1.3570 bits (loss 20.905, data 19.548) 0.00044 lr
Epoch 26 Iter 1200, train entropy gap 1.1304 bits (loss 20.678, data 19.548) 0.00044 lr
Epoch 26 Iter 1400, train entropy gap 1.4704 bits (loss 21.018, data 19.548) 0.00044 lr
Epoch 26 Iter 1600, train entropy gap 1.3470 bits (loss 20.895, data 19.548) 0.00044 lr
Epoch 26 Iter 1800, train entropy gap 1.7701 bits (loss 21.318, data 19.548) 0.00044 lr
Epoch 26 Iter 2000, train entropy gap 2.0159 bits (loss 21.564, data 19.548) 0.00044 lr
Epoch 26 Iter 2200, train entropy gap 1.4435 bits (loss 20.991, data 19.548) 0.00044 lr
Epoch 26 Iter 2400, train entropy gap 1.3009 bits (loss 20.849, data 19.548) 0.00044 lr
Epoch 26 Iter 2600, train entropy gap 1.7799 bits (loss 21.328, data 19.548) 0.00044 lr
Epoch 26 Iter 2800, train entropy gap 1.8060 bits (loss 21.354, data 19.548) 0.00044 lr
Epoch 26 Iter 3000, train entropy gap 2.2417 bits (loss 21.789, data 19.548) 0.00044 lr
Epoch 26 Iter 3200, train entropy gap 1.3554 bits (loss 20.903, data 19.548) 0.00044 lr
Epoch 26 Iter 3400, train entropy gap 2.1085 bits (loss 21.656, data 19.548) 0.00044 lr
Epoch 26 Iter 3600, train entropy gap 1.8922 bits (loss 21.440, data 19.548) 0.00044 lr
Epoch 26 Iter 3800, train entropy gap 1.8595 bits (loss 21.407, data 19.548) 0.00044 lr
Epoch 26 Iter 4000, train entropy gap 1.9749 bits (loss 21.523, data 19.548) 0.00044 lr
Epoch 26 Iter 4200, train entropy gap 0.9262 bits (loss 20.474, data 19.548) 0.00044 lr
Epoch 26 Iter 4400, train entropy gap 2.1420 bits (loss 21.690, data 19.548) 0.00044 lr
Epoch 26 Iter 4600, train entropy gap 1.1940 bits (loss 20.742, data 19.548) 0.00044 lr
Epoch 26 Iter 4800, train entropy gap 1.2210 bits (loss 20.769, data 19.548) 0.00044 lr
Epoch 26 Iter 5000, train entropy gap 1.7226 bits (loss 21.270, data 19.548) 0.00043 lr
Epoch 26 Iter 5200, train entropy gap 1.9764 bits (loss 21.524, data 19.548) 0.00043 lr
Epoch 26 Iter 5400, train entropy gap 1.4554 bits (loss 21.003, data 19.548) 0.00043 lr
Epoch 26 Iter 5600, train entropy gap 1.6990 bits (loss 21.247, data 19.548) 0.00043 lr
Epoch 26 Iter 5800, train entropy gap 0.7207 bits (loss 20.268, data 19.548) 0.00043 lr
Epoch 26 Iter 6000, train entropy gap 1.7506 bits (loss 21.298, data 19.548) 0.00043 lr
epoch 26 train loss 14.7351 nats / 21.2583 bits
time since start: 3802.9 secs
Epoch 27 Iter 0, train entropy gap 3.2803 bits (loss 22.828, data 19.548) 0.00043 lr
Epoch 27 Iter 200, train entropy gap 1.3628 bits (loss 20.910, data 19.548) 0.00043 lr
Epoch 27 Iter 400, train entropy gap 1.5352 bits (loss 21.083, data 19.548) 0.00043 lr
Epoch 27 Iter 600, train entropy gap 2.7010 bits (loss 22.249, data 19.548) 0.00043 lr
Epoch 27 Iter 800, train entropy gap 2.3151 bits (loss 21.863, data 19.548) 0.00043 lr
Epoch 27 Iter 1000, train entropy gap 1.6174 bits (loss 21.165, data 19.548) 0.00043 lr
Epoch 27 Iter 1200, train entropy gap 1.5970 bits (loss 21.145, data 19.548) 0.00043 lr
Epoch 27 Iter 1400, train entropy gap 1.1049 bits (loss 20.653, data 19.548) 0.00043 lr
Epoch 27 Iter 1600, train entropy gap 0.9863 bits (loss 20.534, data 19.548) 0.00043 lr
Epoch 27 Iter 1800, train entropy gap 1.3428 bits (loss 20.891, data 19.548) 0.00043 lr
Epoch 27 Iter 2000, train entropy gap 2.5304 bits (loss 22.078, data 19.548) 0.00043 lr
Epoch 27 Iter 2200, train entropy gap 1.4363 bits (loss 20.984, data 19.548) 0.00043 lr
Epoch 27 Iter 2400, train entropy gap 1.5581 bits (loss 21.106, data 19.548) 0.00043 lr
Epoch 27 Iter 2600, train entropy gap 1.4561 bits (loss 21.004, data 19.548) 0.00043 lr
Epoch 27 Iter 2800, train entropy gap 1.8504 bits (loss 21.398, data 19.548) 0.00043 lr
Epoch 27 Iter 3000, train entropy gap 2.6935 bits (loss 22.241, data 19.548) 0.00043 lr
Epoch 27 Iter 3200, train entropy gap 0.7377 bits (loss 20.285, data 19.548) 0.00043 lr
Epoch 27 Iter 3400, train entropy gap 1.7989 bits (loss 21.347, data 19.548) 0.00043 lr
Epoch 27 Iter 3600, train entropy gap 1.4248 bits (loss 20.972, data 19.548) 0.00043 lr
Epoch 27 Iter 3800, train entropy gap 2.6772 bits (loss 22.225, data 19.548) 0.00043 lr
Epoch 27 Iter 4000, train entropy gap 1.1396 bits (loss 20.687, data 19.548) 0.00043 lr
Epoch 27 Iter 4200, train entropy gap 1.6955 bits (loss 21.243, data 19.548) 0.00043 lr
Epoch 27 Iter 4400, train entropy gap 2.3485 bits (loss 21.896, data 19.548) 0.00043 lr
Epoch 27 Iter 4600, train entropy gap 1.9936 bits (loss 21.541, data 19.548) 0.00043 lr
Epoch 27 Iter 4800, train entropy gap 1.2952 bits (loss 20.843, data 19.548) 0.00043 lr
Epoch 27 Iter 5000, train entropy gap 2.0147 bits (loss 21.562, data 19.548) 0.00043 lr
Epoch 27 Iter 5200, train entropy gap 1.3841 bits (loss 20.932, data 19.548) 0.00043 lr
Epoch 27 Iter 5400, train entropy gap 2.5415 bits (loss 22.089, data 19.548) 0.00043 lr
Epoch 27 Iter 5600, train entropy gap 1.9731 bits (loss 21.521, data 19.548) 0.00043 lr
Epoch 27 Iter 5800, train entropy gap 1.6860 bits (loss 21.234, data 19.548) 0.00043 lr
Epoch 27 Iter 6000, train entropy gap 1.9479 bits (loss 21.496, data 19.548) 0.00043 lr
epoch 27 train loss 14.7327 nats / 21.2548 bits
time since start: 3943.4 secs
Epoch 28 Iter 0, train entropy gap 1.5488 bits (loss 21.097, data 19.548) 0.00043 lr
Epoch 28 Iter 200, train entropy gap 2.5662 bits (loss 22.114, data 19.548) 0.00043 lr
Epoch 28 Iter 400, train entropy gap 2.0558 bits (loss 21.604, data 19.548) 0.00043 lr
Epoch 28 Iter 600, train entropy gap 2.3044 bits (loss 21.852, data 19.548) 0.00042 lr
Epoch 28 Iter 800, train entropy gap 1.4603 bits (loss 21.008, data 19.548) 0.00042 lr
Epoch 28 Iter 1000, train entropy gap 2.1410 bits (loss 21.689, data 19.548) 0.00042 lr
Epoch 28 Iter 1200, train entropy gap 2.0928 bits (loss 21.641, data 19.548) 0.00042 lr
Epoch 28 Iter 1400, train entropy gap 1.3982 bits (loss 20.946, data 19.548) 0.00042 lr
Epoch 28 Iter 1600, train entropy gap 1.4747 bits (loss 21.022, data 19.548) 0.00042 lr
Epoch 28 Iter 1800, train entropy gap 1.3223 bits (loss 20.870, data 19.548) 0.00042 lr
Epoch 28 Iter 2000, train entropy gap 1.3204 bits (loss 20.868, data 19.548) 0.00042 lr
Epoch 28 Iter 2200, train entropy gap 1.3911 bits (loss 20.939, data 19.548) 0.00042 lr
Epoch 28 Iter 2400, train entropy gap 1.7791 bits (loss 21.327, data 19.548) 0.00042 lr
Epoch 28 Iter 2600, train entropy gap 1.4588 bits (loss 21.007, data 19.548) 0.00042 lr
Epoch 28 Iter 2800, train entropy gap 1.6917 bits (loss 21.239, data 19.548) 0.00042 lr
Epoch 28 Iter 3000, train entropy gap 1.2060 bits (loss 20.754, data 19.548) 0.00042 lr
Epoch 28 Iter 3200, train entropy gap 2.0091 bits (loss 21.557, data 19.548) 0.00042 lr
Epoch 28 Iter 3400, train entropy gap 1.9460 bits (loss 21.494, data 19.548) 0.00042 lr
Epoch 28 Iter 3600, train entropy gap 1.3900 bits (loss 20.938, data 19.548) 0.00042 lr
Epoch 28 Iter 3800, train entropy gap 1.5963 bits (loss 21.144, data 19.548) 0.00042 lr
Epoch 28 Iter 4000, train entropy gap 2.4687 bits (loss 22.016, data 19.548) 0.00042 lr
Epoch 28 Iter 4200, train entropy gap 2.1726 bits (loss 21.720, data 19.548) 0.00042 lr
Epoch 28 Iter 4400, train entropy gap 1.3874 bits (loss 20.935, data 19.548) 0.00042 lr
Epoch 28 Iter 4600, train entropy gap 1.6514 bits (loss 21.199, data 19.548) 0.00042 lr
Epoch 28 Iter 4800, train entropy gap 1.2232 bits (loss 20.771, data 19.548) 0.00042 lr
Epoch 28 Iter 5000, train entropy gap 1.5500 bits (loss 21.098, data 19.548) 0.00042 lr
Epoch 28 Iter 5200, train entropy gap 3.0530 bits (loss 22.601, data 19.548) 0.00042 lr
Epoch 28 Iter 5400, train entropy gap 2.6298 bits (loss 22.178, data 19.548) 0.00042 lr
Epoch 28 Iter 5600, train entropy gap 1.9433 bits (loss 21.491, data 19.548) 0.00042 lr
Epoch 28 Iter 5800, train entropy gap 1.2929 bits (loss 20.841, data 19.548) 0.00042 lr
Epoch 28 Iter 6000, train entropy gap 0.9179 bits (loss 20.466, data 19.548) 0.00042 lr
epoch 28 train loss 14.7352 nats / 21.2584 bits
time since start: 4083.8 secs
Epoch 29 Iter 0, train entropy gap 1.7979 bits (loss 21.346, data 19.548) 0.00042 lr
Epoch 29 Iter 200, train entropy gap 1.4894 bits (loss 21.037, data 19.548) 0.00042 lr
Epoch 29 Iter 400, train entropy gap 3.2744 bits (loss 22.822, data 19.548) 0.00042 lr
Epoch 29 Iter 600, train entropy gap 1.5583 bits (loss 21.106, data 19.548) 0.00042 lr
Epoch 29 Iter 800, train entropy gap 2.4061 bits (loss 21.954, data 19.548) 0.00042 lr
Epoch 29 Iter 1000, train entropy gap 2.3713 bits (loss 21.919, data 19.548) 0.00042 lr
Epoch 29 Iter 1200, train entropy gap 1.7777 bits (loss 21.325, data 19.548) 0.00042 lr
Epoch 29 Iter 1400, train entropy gap 2.8019 bits (loss 22.350, data 19.548) 0.00042 lr
Epoch 29 Iter 1600, train entropy gap 1.4089 bits (loss 20.957, data 19.548) 0.00042 lr
Epoch 29 Iter 1800, train entropy gap 2.1178 bits (loss 21.666, data 19.548) 0.00042 lr
Epoch 29 Iter 2000, train entropy gap 2.0514 bits (loss 21.599, data 19.548) 0.00042 lr
Epoch 29 Iter 2200, train entropy gap 1.8053 bits (loss 21.353, data 19.548) 0.00042 lr
Epoch 29 Iter 2400, train entropy gap 1.8248 bits (loss 21.372, data 19.548) 0.00042 lr
Epoch 29 Iter 2600, train entropy gap 1.3975 bits (loss 20.945, data 19.548) 0.00042 lr
Epoch 29 Iter 2800, train entropy gap 1.2810 bits (loss 20.829, data 19.548) 0.00041 lr
Epoch 29 Iter 3000, train entropy gap 3.0758 bits (loss 22.624, data 19.548) 0.00041 lr
Epoch 29 Iter 3200, train entropy gap 2.3246 bits (loss 21.872, data 19.548) 0.00041 lr
Epoch 29 Iter 3400, train entropy gap 1.2475 bits (loss 20.795, data 19.548) 0.00041 lr
Epoch 29 Iter 3600, train entropy gap 1.2188 bits (loss 20.767, data 19.548) 0.00041 lr
Epoch 29 Iter 3800, train entropy gap 1.6966 bits (loss 21.244, data 19.548) 0.00041 lr
Epoch 29 Iter 4000, train entropy gap 1.1284 bits (loss 20.676, data 19.548) 0.00041 lr
Epoch 29 Iter 4200, train entropy gap 2.0052 bits (loss 21.553, data 19.548) 0.00041 lr
Epoch 29 Iter 4400, train entropy gap 2.9567 bits (loss 22.504, data 19.548) 0.00041 lr
Epoch 29 Iter 4600, train entropy gap 1.2763 bits (loss 20.824, data 19.548) 0.00041 lr
Epoch 29 Iter 4800, train entropy gap 2.2731 bits (loss 21.821, data 19.548) 0.00041 lr
Epoch 29 Iter 5000, train entropy gap 1.6384 bits (loss 21.186, data 19.548) 0.00041 lr
Epoch 29 Iter 5200, train entropy gap 2.2171 bits (loss 21.765, data 19.548) 0.00041 lr
Epoch 29 Iter 5400, train entropy gap 2.3368 bits (loss 21.884, data 19.548) 0.00041 lr
Epoch 29 Iter 5600, train entropy gap 2.0384 bits (loss 21.586, data 19.548) 0.00041 lr
Epoch 29 Iter 5800, train entropy gap 1.8980 bits (loss 21.446, data 19.548) 0.00041 lr
Epoch 29 Iter 6000, train entropy gap 1.3712 bits (loss 20.919, data 19.548) 0.00041 lr
epoch 29 train loss 14.7286 nats / 21.2489 bits
time since start: 4225.0 secs
Epoch 30 Iter 0, train entropy gap 1.9931 bits (loss 21.541, data 19.548) 0.00041 lr
Epoch 30 Iter 200, train entropy gap 0.8081 bits (loss 20.356, data 19.548) 0.00041 lr
Epoch 30 Iter 400, train entropy gap 0.9118 bits (loss 20.459, data 19.548) 0.00041 lr
Epoch 30 Iter 600, train entropy gap 1.1847 bits (loss 20.732, data 19.548) 0.00041 lr
Epoch 30 Iter 800, train entropy gap 0.8578 bits (loss 20.406, data 19.548) 0.00041 lr
Epoch 30 Iter 1000, train entropy gap 1.1981 bits (loss 20.746, data 19.548) 0.00041 lr
Epoch 30 Iter 1200, train entropy gap 1.2889 bits (loss 20.837, data 19.548) 0.00041 lr
Epoch 30 Iter 1400, train entropy gap 1.9248 bits (loss 21.473, data 19.548) 0.00041 lr
Epoch 30 Iter 1600, train entropy gap 2.1184 bits (loss 21.666, data 19.548) 0.00041 lr
Epoch 30 Iter 1800, train entropy gap 1.2647 bits (loss 20.812, data 19.548) 0.00041 lr
Epoch 30 Iter 2000, train entropy gap 1.3833 bits (loss 20.931, data 19.548) 0.00041 lr
Epoch 30 Iter 2200, train entropy gap 2.1194 bits (loss 21.667, data 19.548) 0.00041 lr
Epoch 30 Iter 2400, train entropy gap 2.3984 bits (loss 21.946, data 19.548) 0.00041 lr
Epoch 30 Iter 2600, train entropy gap 1.9681 bits (loss 21.516, data 19.548) 0.00041 lr
Epoch 30 Iter 2800, train entropy gap 1.2676 bits (loss 20.815, data 19.548) 0.00041 lr
Epoch 30 Iter 3000, train entropy gap 1.6017 bits (loss 21.149, data 19.548) 0.00041 lr
Epoch 30 Iter 3200, train entropy gap 1.6568 bits (loss 21.205, data 19.548) 0.00041 lr
Epoch 30 Iter 3400, train entropy gap 2.1919 bits (loss 21.740, data 19.548) 0.00041 lr
Epoch 30 Iter 3600, train entropy gap 2.6018 bits (loss 22.150, data 19.548) 0.00041 lr
Epoch 30 Iter 3800, train entropy gap 1.5270 bits (loss 21.075, data 19.548) 0.00041 lr
Epoch 30 Iter 4000, train entropy gap 1.4649 bits (loss 21.013, data 19.548) 0.00041 lr
Epoch 30 Iter 4200, train entropy gap 1.7811 bits (loss 21.329, data 19.548) 0.00041 lr
Epoch 30 Iter 4400, train entropy gap 1.6762 bits (loss 21.224, data 19.548) 0.00041 lr
Epoch 30 Iter 4600, train entropy gap 1.7241 bits (loss 21.272, data 19.548) 0.00041 lr
Epoch 30 Iter 4800, train entropy gap 1.3251 bits (loss 20.873, data 19.548) 0.00041 lr
Epoch 30 Iter 5000, train entropy gap 1.4002 bits (loss 20.948, data 19.548) 0.00041 lr
Epoch 30 Iter 5200, train entropy gap 2.4897 bits (loss 22.037, data 19.548) 0.00041 lr
Epoch 30 Iter 5400, train entropy gap 1.3177 bits (loss 20.865, data 19.548) 0.00041 lr
Epoch 30 Iter 5600, train entropy gap 1.6121 bits (loss 21.160, data 19.548) 0.00041 lr
Epoch 30 Iter 5800, train entropy gap 1.2022 bits (loss 20.750, data 19.548) 0.00040 lr
Epoch 30 Iter 6000, train entropy gap 1.6553 bits (loss 21.203, data 19.548) 0.00040 lr
epoch 30 train loss 14.7329 nats / 21.2551 bits
time since start: 4366.1 secs
Epoch 31 Iter 0, train entropy gap 1.4270 bits (loss 20.975, data 19.548) 0.00040 lr
Epoch 31 Iter 200, train entropy gap 2.1652 bits (loss 21.713, data 19.548) 0.00040 lr
Epoch 31 Iter 400, train entropy gap 1.3677 bits (loss 20.915, data 19.548) 0.00040 lr
Epoch 31 Iter 600, train entropy gap 0.7967 bits (loss 20.344, data 19.548) 0.00040 lr
Epoch 31 Iter 800, train entropy gap 1.0445 bits (loss 20.592, data 19.548) 0.00040 lr
Epoch 31 Iter 1000, train entropy gap 2.2492 bits (loss 21.797, data 19.548) 0.00040 lr
Epoch 31 Iter 1200, train entropy gap 2.7854 bits (loss 22.333, data 19.548) 0.00040 lr
Epoch 31 Iter 1400, train entropy gap 2.0347 bits (loss 21.582, data 19.548) 0.00040 lr
Epoch 31 Iter 1600, train entropy gap 1.9548 bits (loss 21.503, data 19.548) 0.00040 lr
Epoch 31 Iter 1800, train entropy gap 1.5084 bits (loss 21.056, data 19.548) 0.00040 lr
Epoch 31 Iter 2000, train entropy gap 1.5053 bits (loss 21.053, data 19.548) 0.00040 lr
Epoch 31 Iter 2200, train entropy gap 2.3149 bits (loss 21.863, data 19.548) 0.00040 lr
Epoch 31 Iter 2400, train entropy gap 1.6906 bits (loss 21.238, data 19.548) 0.00040 lr
Epoch 31 Iter 2600, train entropy gap 1.3374 bits (loss 20.885, data 19.548) 0.00040 lr
Epoch 31 Iter 2800, train entropy gap 1.6570 bits (loss 21.205, data 19.548) 0.00040 lr
Epoch 31 Iter 3000, train entropy gap 1.4363 bits (loss 20.984, data 19.548) 0.00040 lr
Epoch 31 Iter 3200, train entropy gap 1.7885 bits (loss 21.336, data 19.548) 0.00040 lr
Epoch 31 Iter 3400, train entropy gap 2.0211 bits (loss 21.569, data 19.548) 0.00040 lr
Epoch 31 Iter 3600, train entropy gap 2.0725 bits (loss 21.620, data 19.548) 0.00040 lr
Epoch 31 Iter 3800, train entropy gap 1.3129 bits (loss 20.861, data 19.548) 0.00040 lr
Epoch 31 Iter 4000, train entropy gap 1.2647 bits (loss 20.812, data 19.548) 0.00040 lr
Epoch 31 Iter 4200, train entropy gap 0.6949 bits (loss 20.243, data 19.548) 0.00040 lr
Epoch 31 Iter 4400, train entropy gap 0.9773 bits (loss 20.525, data 19.548) 0.00040 lr
Epoch 31 Iter 4600, train entropy gap 1.2655 bits (loss 20.813, data 19.548) 0.00040 lr
Epoch 31 Iter 4800, train entropy gap 1.5788 bits (loss 21.127, data 19.548) 0.00040 lr
Epoch 31 Iter 5000, train entropy gap 1.7200 bits (loss 21.268, data 19.548) 0.00040 lr
Epoch 31 Iter 5200, train entropy gap 0.7571 bits (loss 20.305, data 19.548) 0.00040 lr
Epoch 31 Iter 5400, train entropy gap 1.3153 bits (loss 20.863, data 19.548) 0.00040 lr
Epoch 31 Iter 5600, train entropy gap 1.4270 bits (loss 20.975, data 19.548) 0.00040 lr
Epoch 31 Iter 5800, train entropy gap 0.9925 bits (loss 20.540, data 19.548) 0.00040 lr
Epoch 31 Iter 6000, train entropy gap 1.5721 bits (loss 21.120, data 19.548) 0.00040 lr
epoch 31 train loss 14.7349 nats / 21.2579 bits
time since start: 4507.3 secs
Epoch 32 Iter 0, train entropy gap 1.1021 bits (loss 20.650, data 19.548) 0.00040 lr
Epoch 32 Iter 200, train entropy gap 1.4704 bits (loss 21.018, data 19.548) 0.00040 lr
Epoch 32 Iter 400, train entropy gap 1.6616 bits (loss 21.209, data 19.548) 0.00040 lr
Epoch 32 Iter 600, train entropy gap 1.3844 bits (loss 20.932, data 19.548) 0.00040 lr
Epoch 32 Iter 800, train entropy gap 2.9731 bits (loss 22.521, data 19.548) 0.00040 lr
Epoch 32 Iter 1000, train entropy gap 1.5515 bits (loss 21.099, data 19.548) 0.00040 lr
Epoch 32 Iter 1200, train entropy gap 1.7515 bits (loss 21.299, data 19.548) 0.00040 lr
Epoch 32 Iter 1400, train entropy gap 1.0766 bits (loss 20.624, data 19.548) 0.00040 lr
Epoch 32 Iter 1600, train entropy gap 2.6876 bits (loss 22.235, data 19.548) 0.00040 lr
Epoch 32 Iter 1800, train entropy gap 2.1699 bits (loss 21.718, data 19.548) 0.00040 lr
Epoch 32 Iter 2000, train entropy gap 1.4818 bits (loss 21.030, data 19.548) 0.00040 lr
Epoch 32 Iter 2200, train entropy gap 1.3807 bits (loss 20.928, data 19.548) 0.00040 lr
Epoch 32 Iter 2400, train entropy gap 2.6243 bits (loss 22.172, data 19.548) 0.00040 lr
Epoch 32 Iter 2600, train entropy gap 2.4842 bits (loss 22.032, data 19.548) 0.00040 lr
Epoch 32 Iter 2800, train entropy gap 1.3660 bits (loss 20.914, data 19.548) 0.00040 lr
Epoch 32 Iter 3000, train entropy gap 1.8586 bits (loss 21.406, data 19.548) 0.00040 lr
Epoch 32 Iter 3200, train entropy gap 1.3399 bits (loss 20.888, data 19.548) 0.00039 lr
Epoch 32 Iter 3400, train entropy gap 0.8640 bits (loss 20.412, data 19.548) 0.00039 lr
Epoch 32 Iter 3600, train entropy gap 0.9798 bits (loss 20.528, data 19.548) 0.00039 lr
Epoch 32 Iter 3800, train entropy gap 1.7751 bits (loss 21.323, data 19.548) 0.00039 lr
Epoch 32 Iter 4000, train entropy gap 0.8559 bits (loss 20.404, data 19.548) 0.00039 lr
Epoch 32 Iter 4200, train entropy gap 2.2394 bits (loss 21.787, data 19.548) 0.00039 lr
Epoch 32 Iter 4400, train entropy gap 1.7465 bits (loss 21.294, data 19.548) 0.00039 lr
Epoch 32 Iter 4600, train entropy gap 2.1161 bits (loss 21.664, data 19.548) 0.00039 lr
Epoch 32 Iter 4800, train entropy gap 2.1136 bits (loss 21.661, data 19.548) 0.00039 lr
Epoch 32 Iter 5000, train entropy gap 1.3960 bits (loss 20.944, data 19.548) 0.00039 lr
Epoch 32 Iter 5200, train entropy gap 2.5275 bits (loss 22.075, data 19.548) 0.00039 lr
Epoch 32 Iter 5400, train entropy gap 1.9411 bits (loss 21.489, data 19.548) 0.00039 lr
Epoch 32 Iter 5600, train entropy gap 1.1874 bits (loss 20.735, data 19.548) 0.00039 lr
Epoch 32 Iter 5800, train entropy gap 1.3425 bits (loss 20.890, data 19.548) 0.00039 lr
Epoch 32 Iter 6000, train entropy gap 2.0958 bits (loss 21.644, data 19.548) 0.00039 lr
epoch 32 train loss 14.7361 nats / 21.2597 bits
time since start: 4648.1 secs
Epoch 33 Iter 0, train entropy gap 1.6886 bits (loss 21.236, data 19.548) 0.00039 lr
Epoch 33 Iter 200, train entropy gap 1.6250 bits (loss 21.173, data 19.548) 0.00039 lr
Epoch 33 Iter 400, train entropy gap 1.5162 bits (loss 21.064, data 19.548) 0.00039 lr
Epoch 33 Iter 600, train entropy gap 1.4497 bits (loss 20.997, data 19.548) 0.00039 lr
Epoch 33 Iter 800, train entropy gap 1.3966 bits (loss 20.944, data 19.548) 0.00039 lr
Epoch 33 Iter 1000, train entropy gap 1.2121 bits (loss 20.760, data 19.548) 0.00039 lr
Epoch 33 Iter 1200, train entropy gap 1.9010 bits (loss 21.449, data 19.548) 0.00039 lr
Epoch 33 Iter 1400, train entropy gap 2.3482 bits (loss 21.896, data 19.548) 0.00039 lr
Epoch 33 Iter 1600, train entropy gap 1.6763 bits (loss 21.224, data 19.548) 0.00039 lr
Epoch 33 Iter 1800, train entropy gap 2.3982 bits (loss 21.946, data 19.548) 0.00039 lr
Epoch 33 Iter 2000, train entropy gap 1.0991 bits (loss 20.647, data 19.548) 0.00039 lr
Epoch 33 Iter 2200, train entropy gap 2.1468 bits (loss 21.695, data 19.548) 0.00039 lr
Epoch 33 Iter 2400, train entropy gap 1.2529 bits (loss 20.801, data 19.548) 0.00039 lr
Epoch 33 Iter 2600, train entropy gap 2.4232 bits (loss 21.971, data 19.548) 0.00039 lr
Epoch 33 Iter 2800, train entropy gap 1.3762 bits (loss 20.924, data 19.548) 0.00039 lr
Epoch 33 Iter 3000, train entropy gap 1.5669 bits (loss 21.115, data 19.548) 0.00039 lr
Epoch 33 Iter 3200, train entropy gap 1.8471 bits (loss 21.395, data 19.548) 0.00039 lr
Epoch 33 Iter 3400, train entropy gap 1.5142 bits (loss 21.062, data 19.548) 0.00039 lr
Epoch 33 Iter 3600, train entropy gap 0.9992 bits (loss 20.547, data 19.548) 0.00039 lr
Epoch 33 Iter 3800, train entropy gap 2.2623 bits (loss 21.810, data 19.548) 0.00039 lr
Epoch 33 Iter 4000, train entropy gap 2.1140 bits (loss 21.662, data 19.548) 0.00039 lr
Epoch 33 Iter 4200, train entropy gap 2.0528 bits (loss 21.601, data 19.548) 0.00039 lr
Epoch 33 Iter 4400, train entropy gap 1.4857 bits (loss 21.033, data 19.548) 0.00039 lr
Epoch 33 Iter 4600, train entropy gap 2.0072 bits (loss 21.555, data 19.548) 0.00039 lr
Epoch 33 Iter 4800, train entropy gap 1.3714 bits (loss 20.919, data 19.548) 0.00039 lr
Epoch 33 Iter 5000, train entropy gap 1.3835 bits (loss 20.931, data 19.548) 0.00039 lr
Epoch 33 Iter 5200, train entropy gap 1.3967 bits (loss 20.944, data 19.548) 0.00039 lr
Epoch 33 Iter 5400, train entropy gap 1.5271 bits (loss 21.075, data 19.548) 0.00039 lr
Epoch 33 Iter 5600, train entropy gap 2.7722 bits (loss 22.320, data 19.548) 0.00039 lr
Epoch 33 Iter 5800, train entropy gap 0.8007 bits (loss 20.348, data 19.548) 0.00039 lr
Epoch 33 Iter 6000, train entropy gap 1.3631 bits (loss 20.911, data 19.548) 0.00039 lr
epoch 33 train loss 14.7340 nats / 21.2566 bits
time since start: 4789.1 secs
Epoch 34 Iter 0, train entropy gap 2.1500 bits (loss 21.698, data 19.548) 0.00039 lr
Epoch 34 Iter 200, train entropy gap 1.2320 bits (loss 20.780, data 19.548) 0.00039 lr
Epoch 34 Iter 400, train entropy gap 0.8488 bits (loss 20.396, data 19.548) 0.00039 lr
Epoch 34 Iter 600, train entropy gap 1.3943 bits (loss 20.942, data 19.548) 0.00039 lr
Epoch 34 Iter 800, train entropy gap 1.3528 bits (loss 20.901, data 19.548) 0.00039 lr
Epoch 34 Iter 1000, train entropy gap 1.8753 bits (loss 21.423, data 19.548) 0.00039 lr
Epoch 34 Iter 1200, train entropy gap 1.5231 bits (loss 21.071, data 19.548) 0.00039 lr
Epoch 34 Iter 1400, train entropy gap 1.2771 bits (loss 20.825, data 19.548) 0.00038 lr
Epoch 34 Iter 1600, train entropy gap 1.4514 bits (loss 20.999, data 19.548) 0.00038 lr
Epoch 34 Iter 1800, train entropy gap 1.4517 bits (loss 20.999, data 19.548) 0.00038 lr
Epoch 34 Iter 2000, train entropy gap 2.8642 bits (loss 22.412, data 19.548) 0.00038 lr
Epoch 34 Iter 2200, train entropy gap 2.2728 bits (loss 21.820, data 19.548) 0.00038 lr
Epoch 34 Iter 2400, train entropy gap 1.5262 bits (loss 21.074, data 19.548) 0.00038 lr
Epoch 34 Iter 2600, train entropy gap 1.5335 bits (loss 21.081, data 19.548) 0.00038 lr
Epoch 34 Iter 2800, train entropy gap 1.3942 bits (loss 20.942, data 19.548) 0.00038 lr
Epoch 34 Iter 3000, train entropy gap 1.4848 bits (loss 21.033, data 19.548) 0.00038 lr
Epoch 34 Iter 3200, train entropy gap 1.8970 bits (loss 21.445, data 19.548) 0.00038 lr
Epoch 34 Iter 3400, train entropy gap 2.2079 bits (loss 21.756, data 19.548) 0.00038 lr
Epoch 34 Iter 3600, train entropy gap 1.2083 bits (loss 20.756, data 19.548) 0.00038 lr
Epoch 34 Iter 3800, train entropy gap 1.4061 bits (loss 20.954, data 19.548) 0.00038 lr
Epoch 34 Iter 4000, train entropy gap 1.3721 bits (loss 20.920, data 19.548) 0.00038 lr
Epoch 34 Iter 4200, train entropy gap 2.0787 bits (loss 21.626, data 19.548) 0.00038 lr
Epoch 34 Iter 4400, train entropy gap 0.9114 bits (loss 20.459, data 19.548) 0.00038 lr
Epoch 34 Iter 4600, train entropy gap 2.2064 bits (loss 21.754, data 19.548) 0.00038 lr
Epoch 34 Iter 4800, train entropy gap 2.2631 bits (loss 21.811, data 19.548) 0.00038 lr
Epoch 34 Iter 5000, train entropy gap 2.0012 bits (loss 21.549, data 19.548) 0.00038 lr
Epoch 34 Iter 5200, train entropy gap 1.6068 bits (loss 21.155, data 19.548) 0.00038 lr
Epoch 34 Iter 5400, train entropy gap 1.7692 bits (loss 21.317, data 19.548) 0.00038 lr
Epoch 34 Iter 5600, train entropy gap 1.1869 bits (loss 20.735, data 19.548) 0.00038 lr
Epoch 34 Iter 5800, train entropy gap 0.9637 bits (loss 20.511, data 19.548) 0.00038 lr
Epoch 34 Iter 6000, train entropy gap 1.2959 bits (loss 20.844, data 19.548) 0.00038 lr
epoch 34 train loss 14.7373 nats / 21.2614 bits
time since start: 4929.6 secs
Epoch 35 Iter 0, train entropy gap 2.1805 bits (loss 21.728, data 19.548) 0.00038 lr
Epoch 35 Iter 200, train entropy gap 1.7656 bits (loss 21.313, data 19.548) 0.00038 lr
Epoch 35 Iter 400, train entropy gap 2.0273 bits (loss 21.575, data 19.548) 0.00038 lr
Epoch 35 Iter 600, train entropy gap 1.8282 bits (loss 21.376, data 19.548) 0.00038 lr
Epoch 35 Iter 800, train entropy gap 2.0384 bits (loss 21.586, data 19.548) 0.00038 lr
Epoch 35 Iter 1000, train entropy gap 0.9456 bits (loss 20.493, data 19.548) 0.00038 lr
Epoch 35 Iter 1200, train entropy gap 2.6884 bits (loss 22.236, data 19.548) 0.00038 lr
Epoch 35 Iter 1400, train entropy gap 2.7241 bits (loss 22.272, data 19.548) 0.00038 lr
Epoch 35 Iter 1600, train entropy gap 1.7786 bits (loss 21.326, data 19.548) 0.00038 lr
Epoch 35 Iter 1800, train entropy gap 1.5275 bits (loss 21.075, data 19.548) 0.00038 lr
Epoch 35 Iter 2000, train entropy gap 1.5873 bits (loss 21.135, data 19.548) 0.00038 lr
Epoch 35 Iter 2200, train entropy gap 3.1662 bits (loss 22.714, data 19.548) 0.00038 lr
Epoch 35 Iter 2400, train entropy gap 2.3527 bits (loss 21.900, data 19.548) 0.00038 lr
Epoch 35 Iter 2600, train entropy gap 2.4524 bits (loss 22.000, data 19.548) 0.00038 lr
Epoch 35 Iter 2800, train entropy gap 1.4130 bits (loss 20.961, data 19.548) 0.00038 lr
Epoch 35 Iter 3000, train entropy gap 1.1507 bits (loss 20.698, data 19.548) 0.00038 lr
Epoch 35 Iter 3200, train entropy gap 1.0837 bits (loss 20.631, data 19.548) 0.00038 lr
Epoch 35 Iter 3400, train entropy gap 1.3274 bits (loss 20.875, data 19.548) 0.00038 lr
Epoch 35 Iter 3600, train entropy gap 2.1309 bits (loss 21.679, data 19.548) 0.00038 lr
Epoch 35 Iter 3800, train entropy gap 1.5804 bits (loss 21.128, data 19.548) 0.00038 lr
Epoch 35 Iter 4000, train entropy gap 2.2210 bits (loss 21.769, data 19.548) 0.00038 lr
Epoch 35 Iter 4200, train entropy gap 1.4412 bits (loss 20.989, data 19.548) 0.00038 lr
Epoch 35 Iter 4400, train entropy gap 1.4431 bits (loss 20.991, data 19.548) 0.00038 lr
Epoch 35 Iter 4600, train entropy gap 2.2117 bits (loss 21.759, data 19.548) 0.00038 lr
Epoch 35 Iter 4800, train entropy gap 1.6654 bits (loss 21.213, data 19.548) 0.00038 lr
Epoch 35 Iter 5000, train entropy gap 1.4814 bits (loss 21.029, data 19.548) 0.00038 lr
Epoch 35 Iter 5200, train entropy gap 2.2065 bits (loss 21.754, data 19.548) 0.00038 lr
Epoch 35 Iter 5400, train entropy gap 2.2935 bits (loss 21.841, data 19.548) 0.00038 lr
Epoch 35 Iter 5600, train entropy gap 1.3094 bits (loss 20.857, data 19.548) 0.00038 lr
Epoch 35 Iter 5800, train entropy gap 3.1325 bits (loss 22.680, data 19.548) 0.00038 lr
Epoch 35 Iter 6000, train entropy gap 2.1714 bits (loss 21.719, data 19.548) 0.00038 lr
epoch 35 train loss 14.7358 nats / 21.2593 bits
time since start: 5070.5 secs
Epoch 36 Iter 0, train entropy gap 1.3483 bits (loss 20.896, data 19.548) 0.00038 lr
Epoch 36 Iter 200, train entropy gap 2.0017 bits (loss 21.549, data 19.548) 0.00038 lr
Epoch 36 Iter 400, train entropy gap 1.0192 bits (loss 20.567, data 19.548) 0.00037 lr
Epoch 36 Iter 600, train entropy gap 2.7177 bits (loss 22.265, data 19.548) 0.00037 lr
Epoch 36 Iter 800, train entropy gap 1.2171 bits (loss 20.765, data 19.548) 0.00037 lr
Epoch 36 Iter 1000, train entropy gap 1.9842 bits (loss 21.532, data 19.548) 0.00037 lr
Epoch 36 Iter 1200, train entropy gap 2.0666 bits (loss 21.614, data 19.548) 0.00037 lr
Epoch 36 Iter 1400, train entropy gap 1.2912 bits (loss 20.839, data 19.548) 0.00037 lr
Epoch 36 Iter 1600, train entropy gap 2.7759 bits (loss 22.324, data 19.548) 0.00037 lr
Epoch 36 Iter 1800, train entropy gap 1.4532 bits (loss 21.001, data 19.548) 0.00037 lr
Epoch 36 Iter 2000, train entropy gap 1.4381 bits (loss 20.986, data 19.548) 0.00037 lr
Epoch 36 Iter 2200, train entropy gap 1.8837 bits (loss 21.431, data 19.548) 0.00037 lr
Epoch 36 Iter 2400, train entropy gap 2.1178 bits (loss 21.665, data 19.548) 0.00037 lr
Epoch 36 Iter 2600, train entropy gap 2.1170 bits (loss 21.665, data 19.548) 0.00037 lr
Epoch 36 Iter 2800, train entropy gap 1.6831 bits (loss 21.231, data 19.548) 0.00037 lr
Epoch 36 Iter 3000, train entropy gap 1.4747 bits (loss 21.022, data 19.548) 0.00037 lr
Epoch 36 Iter 3200, train entropy gap 1.3405 bits (loss 20.888, data 19.548) 0.00037 lr
Epoch 36 Iter 3400, train entropy gap 1.6357 bits (loss 21.183, data 19.548) 0.00037 lr
Epoch 36 Iter 3600, train entropy gap 1.5671 bits (loss 21.115, data 19.548) 0.00037 lr
Epoch 36 Iter 3800, train entropy gap 2.0324 bits (loss 21.580, data 19.548) 0.00037 lr
Epoch 36 Iter 4000, train entropy gap 1.2219 bits (loss 20.770, data 19.548) 0.00037 lr
Epoch 36 Iter 4200, train entropy gap 2.2873 bits (loss 21.835, data 19.548) 0.00037 lr
Epoch 36 Iter 4400, train entropy gap 2.2700 bits (loss 21.818, data 19.548) 0.00037 lr
Epoch 36 Iter 4600, train entropy gap 2.1424 bits (loss 21.690, data 19.548) 0.00037 lr
Epoch 36 Iter 4800, train entropy gap 2.0743 bits (loss 21.622, data 19.548) 0.00037 lr
Epoch 36 Iter 5000, train entropy gap 2.6963 bits (loss 22.244, data 19.548) 0.00037 lr
Epoch 36 Iter 5200, train entropy gap 2.5503 bits (loss 22.098, data 19.548) 0.00037 lr
Epoch 36 Iter 5400, train entropy gap 1.0430 bits (loss 20.591, data 19.548) 0.00037 lr
Epoch 36 Iter 5600, train entropy gap 2.4977 bits (loss 22.045, data 19.548) 0.00037 lr
Epoch 36 Iter 5800, train entropy gap 1.2721 bits (loss 20.820, data 19.548) 0.00037 lr
Epoch 36 Iter 6000, train entropy gap 1.3983 bits (loss 20.946, data 19.548) 0.00037 lr
epoch 36 train loss 14.7315 nats / 21.2531 bits
time since start: 5211.3 secs
Epoch 37 Iter 0, train entropy gap 1.5248 bits (loss 21.073, data 19.548) 0.00037 lr
Epoch 37 Iter 200, train entropy gap 2.1368 bits (loss 21.685, data 19.548) 0.00037 lr
Epoch 37 Iter 400, train entropy gap 2.0118 bits (loss 21.560, data 19.548) 0.00037 lr
Epoch 37 Iter 600, train entropy gap 1.8850 bits (loss 21.433, data 19.548) 0.00037 lr
Epoch 37 Iter 800, train entropy gap 2.0054 bits (loss 21.553, data 19.548) 0.00037 lr
Epoch 37 Iter 1000, train entropy gap 0.8425 bits (loss 20.390, data 19.548) 0.00037 lr
Epoch 37 Iter 1200, train entropy gap 1.2103 bits (loss 20.758, data 19.548) 0.00037 lr
Epoch 37 Iter 1400, train entropy gap 1.1941 bits (loss 20.742, data 19.548) 0.00037 lr
Epoch 37 Iter 1600, train entropy gap 1.3977 bits (loss 20.945, data 19.548) 0.00037 lr
Epoch 37 Iter 1800, train entropy gap 1.7709 bits (loss 21.319, data 19.548) 0.00037 lr
Epoch 37 Iter 2000, train entropy gap 1.7203 bits (loss 21.268, data 19.548) 0.00037 lr
Epoch 37 Iter 2200, train entropy gap 1.5092 bits (loss 21.057, data 19.548) 0.00037 lr
Epoch 37 Iter 2400, train entropy gap 0.9740 bits (loss 20.522, data 19.548) 0.00037 lr
Epoch 37 Iter 2600, train entropy gap 2.4523 bits (loss 22.000, data 19.548) 0.00037 lr
Epoch 37 Iter 2800, train entropy gap 2.3116 bits (loss 21.859, data 19.548) 0.00037 lr
Epoch 37 Iter 3000, train entropy gap 1.8966 bits (loss 21.444, data 19.548) 0.00037 lr
Epoch 37 Iter 3200, train entropy gap 1.1699 bits (loss 20.718, data 19.548) 0.00037 lr
Epoch 37 Iter 3400, train entropy gap 2.0847 bits (loss 21.632, data 19.548) 0.00037 lr
Epoch 37 Iter 3600, train entropy gap 0.7399 bits (loss 20.288, data 19.548) 0.00037 lr
Epoch 37 Iter 3800, train entropy gap 0.9259 bits (loss 20.474, data 19.548) 0.00037 lr
Epoch 37 Iter 4000, train entropy gap 1.2097 bits (loss 20.757, data 19.548) 0.00037 lr
Epoch 37 Iter 4200, train entropy gap 2.3062 bits (loss 21.854, data 19.548) 0.00037 lr
Epoch 37 Iter 4400, train entropy gap 1.4158 bits (loss 20.963, data 19.548) 0.00037 lr
Epoch 37 Iter 4600, train entropy gap 1.0981 bits (loss 20.646, data 19.548) 0.00037 lr
Epoch 37 Iter 4800, train entropy gap 1.8488 bits (loss 21.396, data 19.548) 0.00037 lr
Epoch 37 Iter 5000, train entropy gap 1.8702 bits (loss 21.418, data 19.548) 0.00037 lr
Epoch 37 Iter 5200, train entropy gap 2.1998 bits (loss 21.747, data 19.548) 0.00037 lr
Epoch 37 Iter 5400, train entropy gap 2.0495 bits (loss 21.597, data 19.548) 0.00037 lr
Epoch 37 Iter 5600, train entropy gap 2.1614 bits (loss 21.709, data 19.548) 0.00037 lr
Epoch 37 Iter 5800, train entropy gap 1.4493 bits (loss 20.997, data 19.548) 0.00037 lr
Epoch 37 Iter 6000, train entropy gap 1.5515 bits (loss 21.099, data 19.548) 0.00037 lr
epoch 37 train loss 14.7336 nats / 21.2561 bits
time since start: 5352.3 secs
Epoch 38 Iter 0, train entropy gap 2.0732 bits (loss 21.621, data 19.548) 0.00037 lr
Epoch 38 Iter 200, train entropy gap 1.9133 bits (loss 21.461, data 19.548) 0.00037 lr
Epoch 38 Iter 400, train entropy gap 2.0047 bits (loss 21.552, data 19.548) 0.00036 lr
Epoch 38 Iter 600, train entropy gap 1.4080 bits (loss 20.956, data 19.548) 0.00036 lr
Epoch 38 Iter 800, train entropy gap 0.9159 bits (loss 20.464, data 19.548) 0.00036 lr
Epoch 38 Iter 1000, train entropy gap 2.1108 bits (loss 21.659, data 19.548) 0.00036 lr
Epoch 38 Iter 1200, train entropy gap 1.8161 bits (loss 21.364, data 19.548) 0.00036 lr
Epoch 38 Iter 1400, train entropy gap 1.3990 bits (loss 20.947, data 19.548) 0.00036 lr
Epoch 38 Iter 1600, train entropy gap 1.3193 bits (loss 20.867, data 19.548) 0.00036 lr
Epoch 38 Iter 1800, train entropy gap 2.6051 bits (loss 22.153, data 19.548) 0.00036 lr
Epoch 38 Iter 2000, train entropy gap 2.1233 bits (loss 21.671, data 19.548) 0.00036 lr
Epoch 38 Iter 2200, train entropy gap 1.8084 bits (loss 21.356, data 19.548) 0.00036 lr
Epoch 38 Iter 2400, train entropy gap 1.3982 bits (loss 20.946, data 19.548) 0.00036 lr
Epoch 38 Iter 2600, train entropy gap 1.1877 bits (loss 20.735, data 19.548) 0.00036 lr
Epoch 38 Iter 2800, train entropy gap 2.0232 bits (loss 21.571, data 19.548) 0.00036 lr
Epoch 38 Iter 3000, train entropy gap 2.3589 bits (loss 21.907, data 19.548) 0.00036 lr
Epoch 38 Iter 3200, train entropy gap 1.8344 bits (loss 21.382, data 19.548) 0.00036 lr
Epoch 38 Iter 3400, train entropy gap 1.5788 bits (loss 21.126, data 19.548) 0.00036 lr
Epoch 38 Iter 3600, train entropy gap 1.2481 bits (loss 20.796, data 19.548) 0.00036 lr
Epoch 38 Iter 3800, train entropy gap 1.6896 bits (loss 21.237, data 19.548) 0.00036 lr
Epoch 38 Iter 4000, train entropy gap 1.9511 bits (loss 21.499, data 19.548) 0.00036 lr
Epoch 38 Iter 4200, train entropy gap 1.9229 bits (loss 21.471, data 19.548) 0.00036 lr
Epoch 38 Iter 4400, train entropy gap 2.2160 bits (loss 21.764, data 19.548) 0.00036 lr
Epoch 38 Iter 4600, train entropy gap 0.8731 bits (loss 20.421, data 19.548) 0.00036 lr
Epoch 38 Iter 4800, train entropy gap 1.8787 bits (loss 21.426, data 19.548) 0.00036 lr
Epoch 38 Iter 5000, train entropy gap 1.6437 bits (loss 21.191, data 19.548) 0.00036 lr
Epoch 38 Iter 5200, train entropy gap 1.5316 bits (loss 21.079, data 19.548) 0.00036 lr
Epoch 38 Iter 5400, train entropy gap 2.2024 bits (loss 21.750, data 19.548) 0.00036 lr
Epoch 38 Iter 5600, train entropy gap 2.1416 bits (loss 21.689, data 19.548) 0.00036 lr
Epoch 38 Iter 5800, train entropy gap 1.0724 bits (loss 20.620, data 19.548) 0.00036 lr
Epoch 38 Iter 6000, train entropy gap 2.0056 bits (loss 21.553, data 19.548) 0.00036 lr
epoch 38 train loss 14.7364 nats / 21.2602 bits
time since start: 5493.4 secs
Epoch 39 Iter 0, train entropy gap 1.6711 bits (loss 21.219, data 19.548) 0.00036 lr
Epoch 39 Iter 200, train entropy gap 1.5608 bits (loss 21.109, data 19.548) 0.00036 lr
Epoch 39 Iter 400, train entropy gap 0.9198 bits (loss 20.467, data 19.548) 0.00036 lr
Epoch 39 Iter 600, train entropy gap 1.5209 bits (loss 21.069, data 19.548) 0.00036 lr
Epoch 39 Iter 800, train entropy gap 1.4222 bits (loss 20.970, data 19.548) 0.00036 lr
Epoch 39 Iter 1000, train entropy gap 1.1074 bits (loss 20.655, data 19.548) 0.00036 lr
Epoch 39 Iter 1200, train entropy gap 1.4101 bits (loss 20.958, data 19.548) 0.00036 lr
Epoch 39 Iter 1400, train entropy gap 1.7895 bits (loss 21.337, data 19.548) 0.00036 lr
Epoch 39 Iter 1600, train entropy gap 1.4643 bits (loss 21.012, data 19.548) 0.00036 lr
Epoch 39 Iter 1800, train entropy gap 1.9471 bits (loss 21.495, data 19.548) 0.00036 lr
Epoch 39 Iter 2000, train entropy gap 1.6938 bits (loss 21.242, data 19.548) 0.00036 lr
Epoch 39 Iter 2200, train entropy gap 1.1094 bits (loss 20.657, data 19.548) 0.00036 lr
Epoch 39 Iter 2400, train entropy gap 1.5916 bits (loss 21.139, data 19.548) 0.00036 lr
Epoch 39 Iter 2600, train entropy gap 1.1464 bits (loss 20.694, data 19.548) 0.00036 lr
Epoch 39 Iter 2800, train entropy gap 1.2284 bits (loss 20.776, data 19.548) 0.00036 lr
Epoch 39 Iter 3000, train entropy gap 2.2959 bits (loss 21.844, data 19.548) 0.00036 lr
Epoch 39 Iter 3200, train entropy gap 2.3633 bits (loss 21.911, data 19.548) 0.00036 lr
Epoch 39 Iter 3400, train entropy gap 1.1530 bits (loss 20.701, data 19.548) 0.00036 lr
Epoch 39 Iter 3600, train entropy gap 2.9829 bits (loss 22.531, data 19.548) 0.00036 lr
Epoch 39 Iter 3800, train entropy gap 2.3284 bits (loss 21.876, data 19.548) 0.00036 lr
Epoch 39 Iter 4000, train entropy gap 1.1940 bits (loss 20.742, data 19.548) 0.00036 lr
Epoch 39 Iter 4200, train entropy gap 1.1207 bits (loss 20.668, data 19.548) 0.00036 lr
Epoch 39 Iter 4400, train entropy gap 2.0066 bits (loss 21.554, data 19.548) 0.00036 lr
Epoch 39 Iter 4600, train entropy gap 1.2487 bits (loss 20.796, data 19.548) 0.00036 lr
Epoch 39 Iter 4800, train entropy gap 1.1937 bits (loss 20.741, data 19.548) 0.00036 lr
Epoch 39 Iter 5000, train entropy gap 1.2675 bits (loss 20.815, data 19.548) 0.00036 lr
Epoch 39 Iter 5200, train entropy gap 2.1643 bits (loss 21.712, data 19.548) 0.00036 lr
Epoch 39 Iter 5400, train entropy gap 1.6804 bits (loss 21.228, data 19.548) 0.00036 lr
Epoch 39 Iter 5600, train entropy gap 1.2301 bits (loss 20.778, data 19.548) 0.00036 lr
Epoch 39 Iter 5800, train entropy gap 2.3755 bits (loss 21.923, data 19.548) 0.00036 lr
Epoch 39 Iter 6000, train entropy gap 1.8999 bits (loss 21.448, data 19.548) 0.00036 lr
epoch 39 train loss 14.7292 nats / 21.2497 bits
time since start: 5634.8 secs
Epoch 40 Iter 0, train entropy gap 2.7842 bits (loss 22.332, data 19.548) 0.00036 lr
Epoch 40 Iter 200, train entropy gap 1.7076 bits (loss 21.255, data 19.548) 0.00036 lr
Epoch 40 Iter 400, train entropy gap 1.3841 bits (loss 20.932, data 19.548) 0.00036 lr
Epoch 40 Iter 600, train entropy gap 1.1908 bits (loss 20.738, data 19.548) 0.00036 lr
Epoch 40 Iter 800, train entropy gap 1.3828 bits (loss 20.930, data 19.548) 0.00036 lr
Epoch 40 Iter 1000, train entropy gap 1.1975 bits (loss 20.745, data 19.548) 0.00036 lr
Epoch 40 Iter 1200, train entropy gap 2.0841 bits (loss 21.632, data 19.548) 0.00036 lr
Epoch 40 Iter 1400, train entropy gap 1.3262 bits (loss 20.874, data 19.548) 0.00036 lr
Epoch 40 Iter 1600, train entropy gap 0.9307 bits (loss 20.478, data 19.548) 0.00035 lr
Epoch 40 Iter 1800, train entropy gap 1.4774 bits (loss 21.025, data 19.548) 0.00035 lr
Epoch 40 Iter 2000, train entropy gap 1.3150 bits (loss 20.863, data 19.548) 0.00035 lr
Epoch 40 Iter 2200, train entropy gap 2.4246 bits (loss 21.972, data 19.548) 0.00035 lr
Epoch 40 Iter 2400, train entropy gap 1.1828 bits (loss 20.731, data 19.548) 0.00035 lr
Epoch 40 Iter 2600, train entropy gap 1.4661 bits (loss 21.014, data 19.548) 0.00035 lr
Epoch 40 Iter 2800, train entropy gap 1.4672 bits (loss 21.015, data 19.548) 0.00035 lr
Epoch 40 Iter 3000, train entropy gap 0.8448 bits (loss 20.392, data 19.548) 0.00035 lr
Epoch 40 Iter 3200, train entropy gap 1.5541 bits (loss 21.102, data 19.548) 0.00035 lr
Epoch 40 Iter 3400, train entropy gap 0.9490 bits (loss 20.497, data 19.548) 0.00035 lr
Epoch 40 Iter 3600, train entropy gap 0.8903 bits (loss 20.438, data 19.548) 0.00035 lr
Epoch 40 Iter 3800, train entropy gap 1.2824 bits (loss 20.830, data 19.548) 0.00035 lr
Epoch 40 Iter 4000, train entropy gap 1.5495 bits (loss 21.097, data 19.548) 0.00035 lr
Epoch 40 Iter 4200, train entropy gap 1.3454 bits (loss 20.893, data 19.548) 0.00035 lr
Epoch 40 Iter 4400, train entropy gap 1.8819 bits (loss 21.430, data 19.548) 0.00035 lr
Epoch 40 Iter 4600, train entropy gap 1.7399 bits (loss 21.288, data 19.548) 0.00035 lr
Epoch 40 Iter 4800, train entropy gap 1.7802 bits (loss 21.328, data 19.548) 0.00035 lr
Epoch 40 Iter 5000, train entropy gap 2.1494 bits (loss 21.697, data 19.548) 0.00035 lr
Epoch 40 Iter 5200, train entropy gap 1.0636 bits (loss 20.611, data 19.548) 0.00035 lr
Epoch 40 Iter 5400, train entropy gap 2.6768 bits (loss 22.225, data 19.548) 0.00035 lr
Epoch 40 Iter 5600, train entropy gap 1.1631 bits (loss 20.711, data 19.548) 0.00035 lr
Epoch 40 Iter 5800, train entropy gap 1.0471 bits (loss 20.595, data 19.548) 0.00035 lr
Epoch 40 Iter 6000, train entropy gap 1.2248 bits (loss 20.772, data 19.548) 0.00035 lr
epoch 40 train loss 14.7397 nats / 21.2649 bits
time since start: 5775.8 secs
Epoch 41 Iter 0, train entropy gap 1.2545 bits (loss 20.802, data 19.548) 0.00035 lr
Epoch 41 Iter 200, train entropy gap 1.8219 bits (loss 21.370, data 19.548) 0.00035 lr
Epoch 41 Iter 400, train entropy gap 1.7991 bits (loss 21.347, data 19.548) 0.00035 lr
Epoch 41 Iter 600, train entropy gap 1.5397 bits (loss 21.087, data 19.548) 0.00035 lr
Epoch 41 Iter 800, train entropy gap 1.6677 bits (loss 21.215, data 19.548) 0.00035 lr
Epoch 41 Iter 1000, train entropy gap 1.3870 bits (loss 20.935, data 19.548) 0.00035 lr
Epoch 41 Iter 1200, train entropy gap 1.8124 bits (loss 21.360, data 19.548) 0.00035 lr
Epoch 41 Iter 1400, train entropy gap 1.3263 bits (loss 20.874, data 19.548) 0.00035 lr
Epoch 41 Iter 1600, train entropy gap 1.6490 bits (loss 21.197, data 19.548) 0.00035 lr
Epoch 41 Iter 1800, train entropy gap 2.1561 bits (loss 21.704, data 19.548) 0.00035 lr
Epoch 41 Iter 2000, train entropy gap 1.2551 bits (loss 20.803, data 19.548) 0.00035 lr
Epoch 41 Iter 2200, train entropy gap 1.9551 bits (loss 21.503, data 19.548) 0.00035 lr
Epoch 41 Iter 2400, train entropy gap 1.7259 bits (loss 21.274, data 19.548) 0.00035 lr
Epoch 41 Iter 2600, train entropy gap 2.3822 bits (loss 21.930, data 19.548) 0.00035 lr
Epoch 41 Iter 2800, train entropy gap 1.9472 bits (loss 21.495, data 19.548) 0.00035 lr
Epoch 41 Iter 3000, train entropy gap 2.8257 bits (loss 22.373, data 19.548) 0.00035 lr
Epoch 41 Iter 3200, train entropy gap 1.8286 bits (loss 21.376, data 19.548) 0.00035 lr
Epoch 41 Iter 3400, train entropy gap 1.3336 bits (loss 20.881, data 19.548) 0.00035 lr
Epoch 41 Iter 3600, train entropy gap 1.2725 bits (loss 20.820, data 19.548) 0.00035 lr
Epoch 41 Iter 3800, train entropy gap 1.6011 bits (loss 21.149, data 19.548) 0.00035 lr
Epoch 41 Iter 4000, train entropy gap 2.1530 bits (loss 21.701, data 19.548) 0.00035 lr
Epoch 41 Iter 4200, train entropy gap 2.5363 bits (loss 22.084, data 19.548) 0.00035 lr
Epoch 41 Iter 4400, train entropy gap 0.9268 bits (loss 20.474, data 19.548) 0.00035 lr
Epoch 41 Iter 4600, train entropy gap 1.8127 bits (loss 21.360, data 19.548) 0.00035 lr
Epoch 41 Iter 4800, train entropy gap 1.4016 bits (loss 20.949, data 19.548) 0.00035 lr
Epoch 41 Iter 5000, train entropy gap 1.6631 bits (loss 21.211, data 19.548) 0.00035 lr
Epoch 41 Iter 5200, train entropy gap 2.4779 bits (loss 22.026, data 19.548) 0.00035 lr
Epoch 41 Iter 5400, train entropy gap 2.3191 bits (loss 21.867, data 19.548) 0.00035 lr
Epoch 41 Iter 5600, train entropy gap 2.3195 bits (loss 21.867, data 19.548) 0.00035 lr
Epoch 41 Iter 5800, train entropy gap 1.3491 bits (loss 20.897, data 19.548) 0.00035 lr
Epoch 41 Iter 6000, train entropy gap 1.4566 bits (loss 21.004, data 19.548) 0.00035 lr
epoch 41 train loss 14.7299 nats / 21.2508 bits
time since start: 5916.6 secs
Epoch 42 Iter 0, train entropy gap 1.8084 bits (loss 21.356, data 19.548) 0.00035 lr
Epoch 42 Iter 200, train entropy gap 1.5468 bits (loss 21.094, data 19.548) 0.00035 lr
Epoch 42 Iter 400, train entropy gap 2.9000 bits (loss 22.448, data 19.548) 0.00035 lr
Epoch 42 Iter 600, train entropy gap 2.3881 bits (loss 21.936, data 19.548) 0.00035 lr
Epoch 42 Iter 800, train entropy gap 1.5435 bits (loss 21.091, data 19.548) 0.00035 lr
Epoch 42 Iter 1000, train entropy gap 1.5642 bits (loss 21.112, data 19.548) 0.00035 lr
Epoch 42 Iter 1200, train entropy gap 1.1109 bits (loss 20.659, data 19.548) 0.00035 lr
Epoch 42 Iter 1400, train entropy gap 2.8706 bits (loss 22.418, data 19.548) 0.00035 lr
Epoch 42 Iter 1600, train entropy gap 1.1969 bits (loss 20.745, data 19.548) 0.00035 lr
Epoch 42 Iter 1800, train entropy gap 1.9324 bits (loss 21.480, data 19.548) 0.00035 lr
Epoch 42 Iter 2000, train entropy gap 1.3321 bits (loss 20.880, data 19.548) 0.00035 lr
Epoch 42 Iter 2200, train entropy gap 1.2231 bits (loss 20.771, data 19.548) 0.00035 lr
Epoch 42 Iter 2400, train entropy gap 1.6854 bits (loss 21.233, data 19.548) 0.00035 lr
Epoch 42 Iter 2600, train entropy gap 1.5228 bits (loss 21.071, data 19.548) 0.00035 lr
Epoch 42 Iter 2800, train entropy gap 2.5643 bits (loss 22.112, data 19.548) 0.00035 lr
Epoch 42 Iter 3000, train entropy gap 2.1735 bits (loss 21.721, data 19.548) 0.00035 lr
Epoch 42 Iter 3200, train entropy gap 1.4537 bits (loss 21.001, data 19.548) 0.00035 lr
Epoch 42 Iter 3400, train entropy gap 1.6481 bits (loss 21.196, data 19.548) 0.00035 lr
Epoch 42 Iter 3600, train entropy gap 1.6698 bits (loss 21.218, data 19.548) 0.00035 lr
Epoch 42 Iter 3800, train entropy gap 0.8328 bits (loss 20.380, data 19.548) 0.00034 lr
Epoch 42 Iter 4000, train entropy gap 2.0928 bits (loss 21.640, data 19.548) 0.00034 lr
Epoch 42 Iter 4200, train entropy gap 1.9251 bits (loss 21.473, data 19.548) 0.00034 lr
Epoch 42 Iter 4400, train entropy gap 1.6124 bits (loss 21.160, data 19.548) 0.00034 lr
Epoch 42 Iter 4600, train entropy gap 1.4806 bits (loss 21.028, data 19.548) 0.00034 lr
Epoch 42 Iter 4800, train entropy gap 1.5602 bits (loss 21.108, data 19.548) 0.00034 lr
Epoch 42 Iter 5000, train entropy gap 2.0141 bits (loss 21.562, data 19.548) 0.00034 lr
Epoch 42 Iter 5200, train entropy gap 1.9441 bits (loss 21.492, data 19.548) 0.00034 lr
Epoch 42 Iter 5400, train entropy gap 2.5311 bits (loss 22.079, data 19.548) 0.00034 lr
Epoch 42 Iter 5600, train entropy gap 1.0725 bits (loss 20.620, data 19.548) 0.00034 lr
Epoch 42 Iter 5800, train entropy gap 1.2519 bits (loss 20.800, data 19.548) 0.00034 lr
Epoch 42 Iter 6000, train entropy gap 1.2266 bits (loss 20.774, data 19.548) 0.00034 lr
epoch 42 train loss 14.7345 nats / 21.2573 bits
time since start: 6057.8 secs
Epoch 43 Iter 0, train entropy gap 2.4722 bits (loss 22.020, data 19.548) 0.00034 lr
Epoch 43 Iter 200, train entropy gap 1.5463 bits (loss 21.094, data 19.548) 0.00034 lr
Epoch 43 Iter 400, train entropy gap 2.3107 bits (loss 21.858, data 19.548) 0.00034 lr
Epoch 43 Iter 600, train entropy gap 1.6629 bits (loss 21.211, data 19.548) 0.00034 lr
Epoch 43 Iter 800, train entropy gap 2.9399 bits (loss 22.488, data 19.548) 0.00034 lr
Epoch 43 Iter 1000, train entropy gap 0.7412 bits (loss 20.289, data 19.548) 0.00034 lr
Epoch 43 Iter 1200, train entropy gap 1.3239 bits (loss 20.872, data 19.548) 0.00034 lr
Epoch 43 Iter 1400, train entropy gap 0.9738 bits (loss 20.521, data 19.548) 0.00034 lr
Epoch 43 Iter 1600, train entropy gap 1.3150 bits (loss 20.863, data 19.548) 0.00034 lr
Epoch 43 Iter 1800, train entropy gap 0.9310 bits (loss 20.479, data 19.548) 0.00034 lr
Epoch 43 Iter 2000, train entropy gap 2.3743 bits (loss 21.922, data 19.548) 0.00034 lr
Epoch 43 Iter 2200, train entropy gap 2.2593 bits (loss 21.807, data 19.548) 0.00034 lr
Epoch 43 Iter 2400, train entropy gap 0.9748 bits (loss 20.522, data 19.548) 0.00034 lr
Epoch 43 Iter 2600, train entropy gap 3.0718 bits (loss 22.620, data 19.548) 0.00034 lr
Epoch 43 Iter 2800, train entropy gap 2.5673 bits (loss 22.115, data 19.548) 0.00034 lr
Epoch 43 Iter 3000, train entropy gap 1.6189 bits (loss 21.167, data 19.548) 0.00034 lr
Epoch 43 Iter 3200, train entropy gap 1.5788 bits (loss 21.127, data 19.548) 0.00034 lr
Epoch 43 Iter 3400, train entropy gap 1.2160 bits (loss 20.764, data 19.548) 0.00034 lr
Epoch 43 Iter 3600, train entropy gap 1.2836 bits (loss 20.831, data 19.548) 0.00034 lr
Epoch 43 Iter 3800, train entropy gap 1.6030 bits (loss 21.151, data 19.548) 0.00034 lr
Epoch 43 Iter 4000, train entropy gap 1.2090 bits (loss 20.757, data 19.548) 0.00034 lr
Epoch 43 Iter 4200, train entropy gap 2.0002 bits (loss 21.548, data 19.548) 0.00034 lr
Epoch 43 Iter 4400, train entropy gap 1.9700 bits (loss 21.518, data 19.548) 0.00034 lr
Epoch 43 Iter 4600, train entropy gap 1.6862 bits (loss 21.234, data 19.548) 0.00034 lr
Epoch 43 Iter 4800, train entropy gap 1.3911 bits (loss 20.939, data 19.548) 0.00034 lr
Epoch 43 Iter 5000, train entropy gap 1.4346 bits (loss 20.982, data 19.548) 0.00034 lr
Epoch 43 Iter 5200, train entropy gap 1.4647 bits (loss 21.012, data 19.548) 0.00034 lr
Epoch 43 Iter 5400, train entropy gap 1.0678 bits (loss 20.615, data 19.548) 0.00034 lr
Epoch 43 Iter 5600, train entropy gap 1.8514 bits (loss 21.399, data 19.548) 0.00034 lr
Epoch 43 Iter 5800, train entropy gap 1.5530 bits (loss 21.101, data 19.548) 0.00034 lr
Epoch 43 Iter 6000, train entropy gap 2.3196 bits (loss 21.867, data 19.548) 0.00034 lr
epoch 43 train loss 14.7387 nats / 21.2635 bits
time since start: 6199.2 secs
Epoch 44 Iter 0, train entropy gap 2.3530 bits (loss 21.901, data 19.548) 0.00034 lr
Epoch 44 Iter 200, train entropy gap 1.9873 bits (loss 21.535, data 19.548) 0.00034 lr
Epoch 44 Iter 400, train entropy gap 1.8956 bits (loss 21.443, data 19.548) 0.00034 lr
Epoch 44 Iter 600, train entropy gap 1.4093 bits (loss 20.957, data 19.548) 0.00034 lr
Epoch 44 Iter 800, train entropy gap 1.8353 bits (loss 21.383, data 19.548) 0.00034 lr
Epoch 44 Iter 1000, train entropy gap 1.5509 bits (loss 21.099, data 19.548) 0.00034 lr
Epoch 44 Iter 1200, train entropy gap 0.9320 bits (loss 20.480, data 19.548) 0.00034 lr
Epoch 44 Iter 1400, train entropy gap 1.7850 bits (loss 21.333, data 19.548) 0.00034 lr
Epoch 44 Iter 1600, train entropy gap 2.5811 bits (loss 22.129, data 19.548) 0.00034 lr
Epoch 44 Iter 1800, train entropy gap 1.3382 bits (loss 20.886, data 19.548) 0.00034 lr
Epoch 44 Iter 2000, train entropy gap 1.0685 bits (loss 20.616, data 19.548) 0.00034 lr
Epoch 44 Iter 2200, train entropy gap 0.9446 bits (loss 20.492, data 19.548) 0.00034 lr
Epoch 44 Iter 2400, train entropy gap 1.4658 bits (loss 21.013, data 19.548) 0.00034 lr
Epoch 44 Iter 2600, train entropy gap 0.9654 bits (loss 20.513, data 19.548) 0.00034 lr
Epoch 44 Iter 2800, train entropy gap 1.7679 bits (loss 21.316, data 19.548) 0.00034 lr
Epoch 44 Iter 3000, train entropy gap 1.4621 bits (loss 21.010, data 19.548) 0.00034 lr
Epoch 44 Iter 3200, train entropy gap 1.7339 bits (loss 21.282, data 19.548) 0.00034 lr
Epoch 44 Iter 3400, train entropy gap 1.4955 bits (loss 21.043, data 19.548) 0.00034 lr
Epoch 44 Iter 3600, train entropy gap 1.8432 bits (loss 21.391, data 19.548) 0.00034 lr
Epoch 44 Iter 3800, train entropy gap 2.1711 bits (loss 21.719, data 19.548) 0.00034 lr
Epoch 44 Iter 4000, train entropy gap 1.5883 bits (loss 21.136, data 19.548) 0.00034 lr
Epoch 44 Iter 4200, train entropy gap 1.0022 bits (loss 20.550, data 19.548) 0.00034 lr
Epoch 44 Iter 4400, train entropy gap 1.0854 bits (loss 20.633, data 19.548) 0.00034 lr
Epoch 44 Iter 4600, train entropy gap 1.8412 bits (loss 21.389, data 19.548) 0.00034 lr
Epoch 44 Iter 4800, train entropy gap 2.3880 bits (loss 21.936, data 19.548) 0.00034 lr
Epoch 44 Iter 5000, train entropy gap 1.7875 bits (loss 21.335, data 19.548) 0.00034 lr
Epoch 44 Iter 5200, train entropy gap 1.5245 bits (loss 21.072, data 19.548) 0.00034 lr
Epoch 44 Iter 5400, train entropy gap 2.4902 bits (loss 22.038, data 19.548) 0.00034 lr
Epoch 44 Iter 5600, train entropy gap 1.0803 bits (loss 20.628, data 19.548) 0.00034 lr
Epoch 44 Iter 5800, train entropy gap 2.0807 bits (loss 21.628, data 19.548) 0.00034 lr
Epoch 44 Iter 6000, train entropy gap 1.9384 bits (loss 21.486, data 19.548) 0.00034 lr
epoch 44 train loss 14.7383 nats / 21.2629 bits
time since start: 6340.1 secs
Epoch 45 Iter 0, train entropy gap 1.9076 bits (loss 21.455, data 19.548) 0.00034 lr
Epoch 45 Iter 200, train entropy gap 2.1065 bits (loss 21.654, data 19.548) 0.00034 lr
Epoch 45 Iter 400, train entropy gap 2.5311 bits (loss 22.079, data 19.548) 0.00034 lr
Epoch 45 Iter 600, train entropy gap 2.1330 bits (loss 21.681, data 19.548) 0.00034 lr
Epoch 45 Iter 800, train entropy gap 1.9899 bits (loss 21.538, data 19.548) 0.00034 lr
Epoch 45 Iter 1000, train entropy gap 1.8099 bits (loss 21.358, data 19.548) 0.00034 lr
Epoch 45 Iter 1200, train entropy gap 3.0651 bits (loss 22.613, data 19.548) 0.00033 lr
Epoch 45 Iter 1400, train entropy gap 1.7894 bits (loss 21.337, data 19.548) 0.00033 lr
Epoch 45 Iter 1600, train entropy gap 1.8453 bits (loss 21.393, data 19.548) 0.00033 lr
Epoch 45 Iter 1800, train entropy gap 2.1672 bits (loss 21.715, data 19.548) 0.00033 lr
Epoch 45 Iter 2000, train entropy gap 1.3269 bits (loss 20.875, data 19.548) 0.00033 lr
Epoch 45 Iter 2200, train entropy gap 1.2488 bits (loss 20.797, data 19.548) 0.00033 lr
Epoch 45 Iter 2400, train entropy gap 2.8610 bits (loss 22.409, data 19.548) 0.00033 lr
Epoch 45 Iter 2600, train entropy gap 1.5941 bits (loss 21.142, data 19.548) 0.00033 lr
Epoch 45 Iter 2800, train entropy gap 1.8255 bits (loss 21.373, data 19.548) 0.00033 lr
Epoch 45 Iter 3000, train entropy gap 0.6515 bits (loss 20.199, data 19.548) 0.00033 lr
Epoch 45 Iter 3200, train entropy gap 1.2421 bits (loss 20.790, data 19.548) 0.00033 lr
Epoch 45 Iter 3400, train entropy gap 0.9329 bits (loss 20.481, data 19.548) 0.00033 lr
Epoch 45 Iter 3600, train entropy gap 2.4547 bits (loss 22.002, data 19.548) 0.00033 lr
Epoch 45 Iter 3800, train entropy gap 2.3082 bits (loss 21.856, data 19.548) 0.00033 lr
Epoch 45 Iter 4000, train entropy gap 2.2610 bits (loss 21.809, data 19.548) 0.00033 lr
Epoch 45 Iter 4200, train entropy gap 3.1173 bits (loss 22.665, data 19.548) 0.00033 lr
Epoch 45 Iter 4400, train entropy gap 1.6159 bits (loss 21.164, data 19.548) 0.00033 lr
Epoch 45 Iter 4600, train entropy gap 1.4316 bits (loss 20.979, data 19.548) 0.00033 lr
Epoch 45 Iter 4800, train entropy gap 2.1114 bits (loss 21.659, data 19.548) 0.00033 lr
Epoch 45 Iter 5000, train entropy gap 1.3194 bits (loss 20.867, data 19.548) 0.00033 lr
Epoch 45 Iter 5200, train entropy gap 1.4099 bits (loss 20.958, data 19.548) 0.00033 lr
Epoch 45 Iter 5400, train entropy gap 1.7595 bits (loss 21.307, data 19.548) 0.00033 lr
Epoch 45 Iter 5600, train entropy gap 2.8815 bits (loss 22.429, data 19.548) 0.00033 lr
Epoch 45 Iter 5800, train entropy gap 1.5946 bits (loss 21.142, data 19.548) 0.00033 lr
Epoch 45 Iter 6000, train entropy gap 1.1238 bits (loss 20.672, data 19.548) 0.00033 lr
epoch 45 train loss 14.7278 nats / 21.2477 bits
time since start: 6480.7 secs
Epoch 46 Iter 0, train entropy gap 2.0593 bits (loss 21.607, data 19.548) 0.00033 lr
Epoch 46 Iter 200, train entropy gap 1.2640 bits (loss 20.812, data 19.548) 0.00033 lr
Epoch 46 Iter 400, train entropy gap 1.4774 bits (loss 21.025, data 19.548) 0.00033 lr
Epoch 46 Iter 600, train entropy gap 2.2627 bits (loss 21.810, data 19.548) 0.00033 lr
Epoch 46 Iter 800, train entropy gap 1.7004 bits (loss 21.248, data 19.548) 0.00033 lr
Epoch 46 Iter 1000, train entropy gap 2.4735 bits (loss 22.021, data 19.548) 0.00033 lr
Epoch 46 Iter 1200, train entropy gap 2.2024 bits (loss 21.750, data 19.548) 0.00033 lr
Epoch 46 Iter 1400, train entropy gap 2.2967 bits (loss 21.844, data 19.548) 0.00033 lr
Epoch 46 Iter 1600, train entropy gap 0.9363 bits (loss 20.484, data 19.548) 0.00033 lr
Epoch 46 Iter 1800, train entropy gap 1.0707 bits (loss 20.618, data 19.548) 0.00033 lr
Epoch 46 Iter 2000, train entropy gap 1.0767 bits (loss 20.624, data 19.548) 0.00033 lr
Epoch 46 Iter 2200, train entropy gap 2.4065 bits (loss 21.954, data 19.548) 0.00033 lr
Epoch 46 Iter 2400, train entropy gap 1.8729 bits (loss 21.421, data 19.548) 0.00033 lr
Epoch 46 Iter 2600, train entropy gap 1.2807 bits (loss 20.828, data 19.548) 0.00033 lr
Epoch 46 Iter 2800, train entropy gap 1.8234 bits (loss 21.371, data 19.548) 0.00033 lr
Epoch 46 Iter 3000, train entropy gap 1.4908 bits (loss 21.039, data 19.548) 0.00033 lr
Epoch 46 Iter 3200, train entropy gap 2.2377 bits (loss 21.785, data 19.548) 0.00033 lr
Epoch 46 Iter 3400, train entropy gap 2.7175 bits (loss 22.265, data 19.548) 0.00033 lr
Epoch 46 Iter 3600, train entropy gap 2.5507 bits (loss 22.098, data 19.548) 0.00033 lr
Epoch 46 Iter 3800, train entropy gap 2.0430 bits (loss 21.591, data 19.548) 0.00033 lr
Epoch 46 Iter 4000, train entropy gap 1.7845 bits (loss 21.332, data 19.548) 0.00033 lr
Epoch 46 Iter 4200, train entropy gap 1.0047 bits (loss 20.552, data 19.548) 0.00033 lr
Epoch 46 Iter 4400, train entropy gap 1.0115 bits (loss 20.559, data 19.548) 0.00033 lr
Epoch 46 Iter 4600, train entropy gap 1.3136 bits (loss 20.861, data 19.548) 0.00033 lr
Epoch 46 Iter 4800, train entropy gap 2.0200 bits (loss 21.568, data 19.548) 0.00033 lr
Epoch 46 Iter 5000, train entropy gap 3.3796 bits (loss 22.927, data 19.548) 0.00033 lr
Epoch 46 Iter 5200, train entropy gap 1.5722 bits (loss 21.120, data 19.548) 0.00033 lr
Epoch 46 Iter 5400, train entropy gap 1.4958 bits (loss 21.044, data 19.548) 0.00033 lr
Epoch 46 Iter 5600, train entropy gap 2.1454 bits (loss 21.693, data 19.548) 0.00033 lr
Epoch 46 Iter 5800, train entropy gap 1.9835 bits (loss 21.531, data 19.548) 0.00033 lr
Epoch 46 Iter 6000, train entropy gap 1.7800 bits (loss 21.328, data 19.548) 0.00033 lr
epoch 46 train loss 14.7308 nats / 21.2520 bits
time since start: 6620.1 secs
Epoch 47 Iter 0, train entropy gap 2.6094 bits (loss 22.157, data 19.548) 0.00033 lr
Epoch 47 Iter 200, train entropy gap 1.6537 bits (loss 21.201, data 19.548) 0.00033 lr
Epoch 47 Iter 400, train entropy gap 1.5205 bits (loss 21.068, data 19.548) 0.00033 lr
Epoch 47 Iter 600, train entropy gap 2.3815 bits (loss 21.929, data 19.548) 0.00033 lr
Epoch 47 Iter 800, train entropy gap 1.9578 bits (loss 21.505, data 19.548) 0.00033 lr
Epoch 47 Iter 1000, train entropy gap 2.1395 bits (loss 21.687, data 19.548) 0.00033 lr
Epoch 47 Iter 1200, train entropy gap 0.6867 bits (loss 20.234, data 19.548) 0.00033 lr
Epoch 47 Iter 1400, train entropy gap 2.2024 bits (loss 21.750, data 19.548) 0.00033 lr
Epoch 47 Iter 1600, train entropy gap 1.5334 bits (loss 21.081, data 19.548) 0.00033 lr
Epoch 47 Iter 1800, train entropy gap 1.4145 bits (loss 20.962, data 19.548) 0.00033 lr
Epoch 47 Iter 2000, train entropy gap 1.2347 bits (loss 20.782, data 19.548) 0.00033 lr
Epoch 47 Iter 2200, train entropy gap 2.2526 bits (loss 21.800, data 19.548) 0.00033 lr
Epoch 47 Iter 2400, train entropy gap 1.7233 bits (loss 21.271, data 19.548) 0.00033 lr
Epoch 47 Iter 2600, train entropy gap 2.0922 bits (loss 21.640, data 19.548) 0.00033 lr
Epoch 47 Iter 2800, train entropy gap 1.1182 bits (loss 20.666, data 19.548) 0.00033 lr
Epoch 47 Iter 3000, train entropy gap 1.9455 bits (loss 21.493, data 19.548) 0.00033 lr
Epoch 47 Iter 3200, train entropy gap 1.7490 bits (loss 21.297, data 19.548) 0.00033 lr
Epoch 47 Iter 3400, train entropy gap 2.2483 bits (loss 21.796, data 19.548) 0.00033 lr
Epoch 47 Iter 3600, train entropy gap 1.1740 bits (loss 20.722, data 19.548) 0.00033 lr
Epoch 47 Iter 3800, train entropy gap 0.8487 bits (loss 20.396, data 19.548) 0.00033 lr
Epoch 47 Iter 4000, train entropy gap 1.3911 bits (loss 20.939, data 19.548) 0.00033 lr
Epoch 47 Iter 4200, train entropy gap 1.6901 bits (loss 21.238, data 19.548) 0.00033 lr
Epoch 47 Iter 4400, train entropy gap 2.4637 bits (loss 22.011, data 19.548) 0.00033 lr
Epoch 47 Iter 4600, train entropy gap 1.7610 bits (loss 21.309, data 19.548) 0.00033 lr
Epoch 47 Iter 4800, train entropy gap 1.8119 bits (loss 21.360, data 19.548) 0.00033 lr
Epoch 47 Iter 5000, train entropy gap 1.9728 bits (loss 21.520, data 19.548) 0.00033 lr
Epoch 47 Iter 5200, train entropy gap 0.8293 bits (loss 20.377, data 19.548) 0.00033 lr
Epoch 47 Iter 5400, train entropy gap 1.6925 bits (loss 21.240, data 19.548) 0.00033 lr
Epoch 47 Iter 5600, train entropy gap 2.0123 bits (loss 21.560, data 19.548) 0.00033 lr
Epoch 47 Iter 5800, train entropy gap 1.2157 bits (loss 20.763, data 19.548) 0.00033 lr
Epoch 47 Iter 6000, train entropy gap 1.6959 bits (loss 21.244, data 19.548) 0.00033 lr
epoch 47 train loss 14.7423 nats / 21.2686 bits
time since start: 6760.7 secs
Epoch 48 Iter 0, train entropy gap 1.0718 bits (loss 20.619, data 19.548) 0.00033 lr
Epoch 48 Iter 200, train entropy gap 2.2802 bits (loss 21.828, data 19.548) 0.00032 lr
Epoch 48 Iter 400, train entropy gap 1.1962 bits (loss 20.744, data 19.548) 0.00032 lr
Epoch 48 Iter 600, train entropy gap 1.9316 bits (loss 21.479, data 19.548) 0.00032 lr
Epoch 48 Iter 800, train entropy gap 1.3872 bits (loss 20.935, data 19.548) 0.00032 lr
Epoch 48 Iter 1000, train entropy gap 1.3585 bits (loss 20.906, data 19.548) 0.00032 lr
Epoch 48 Iter 1200, train entropy gap 0.8129 bits (loss 20.361, data 19.548) 0.00032 lr
Epoch 48 Iter 1400, train entropy gap 1.7612 bits (loss 21.309, data 19.548) 0.00032 lr
Epoch 48 Iter 1600, train entropy gap 2.2015 bits (loss 21.749, data 19.548) 0.00032 lr
Epoch 48 Iter 1800, train entropy gap 1.8602 bits (loss 21.408, data 19.548) 0.00032 lr
Epoch 48 Iter 2000, train entropy gap 1.1232 bits (loss 20.671, data 19.548) 0.00032 lr
Epoch 48 Iter 2200, train entropy gap 2.1725 bits (loss 21.720, data 19.548) 0.00032 lr
Epoch 48 Iter 2400, train entropy gap 1.8325 bits (loss 21.380, data 19.548) 0.00032 lr
Epoch 48 Iter 2600, train entropy gap 1.5127 bits (loss 21.060, data 19.548) 0.00032 lr
Epoch 48 Iter 2800, train entropy gap 1.3830 bits (loss 20.931, data 19.548) 0.00032 lr
Epoch 48 Iter 3000, train entropy gap 2.1367 bits (loss 21.684, data 19.548) 0.00032 lr
Epoch 48 Iter 3200, train entropy gap 1.4346 bits (loss 20.982, data 19.548) 0.00032 lr
Epoch 48 Iter 3400, train entropy gap 1.8902 bits (loss 21.438, data 19.548) 0.00032 lr
Epoch 48 Iter 3600, train entropy gap 1.7605 bits (loss 21.308, data 19.548) 0.00032 lr
Epoch 48 Iter 3800, train entropy gap 1.0844 bits (loss 20.632, data 19.548) 0.00032 lr
Epoch 48 Iter 4000, train entropy gap 1.5306 bits (loss 21.078, data 19.548) 0.00032 lr
Epoch 48 Iter 4200, train entropy gap 0.9961 bits (loss 20.544, data 19.548) 0.00032 lr
Epoch 48 Iter 4400, train entropy gap 1.2959 bits (loss 20.844, data 19.548) 0.00032 lr
Epoch 48 Iter 4600, train entropy gap 2.5386 bits (loss 22.086, data 19.548) 0.00032 lr
Epoch 48 Iter 4800, train entropy gap 1.6916 bits (loss 21.239, data 19.548) 0.00032 lr
Epoch 48 Iter 5000, train entropy gap 2.3419 bits (loss 21.890, data 19.548) 0.00032 lr
Epoch 48 Iter 5200, train entropy gap 1.0146 bits (loss 20.562, data 19.548) 0.00032 lr
Epoch 48 Iter 5400, train entropy gap 2.2937 bits (loss 21.841, data 19.548) 0.00032 lr
Epoch 48 Iter 5600, train entropy gap 1.7519 bits (loss 21.300, data 19.548) 0.00032 lr
Epoch 48 Iter 5800, train entropy gap 1.6071 bits (loss 21.155, data 19.548) 0.00032 lr
Epoch 48 Iter 6000, train entropy gap 0.9471 bits (loss 20.495, data 19.548) 0.00032 lr
epoch 48 train loss 14.7248 nats / 21.2434 bits
time since start: 6901.5 secs
Epoch 49 Iter 0, train entropy gap 1.0771 bits (loss 20.625, data 19.548) 0.00032 lr
Epoch 49 Iter 200, train entropy gap 2.6255 bits (loss 22.173, data 19.548) 0.00032 lr
Epoch 49 Iter 400, train entropy gap 1.1912 bits (loss 20.739, data 19.548) 0.00032 lr
Epoch 49 Iter 600, train entropy gap 1.6227 bits (loss 21.170, data 19.548) 0.00032 lr
Epoch 49 Iter 800, train entropy gap 1.7435 bits (loss 21.291, data 19.548) 0.00032 lr
Epoch 49 Iter 1000, train entropy gap 2.6384 bits (loss 22.186, data 19.548) 0.00032 lr
Epoch 49 Iter 1200, train entropy gap 1.5273 bits (loss 21.075, data 19.548) 0.00032 lr
Epoch 49 Iter 1400, train entropy gap 1.8043 bits (loss 21.352, data 19.548) 0.00032 lr
Epoch 49 Iter 1600, train entropy gap 1.8502 bits (loss 21.398, data 19.548) 0.00032 lr
Epoch 49 Iter 1800, train entropy gap 1.3983 bits (loss 20.946, data 19.548) 0.00032 lr
Epoch 49 Iter 2000, train entropy gap 1.5194 bits (loss 21.067, data 19.548) 0.00032 lr
Epoch 49 Iter 2200, train entropy gap 2.2768 bits (loss 21.825, data 19.548) 0.00032 lr
Epoch 49 Iter 2400, train entropy gap 2.6743 bits (loss 22.222, data 19.548) 0.00032 lr
Epoch 49 Iter 2600, train entropy gap 1.1572 bits (loss 20.705, data 19.548) 0.00032 lr
Epoch 49 Iter 2800, train entropy gap 1.4939 bits (loss 21.042, data 19.548) 0.00032 lr
Epoch 49 Iter 3000, train entropy gap 1.5647 bits (loss 21.112, data 19.548) 0.00032 lr
Epoch 49 Iter 3200, train entropy gap 1.5433 bits (loss 21.091, data 19.548) 0.00032 lr
Epoch 49 Iter 3400, train entropy gap 1.6426 bits (loss 21.190, data 19.548) 0.00032 lr
Epoch 49 Iter 3600, train entropy gap 1.0396 bits (loss 20.587, data 19.548) 0.00032 lr
Epoch 49 Iter 3800, train entropy gap 2.1407 bits (loss 21.688, data 19.548) 0.00032 lr
Epoch 49 Iter 4000, train entropy gap 2.7634 bits (loss 22.311, data 19.548) 0.00032 lr
Epoch 49 Iter 4200, train entropy gap 1.5420 bits (loss 21.090, data 19.548) 0.00032 lr
Epoch 49 Iter 4400, train entropy gap 1.6380 bits (loss 21.186, data 19.548) 0.00032 lr
Epoch 49 Iter 4600, train entropy gap 1.1967 bits (loss 20.744, data 19.548) 0.00032 lr
Epoch 49 Iter 4800, train entropy gap 2.2204 bits (loss 21.768, data 19.548) 0.00032 lr
Epoch 49 Iter 5000, train entropy gap 1.2099 bits (loss 20.758, data 19.548) 0.00032 lr
Epoch 49 Iter 5200, train entropy gap 1.6259 bits (loss 21.174, data 19.548) 0.00032 lr
Epoch 49 Iter 5400, train entropy gap 1.0815 bits (loss 20.629, data 19.548) 0.00032 lr
Epoch 49 Iter 5600, train entropy gap 2.1819 bits (loss 21.730, data 19.548) 0.00032 lr
Epoch 49 Iter 5800, train entropy gap 1.2282 bits (loss 20.776, data 19.548) 0.00032 lr
Epoch 49 Iter 6000, train entropy gap 1.0888 bits (loss 20.636, data 19.548) 0.00032 lr
epoch 49 train loss 14.7381 nats / 21.2625 bits
time since start: 7042.1 secs
Epoch 50 Iter 0, train entropy gap 1.0375 bits (loss 20.585, data 19.548) 0.00032 lr
Epoch 50 Iter 200, train entropy gap 0.8713 bits (loss 20.419, data 19.548) 0.00032 lr
Epoch 50 Iter 400, train entropy gap 1.6367 bits (loss 21.184, data 19.548) 0.00032 lr
Epoch 50 Iter 600, train entropy gap 2.2925 bits (loss 21.840, data 19.548) 0.00032 lr
Epoch 50 Iter 800, train entropy gap 1.7992 bits (loss 21.347, data 19.548) 0.00032 lr
Epoch 50 Iter 1000, train entropy gap 1.9805 bits (loss 21.528, data 19.548) 0.00032 lr
Epoch 50 Iter 1200, train entropy gap 1.3607 bits (loss 20.908, data 19.548) 0.00032 lr
Epoch 50 Iter 1400, train entropy gap 1.1500 bits (loss 20.698, data 19.548) 0.00032 lr
Epoch 50 Iter 1600, train entropy gap 1.7744 bits (loss 21.322, data 19.548) 0.00032 lr
Epoch 50 Iter 1800, train entropy gap 1.3885 bits (loss 20.936, data 19.548) 0.00032 lr
Epoch 50 Iter 2000, train entropy gap 2.7939 bits (loss 22.342, data 19.548) 0.00032 lr
Epoch 50 Iter 2200, train entropy gap 1.5986 bits (loss 21.146, data 19.548) 0.00032 lr
Epoch 50 Iter 2400, train entropy gap 1.6014 bits (loss 21.149, data 19.548) 0.00032 lr
Epoch 50 Iter 2600, train entropy gap 2.0544 bits (loss 21.602, data 19.548) 0.00032 lr
Epoch 50 Iter 2800, train entropy gap 2.8295 bits (loss 22.377, data 19.548) 0.00032 lr
Epoch 50 Iter 3000, train entropy gap 1.1720 bits (loss 20.720, data 19.548) 0.00032 lr
Epoch 50 Iter 3200, train entropy gap 1.7763 bits (loss 21.324, data 19.548) 0.00032 lr
Epoch 50 Iter 3400, train entropy gap 1.2204 bits (loss 20.768, data 19.548) 0.00032 lr
Epoch 50 Iter 3600, train entropy gap 0.8193 bits (loss 20.367, data 19.548) 0.00032 lr
Epoch 50 Iter 3800, train entropy gap 1.3975 bits (loss 20.945, data 19.548) 0.00032 lr
Epoch 50 Iter 4000, train entropy gap 2.8160 bits (loss 22.364, data 19.548) 0.00032 lr
Epoch 50 Iter 4200, train entropy gap 1.6991 bits (loss 21.247, data 19.548) 0.00032 lr
Epoch 50 Iter 4400, train entropy gap 1.8303 bits (loss 21.378, data 19.548) 0.00032 lr
Epoch 50 Iter 4600, train entropy gap 1.7966 bits (loss 21.344, data 19.548) 0.00032 lr
Epoch 50 Iter 4800, train entropy gap 1.9257 bits (loss 21.473, data 19.548) 0.00032 lr
Epoch 50 Iter 5000, train entropy gap 2.2935 bits (loss 21.841, data 19.548) 0.00032 lr
Epoch 50 Iter 5200, train entropy gap 1.9070 bits (loss 21.455, data 19.548) 0.00032 lr
Epoch 50 Iter 5400, train entropy gap 2.0174 bits (loss 21.565, data 19.548) 0.00032 lr
Epoch 50 Iter 5600, train entropy gap 1.3485 bits (loss 20.896, data 19.548) 0.00032 lr
Epoch 50 Iter 5800, train entropy gap 1.6257 bits (loss 21.173, data 19.548) 0.00032 lr
Epoch 50 Iter 6000, train entropy gap 1.0707 bits (loss 20.618, data 19.548) 0.00032 lr
epoch 50 train loss 14.7319 nats / 21.2536 bits
time since start: 7182.9 secs
Epoch 51 Iter 0, train entropy gap 3.2137 bits (loss 22.761, data 19.548) 0.00032 lr
Epoch 51 Iter 200, train entropy gap 2.2174 bits (loss 21.765, data 19.548) 0.00032 lr
Epoch 51 Iter 400, train entropy gap 1.5702 bits (loss 21.118, data 19.548) 0.00032 lr
Epoch 51 Iter 600, train entropy gap 1.1332 bits (loss 20.681, data 19.548) 0.00032 lr
Epoch 51 Iter 800, train entropy gap 1.7161 bits (loss 21.264, data 19.548) 0.00031 lr
Epoch 51 Iter 1000, train entropy gap 2.0113 bits (loss 21.559, data 19.548) 0.00031 lr
Epoch 51 Iter 1200, train entropy gap 1.9847 bits (loss 21.532, data 19.548) 0.00031 lr
Epoch 51 Iter 1400, train entropy gap 0.8051 bits (loss 20.353, data 19.548) 0.00031 lr
Epoch 51 Iter 1600, train entropy gap 1.4677 bits (loss 21.015, data 19.548) 0.00031 lr
Epoch 51 Iter 1800, train entropy gap 2.0476 bits (loss 21.595, data 19.548) 0.00031 lr
Epoch 51 Iter 2000, train entropy gap 2.0036 bits (loss 21.551, data 19.548) 0.00031 lr
Epoch 51 Iter 2200, train entropy gap 1.1455 bits (loss 20.693, data 19.548) 0.00031 lr
Epoch 51 Iter 2400, train entropy gap 1.6816 bits (loss 21.229, data 19.548) 0.00031 lr
Epoch 51 Iter 2600, train entropy gap 1.9321 bits (loss 21.480, data 19.548) 0.00031 lr
Epoch 51 Iter 2800, train entropy gap 2.3981 bits (loss 21.946, data 19.548) 0.00031 lr
Epoch 51 Iter 3000, train entropy gap 2.0986 bits (loss 21.646, data 19.548) 0.00031 lr
Epoch 51 Iter 3200, train entropy gap 1.2263 bits (loss 20.774, data 19.548) 0.00031 lr
Epoch 51 Iter 3400, train entropy gap 2.0840 bits (loss 21.632, data 19.548) 0.00031 lr
Epoch 51 Iter 3600, train entropy gap 1.3921 bits (loss 20.940, data 19.548) 0.00031 lr
Epoch 51 Iter 3800, train entropy gap 2.4512 bits (loss 21.999, data 19.548) 0.00031 lr
Epoch 51 Iter 4000, train entropy gap 2.0748 bits (loss 21.622, data 19.548) 0.00031 lr
Epoch 51 Iter 4200, train entropy gap 1.8316 bits (loss 21.379, data 19.548) 0.00031 lr
Epoch 51 Iter 4400, train entropy gap 1.2997 bits (loss 20.847, data 19.548) 0.00031 lr
Epoch 51 Iter 4600, train entropy gap 1.1784 bits (loss 20.726, data 19.548) 0.00031 lr
Epoch 51 Iter 4800, train entropy gap 1.7684 bits (loss 21.316, data 19.548) 0.00031 lr
Epoch 51 Iter 5000, train entropy gap 2.7885 bits (loss 22.336, data 19.548) 0.00031 lr
Epoch 51 Iter 5200, train entropy gap 1.8861 bits (loss 21.434, data 19.548) 0.00031 lr
Epoch 51 Iter 5400, train entropy gap 1.4097 bits (loss 20.957, data 19.548) 0.00031 lr
Epoch 51 Iter 5600, train entropy gap 1.2142 bits (loss 20.762, data 19.548) 0.00031 lr
Epoch 51 Iter 5800, train entropy gap 1.5077 bits (loss 21.055, data 19.548) 0.00031 lr
Epoch 51 Iter 6000, train entropy gap 1.1790 bits (loss 20.727, data 19.548) 0.00031 lr
epoch 51 train loss 14.7342 nats / 21.2570 bits
time since start: 7323.9 secs
Epoch 52 Iter 0, train entropy gap 2.0556 bits (loss 21.603, data 19.548) 0.00031 lr
Epoch 52 Iter 200, train entropy gap 3.1442 bits (loss 22.692, data 19.548) 0.00031 lr
Epoch 52 Iter 400, train entropy gap 0.9278 bits (loss 20.476, data 19.548) 0.00031 lr
Epoch 52 Iter 600, train entropy gap 1.8759 bits (loss 21.424, data 19.548) 0.00031 lr
Epoch 52 Iter 800, train entropy gap 1.5825 bits (loss 21.130, data 19.548) 0.00031 lr
Epoch 52 Iter 1000, train entropy gap 1.1874 bits (loss 20.735, data 19.548) 0.00031 lr
Epoch 52 Iter 1200, train entropy gap 1.4471 bits (loss 20.995, data 19.548) 0.00031 lr
Epoch 52 Iter 1400, train entropy gap 2.3746 bits (loss 21.922, data 19.548) 0.00031 lr
Epoch 52 Iter 1600, train entropy gap 0.8719 bits (loss 20.420, data 19.548) 0.00031 lr
Epoch 52 Iter 1800, train entropy gap 1.6483 bits (loss 21.196, data 19.548) 0.00031 lr
Epoch 52 Iter 2000, train entropy gap 2.0229 bits (loss 21.571, data 19.548) 0.00031 lr
Epoch 52 Iter 2200, train entropy gap 2.8022 bits (loss 22.350, data 19.548) 0.00031 lr
Epoch 52 Iter 2400, train entropy gap 1.2827 bits (loss 20.830, data 19.548) 0.00031 lr
Epoch 52 Iter 2600, train entropy gap 1.8732 bits (loss 21.421, data 19.548) 0.00031 lr
Epoch 52 Iter 2800, train entropy gap 2.4507 bits (loss 21.998, data 19.548) 0.00031 lr
Epoch 52 Iter 3000, train entropy gap 3.0540 bits (loss 22.602, data 19.548) 0.00031 lr
Epoch 52 Iter 3200, train entropy gap 1.8486 bits (loss 21.396, data 19.548) 0.00031 lr
Epoch 52 Iter 3400, train entropy gap 1.7273 bits (loss 21.275, data 19.548) 0.00031 lr
Epoch 52 Iter 3600, train entropy gap 1.2135 bits (loss 20.761, data 19.548) 0.00031 lr
Epoch 52 Iter 3800, train entropy gap 1.8050 bits (loss 21.353, data 19.548) 0.00031 lr
Epoch 52 Iter 4000, train entropy gap 1.6434 bits (loss 21.191, data 19.548) 0.00031 lr
Epoch 52 Iter 4200, train entropy gap 2.4237 bits (loss 21.971, data 19.548) 0.00031 lr
Epoch 52 Iter 4400, train entropy gap 0.7815 bits (loss 20.329, data 19.548) 0.00031 lr
Epoch 52 Iter 4600, train entropy gap 0.9463 bits (loss 20.494, data 19.548) 0.00031 lr
Epoch 52 Iter 4800, train entropy gap 1.1794 bits (loss 20.727, data 19.548) 0.00031 lr
Epoch 52 Iter 5000, train entropy gap 1.6131 bits (loss 21.161, data 19.548) 0.00031 lr
Epoch 52 Iter 5200, train entropy gap 2.0307 bits (loss 21.578, data 19.548) 0.00031 lr
Epoch 52 Iter 5400, train entropy gap 2.4710 bits (loss 22.019, data 19.548) 0.00031 lr
Epoch 52 Iter 5600, train entropy gap 2.4170 bits (loss 21.965, data 19.548) 0.00031 lr
Epoch 52 Iter 5800, train entropy gap 1.2305 bits (loss 20.778, data 19.548) 0.00031 lr
Epoch 52 Iter 6000, train entropy gap 2.4627 bits (loss 22.010, data 19.548) 0.00031 lr
epoch 52 train loss 14.7288 nats / 21.2491 bits
time since start: 7464.9 secs
Epoch 53 Iter 0, train entropy gap 1.4128 bits (loss 20.961, data 19.548) 0.00031 lr
Epoch 53 Iter 200, train entropy gap 1.4973 bits (loss 21.045, data 19.548) 0.00031 lr
Epoch 53 Iter 400, train entropy gap 1.2018 bits (loss 20.750, data 19.548) 0.00031 lr
Epoch 53 Iter 600, train entropy gap 1.2527 bits (loss 20.800, data 19.548) 0.00031 lr
Epoch 53 Iter 800, train entropy gap 2.1074 bits (loss 21.655, data 19.548) 0.00031 lr
Epoch 53 Iter 1000, train entropy gap 1.6849 bits (loss 21.233, data 19.548) 0.00031 lr
Epoch 53 Iter 1200, train entropy gap 2.3431 bits (loss 21.891, data 19.548) 0.00031 lr
Epoch 53 Iter 1400, train entropy gap 1.4468 bits (loss 20.995, data 19.548) 0.00031 lr
Epoch 53 Iter 1600, train entropy gap 0.9036 bits (loss 20.451, data 19.548) 0.00031 lr
Epoch 53 Iter 1800, train entropy gap 0.9999 bits (loss 20.548, data 19.548) 0.00031 lr
Epoch 53 Iter 2000, train entropy gap 1.2155 bits (loss 20.763, data 19.548) 0.00031 lr
Epoch 53 Iter 2200, train entropy gap 1.3462 bits (loss 20.894, data 19.548) 0.00031 lr
Epoch 53 Iter 2400, train entropy gap 2.5340 bits (loss 22.082, data 19.548) 0.00031 lr
Epoch 53 Iter 2600, train entropy gap 1.5156 bits (loss 21.063, data 19.548) 0.00031 lr
Epoch 53 Iter 2800, train entropy gap 0.9469 bits (loss 20.495, data 19.548) 0.00031 lr
Epoch 53 Iter 3000, train entropy gap 0.9234 bits (loss 20.471, data 19.548) 0.00031 lr
Epoch 53 Iter 3200, train entropy gap 1.8469 bits (loss 21.395, data 19.548) 0.00031 lr
Epoch 53 Iter 3400, train entropy gap 1.5334 bits (loss 21.081, data 19.548) 0.00031 lr
Epoch 53 Iter 3600, train entropy gap 2.1954 bits (loss 21.743, data 19.548) 0.00031 lr
Epoch 53 Iter 3800, train entropy gap 2.4946 bits (loss 22.042, data 19.548) 0.00031 lr
Epoch 53 Iter 4000, train entropy gap 2.1543 bits (loss 21.702, data 19.548) 0.00031 lr
Epoch 53 Iter 4200, train entropy gap 1.6354 bits (loss 21.183, data 19.548) 0.00031 lr
Epoch 53 Iter 4400, train entropy gap 1.7676 bits (loss 21.315, data 19.548) 0.00031 lr
Epoch 53 Iter 4600, train entropy gap 1.4381 bits (loss 20.986, data 19.548) 0.00031 lr
Epoch 53 Iter 4800, train entropy gap 1.5937 bits (loss 21.141, data 19.548) 0.00031 lr
Epoch 53 Iter 5000, train entropy gap 2.3905 bits (loss 21.938, data 19.548) 0.00031 lr
Epoch 53 Iter 5200, train entropy gap 1.9911 bits (loss 21.539, data 19.548) 0.00031 lr
Epoch 53 Iter 5400, train entropy gap 1.9739 bits (loss 21.522, data 19.548) 0.00031 lr
Epoch 53 Iter 5600, train entropy gap 1.9240 bits (loss 21.472, data 19.548) 0.00031 lr
Epoch 53 Iter 5800, train entropy gap 1.4027 bits (loss 20.950, data 19.548) 0.00031 lr
Epoch 53 Iter 6000, train entropy gap 2.9978 bits (loss 22.546, data 19.548) 0.00031 lr
epoch 53 train loss 14.7265 nats / 21.2458 bits
time since start: 7605.9 secs
Epoch 54 Iter 0, train entropy gap 1.2022 bits (loss 20.750, data 19.548) 0.00031 lr
Epoch 54 Iter 200, train entropy gap 2.4471 bits (loss 21.995, data 19.548) 0.00031 lr
Epoch 54 Iter 400, train entropy gap 1.6518 bits (loss 21.200, data 19.548) 0.00031 lr
Epoch 54 Iter 600, train entropy gap 2.0368 bits (loss 21.585, data 19.548) 0.00031 lr
Epoch 54 Iter 800, train entropy gap 1.6875 bits (loss 21.235, data 19.548) 0.00031 lr
Epoch 54 Iter 1000, train entropy gap 1.2808 bits (loss 20.829, data 19.548) 0.00031 lr
Epoch 54 Iter 1200, train entropy gap 1.3405 bits (loss 20.888, data 19.548) 0.00031 lr
Epoch 54 Iter 1400, train entropy gap 2.4067 bits (loss 21.954, data 19.548) 0.00031 lr
Epoch 54 Iter 1600, train entropy gap 1.6550 bits (loss 21.203, data 19.548) 0.00031 lr
Epoch 54 Iter 1800, train entropy gap 1.1511 bits (loss 20.699, data 19.548) 0.00031 lr
Epoch 54 Iter 2000, train entropy gap 2.4216 bits (loss 21.969, data 19.548) 0.00031 lr
Epoch 54 Iter 2200, train entropy gap 1.4536 bits (loss 21.001, data 19.548) 0.00031 lr
Epoch 54 Iter 2400, train entropy gap 1.1755 bits (loss 20.723, data 19.548) 0.00031 lr
Epoch 54 Iter 2600, train entropy gap 1.6249 bits (loss 21.173, data 19.548) 0.00031 lr
Epoch 54 Iter 2800, train entropy gap 1.6002 bits (loss 21.148, data 19.548) 0.00031 lr
Epoch 54 Iter 3000, train entropy gap 1.4782 bits (loss 21.026, data 19.548) 0.00031 lr
Epoch 54 Iter 3200, train entropy gap 1.1401 bits (loss 20.688, data 19.548) 0.00030 lr
Epoch 54 Iter 3400, train entropy gap 2.7023 bits (loss 22.250, data 19.548) 0.00030 lr
Epoch 54 Iter 3600, train entropy gap 2.9089 bits (loss 22.457, data 19.548) 0.00030 lr
Epoch 54 Iter 3800, train entropy gap 2.2907 bits (loss 21.838, data 19.548) 0.00030 lr
Epoch 54 Iter 4000, train entropy gap 1.8037 bits (loss 21.351, data 19.548) 0.00030 lr
Epoch 54 Iter 4200, train entropy gap 1.8197 bits (loss 21.367, data 19.548) 0.00030 lr
Epoch 54 Iter 4400, train entropy gap 1.0037 bits (loss 20.551, data 19.548) 0.00030 lr
Epoch 54 Iter 4600, train entropy gap 1.0758 bits (loss 20.623, data 19.548) 0.00030 lr
Epoch 54 Iter 4800, train entropy gap 1.8608 bits (loss 21.408, data 19.548) 0.00030 lr
Epoch 54 Iter 5000, train entropy gap 2.7826 bits (loss 22.330, data 19.548) 0.00030 lr
Epoch 54 Iter 5200, train entropy gap 1.8922 bits (loss 21.440, data 19.548) 0.00030 lr
Epoch 54 Iter 5400, train entropy gap 0.9050 bits (loss 20.453, data 19.548) 0.00030 lr
Epoch 54 Iter 5600, train entropy gap 1.9506 bits (loss 21.498, data 19.548) 0.00030 lr
Epoch 54 Iter 5800, train entropy gap 1.7514 bits (loss 21.299, data 19.548) 0.00030 lr
Epoch 54 Iter 6000, train entropy gap 1.4667 bits (loss 21.014, data 19.548) 0.00030 lr
epoch 54 train loss 14.7303 nats / 21.2514 bits
time since start: 7747.1 secs
Epoch 55 Iter 0, train entropy gap 2.7598 bits (loss 22.307, data 19.548) 0.00030 lr
Epoch 55 Iter 200, train entropy gap 1.5291 bits (loss 21.077, data 19.548) 0.00030 lr
Epoch 55 Iter 400, train entropy gap 1.6195 bits (loss 21.167, data 19.548) 0.00030 lr
Epoch 55 Iter 600, train entropy gap 2.3597 bits (loss 21.907, data 19.548) 0.00030 lr
Epoch 55 Iter 800, train entropy gap 1.4029 bits (loss 20.951, data 19.548) 0.00030 lr
Epoch 55 Iter 1000, train entropy gap 1.7566 bits (loss 21.304, data 19.548) 0.00030 lr
Epoch 55 Iter 1200, train entropy gap 1.3506 bits (loss 20.898, data 19.548) 0.00030 lr
Epoch 55 Iter 1400, train entropy gap 0.8496 bits (loss 20.397, data 19.548) 0.00030 lr
Epoch 55 Iter 1600, train entropy gap 2.1697 bits (loss 21.717, data 19.548) 0.00030 lr
Epoch 55 Iter 1800, train entropy gap 1.4562 bits (loss 21.004, data 19.548) 0.00030 lr
Epoch 55 Iter 2000, train entropy gap 1.5159 bits (loss 21.064, data 19.548) 0.00030 lr
Epoch 55 Iter 2200, train entropy gap 1.4749 bits (loss 21.023, data 19.548) 0.00030 lr
Epoch 55 Iter 2400, train entropy gap 1.4794 bits (loss 21.027, data 19.548) 0.00030 lr
Epoch 55 Iter 2600, train entropy gap 1.3510 bits (loss 20.899, data 19.548) 0.00030 lr
Epoch 55 Iter 2800, train entropy gap 1.1468 bits (loss 20.695, data 19.548) 0.00030 lr
Epoch 55 Iter 3000, train entropy gap 0.8749 bits (loss 20.423, data 19.548) 0.00030 lr
Epoch 55 Iter 3200, train entropy gap 1.7120 bits (loss 21.260, data 19.548) 0.00030 lr
Epoch 55 Iter 3400, train entropy gap 1.9474 bits (loss 21.495, data 19.548) 0.00030 lr
Epoch 55 Iter 3600, train entropy gap 1.0343 bits (loss 20.582, data 19.548) 0.00030 lr
Epoch 55 Iter 3800, train entropy gap 1.5438 bits (loss 21.092, data 19.548) 0.00030 lr
Epoch 55 Iter 4000, train entropy gap 0.7669 bits (loss 20.315, data 19.548) 0.00030 lr
Epoch 55 Iter 4200, train entropy gap 1.1017 bits (loss 20.649, data 19.548) 0.00030 lr
Epoch 55 Iter 4400, train entropy gap 1.4854 bits (loss 21.033, data 19.548) 0.00030 lr
Epoch 55 Iter 4600, train entropy gap 1.7017 bits (loss 21.249, data 19.548) 0.00030 lr
Epoch 55 Iter 4800, train entropy gap 2.5558 bits (loss 22.104, data 19.548) 0.00030 lr
Epoch 55 Iter 5000, train entropy gap 2.7276 bits (loss 22.275, data 19.548) 0.00030 lr
Epoch 55 Iter 5200, train entropy gap 2.3853 bits (loss 21.933, data 19.548) 0.00030 lr
Epoch 55 Iter 5400, train entropy gap 1.6732 bits (loss 21.221, data 19.548) 0.00030 lr
Epoch 55 Iter 5600, train entropy gap 1.5134 bits (loss 21.061, data 19.548) 0.00030 lr
Epoch 55 Iter 5800, train entropy gap 2.2938 bits (loss 21.841, data 19.548) 0.00030 lr
Epoch 55 Iter 6000, train entropy gap 1.0377 bits (loss 20.585, data 19.548) 0.00030 lr
epoch 55 train loss 14.7409 nats / 21.2666 bits
time since start: 7886.4 secs
Epoch 56 Iter 0, train entropy gap 1.8046 bits (loss 21.352, data 19.548) 0.00030 lr
Epoch 56 Iter 200, train entropy gap 1.5672 bits (loss 21.115, data 19.548) 0.00030 lr
Epoch 56 Iter 400, train entropy gap 1.6596 bits (loss 21.207, data 19.548) 0.00030 lr
Epoch 56 Iter 600, train entropy gap 1.8523 bits (loss 21.400, data 19.548) 0.00030 lr
Epoch 56 Iter 800, train entropy gap 0.9233 bits (loss 20.471, data 19.548) 0.00030 lr
Epoch 56 Iter 1000, train entropy gap 2.3059 bits (loss 21.854, data 19.548) 0.00030 lr
Epoch 56 Iter 1200, train entropy gap 1.9379 bits (loss 21.486, data 19.548) 0.00030 lr
Epoch 56 Iter 1400, train entropy gap 1.5862 bits (loss 21.134, data 19.548) 0.00030 lr
Epoch 56 Iter 1600, train entropy gap 2.7512 bits (loss 22.299, data 19.548) 0.00030 lr
Epoch 56 Iter 1800, train entropy gap 1.4815 bits (loss 21.029, data 19.548) 0.00030 lr
Epoch 56 Iter 2000, train entropy gap 2.0781 bits (loss 21.626, data 19.548) 0.00030 lr
Epoch 56 Iter 2200, train entropy gap 1.8826 bits (loss 21.430, data 19.548) 0.00030 lr
Epoch 56 Iter 2400, train entropy gap 2.8205 bits (loss 22.368, data 19.548) 0.00030 lr
Epoch 56 Iter 2600, train entropy gap 1.4408 bits (loss 20.989, data 19.548) 0.00030 lr
Epoch 56 Iter 2800, train entropy gap 1.4047 bits (loss 20.952, data 19.548) 0.00030 lr
Epoch 56 Iter 3000, train entropy gap 2.6681 bits (loss 22.216, data 19.548) 0.00030 lr
Epoch 56 Iter 3200, train entropy gap 1.2245 bits (loss 20.772, data 19.548) 0.00030 lr
Epoch 56 Iter 3400, train entropy gap 1.6991 bits (loss 21.247, data 19.548) 0.00030 lr
Epoch 56 Iter 3600, train entropy gap 1.2511 bits (loss 20.799, data 19.548) 0.00030 lr
Epoch 56 Iter 3800, train entropy gap 1.2484 bits (loss 20.796, data 19.548) 0.00030 lr
Epoch 56 Iter 4000, train entropy gap 1.6105 bits (loss 21.158, data 19.548) 0.00030 lr
Epoch 56 Iter 4200, train entropy gap 1.0068 bits (loss 20.555, data 19.548) 0.00030 lr
Epoch 56 Iter 4400, train entropy gap 1.8921 bits (loss 21.440, data 19.548) 0.00030 lr
Epoch 56 Iter 4600, train entropy gap 1.7004 bits (loss 21.248, data 19.548) 0.00030 lr
Epoch 56 Iter 4800, train entropy gap 1.0402 bits (loss 20.588, data 19.548) 0.00030 lr
Epoch 56 Iter 5000, train entropy gap 2.2176 bits (loss 21.765, data 19.548) 0.00030 lr
Epoch 56 Iter 5200, train entropy gap 0.7283 bits (loss 20.276, data 19.548) 0.00030 lr
Epoch 56 Iter 5400, train entropy gap 1.2144 bits (loss 20.762, data 19.548) 0.00030 lr
Epoch 56 Iter 5600, train entropy gap 2.0405 bits (loss 21.588, data 19.548) 0.00030 lr
Epoch 56 Iter 5800, train entropy gap 1.1355 bits (loss 20.683, data 19.548) 0.00030 lr
Epoch 56 Iter 6000, train entropy gap 1.7136 bits (loss 21.261, data 19.548) 0.00030 lr
epoch 56 train loss 14.7359 nats / 21.2595 bits
time since start: 8027.5 secs
Epoch 57 Iter 0, train entropy gap 1.8334 bits (loss 21.381, data 19.548) 0.00030 lr
Epoch 57 Iter 200, train entropy gap 2.2004 bits (loss 21.748, data 19.548) 0.00030 lr
Epoch 57 Iter 400, train entropy gap 1.0365 bits (loss 20.584, data 19.548) 0.00030 lr
Epoch 57 Iter 600, train entropy gap 1.3574 bits (loss 20.905, data 19.548) 0.00030 lr
Epoch 57 Iter 800, train entropy gap 1.3759 bits (loss 20.924, data 19.548) 0.00030 lr
Epoch 57 Iter 1000, train entropy gap 1.7284 bits (loss 21.276, data 19.548) 0.00030 lr
Epoch 57 Iter 1200, train entropy gap 1.2822 bits (loss 20.830, data 19.548) 0.00030 lr
Epoch 57 Iter 1400, train entropy gap 1.7010 bits (loss 21.249, data 19.548) 0.00030 lr
Epoch 57 Iter 1600, train entropy gap 1.2169 bits (loss 20.765, data 19.548) 0.00030 lr
Epoch 57 Iter 1800, train entropy gap 1.7442 bits (loss 21.292, data 19.548) 0.00030 lr
Epoch 57 Iter 2000, train entropy gap 1.2920 bits (loss 20.840, data 19.548) 0.00030 lr
Epoch 57 Iter 2200, train entropy gap 2.6492 bits (loss 22.197, data 19.548) 0.00030 lr
Epoch 57 Iter 2400, train entropy gap 2.2673 bits (loss 21.815, data 19.548) 0.00030 lr
Epoch 57 Iter 2600, train entropy gap 2.6525 bits (loss 22.200, data 19.548) 0.00030 lr
Epoch 57 Iter 2800, train entropy gap 1.0782 bits (loss 20.626, data 19.548) 0.00030 lr
Epoch 57 Iter 3000, train entropy gap 1.8489 bits (loss 21.397, data 19.548) 0.00030 lr
Epoch 57 Iter 3200, train entropy gap 1.3312 bits (loss 20.879, data 19.548) 0.00030 lr
Epoch 57 Iter 3400, train entropy gap 2.1265 bits (loss 21.674, data 19.548) 0.00030 lr
Epoch 57 Iter 3600, train entropy gap 1.4334 bits (loss 20.981, data 19.548) 0.00030 lr
Epoch 57 Iter 3800, train entropy gap 1.8905 bits (loss 21.438, data 19.548) 0.00030 lr
Epoch 57 Iter 4000, train entropy gap 1.1097 bits (loss 20.657, data 19.548) 0.00030 lr
Epoch 57 Iter 4200, train entropy gap 1.7459 bits (loss 21.294, data 19.548) 0.00030 lr
Epoch 57 Iter 4400, train entropy gap 1.9923 bits (loss 21.540, data 19.548) 0.00030 lr
Epoch 57 Iter 4600, train entropy gap 1.5668 bits (loss 21.114, data 19.548) 0.00030 lr
Epoch 57 Iter 4800, train entropy gap 2.0014 bits (loss 21.549, data 19.548) 0.00030 lr
Epoch 57 Iter 5000, train entropy gap 1.3079 bits (loss 20.856, data 19.548) 0.00030 lr
Epoch 57 Iter 5200, train entropy gap 1.5917 bits (loss 21.139, data 19.548) 0.00030 lr
Epoch 57 Iter 5400, train entropy gap 2.0133 bits (loss 21.561, data 19.548) 0.00030 lr
Epoch 57 Iter 5600, train entropy gap 0.9823 bits (loss 20.530, data 19.548) 0.00030 lr
Epoch 57 Iter 5800, train entropy gap 1.6615 bits (loss 21.209, data 19.548) 0.00030 lr
Epoch 57 Iter 6000, train entropy gap 0.9070 bits (loss 20.455, data 19.548) 0.00030 lr
epoch 57 train loss 14.7344 nats / 21.2572 bits
time since start: 8168.3 secs
Epoch 58 Iter 0, train entropy gap 1.2131 bits (loss 20.761, data 19.548) 0.00030 lr
Epoch 58 Iter 200, train entropy gap 1.2383 bits (loss 20.786, data 19.548) 0.00030 lr
Epoch 58 Iter 400, train entropy gap 0.6947 bits (loss 20.242, data 19.548) 0.00030 lr
Epoch 58 Iter 600, train entropy gap 2.5799 bits (loss 22.128, data 19.548) 0.00030 lr
Epoch 58 Iter 800, train entropy gap 3.4380 bits (loss 22.986, data 19.548) 0.00030 lr
Epoch 58 Iter 1000, train entropy gap 0.9058 bits (loss 20.454, data 19.548) 0.00030 lr
Epoch 58 Iter 1200, train entropy gap 1.9492 bits (loss 21.497, data 19.548) 0.00030 lr
Epoch 58 Iter 1400, train entropy gap 1.9117 bits (loss 21.459, data 19.548) 0.00030 lr
Epoch 58 Iter 1600, train entropy gap 1.4122 bits (loss 20.960, data 19.548) 0.00030 lr
Epoch 58 Iter 1800, train entropy gap 1.7427 bits (loss 21.290, data 19.548) 0.00029 lr
Epoch 58 Iter 2000, train entropy gap 0.9776 bits (loss 20.525, data 19.548) 0.00029 lr
Epoch 58 Iter 2200, train entropy gap 1.6924 bits (loss 21.240, data 19.548) 0.00029 lr
Epoch 58 Iter 2400, train entropy gap 2.5028 bits (loss 22.050, data 19.548) 0.00029 lr
Epoch 58 Iter 2600, train entropy gap 1.7520 bits (loss 21.300, data 19.548) 0.00029 lr
Epoch 58 Iter 2800, train entropy gap 1.1379 bits (loss 20.686, data 19.548) 0.00029 lr
Epoch 58 Iter 3000, train entropy gap 1.8982 bits (loss 21.446, data 19.548) 0.00029 lr
Epoch 58 Iter 3200, train entropy gap 1.6695 bits (loss 21.217, data 19.548) 0.00029 lr
Epoch 58 Iter 3400, train entropy gap 1.9026 bits (loss 21.450, data 19.548) 0.00029 lr
Epoch 58 Iter 3600, train entropy gap 1.3795 bits (loss 20.927, data 19.548) 0.00029 lr
Epoch 58 Iter 3800, train entropy gap 1.3933 bits (loss 20.941, data 19.548) 0.00029 lr
Epoch 58 Iter 4000, train entropy gap 1.5044 bits (loss 21.052, data 19.548) 0.00029 lr
Epoch 58 Iter 4200, train entropy gap 2.0207 bits (loss 21.568, data 19.548) 0.00029 lr
Epoch 58 Iter 4400, train entropy gap 0.9053 bits (loss 20.453, data 19.548) 0.00029 lr
Epoch 58 Iter 4600, train entropy gap 1.1421 bits (loss 20.690, data 19.548) 0.00029 lr
Epoch 58 Iter 4800, train entropy gap 2.1344 bits (loss 21.682, data 19.548) 0.00029 lr
Epoch 58 Iter 5000, train entropy gap 1.1219 bits (loss 20.670, data 19.548) 0.00029 lr
Epoch 58 Iter 5200, train entropy gap 1.5723 bits (loss 21.120, data 19.548) 0.00029 lr
Epoch 58 Iter 5400, train entropy gap 1.5149 bits (loss 21.063, data 19.548) 0.00029 lr
Epoch 58 Iter 5600, train entropy gap 1.4835 bits (loss 21.031, data 19.548) 0.00029 lr
Epoch 58 Iter 5800, train entropy gap 1.4446 bits (loss 20.992, data 19.548) 0.00029 lr
Epoch 58 Iter 6000, train entropy gap 1.8538 bits (loss 21.402, data 19.548) 0.00029 lr
epoch 58 train loss 14.7293 nats / 21.2498 bits
time since start: 8309.2 secs
Epoch 59 Iter 0, train entropy gap 1.7700 bits (loss 21.318, data 19.548) 0.00029 lr
Epoch 59 Iter 200, train entropy gap 2.2748 bits (loss 21.823, data 19.548) 0.00029 lr
Epoch 59 Iter 400, train entropy gap 1.3197 bits (loss 20.867, data 19.548) 0.00029 lr
Epoch 59 Iter 600, train entropy gap 0.9217 bits (loss 20.469, data 19.548) 0.00029 lr
Epoch 59 Iter 800, train entropy gap 1.8051 bits (loss 21.353, data 19.548) 0.00029 lr
Epoch 59 Iter 1000, train entropy gap 2.1229 bits (loss 21.671, data 19.548) 0.00029 lr
Epoch 59 Iter 1200, train entropy gap 2.6107 bits (loss 22.158, data 19.548) 0.00029 lr
Epoch 59 Iter 1400, train entropy gap 1.8284 bits (loss 21.376, data 19.548) 0.00029 lr
Epoch 59 Iter 1600, train entropy gap 1.3652 bits (loss 20.913, data 19.548) 0.00029 lr
Epoch 59 Iter 1800, train entropy gap 1.5095 bits (loss 21.057, data 19.548) 0.00029 lr
Epoch 59 Iter 2000, train entropy gap 1.4078 bits (loss 20.956, data 19.548) 0.00029 lr
Epoch 59 Iter 2200, train entropy gap 1.0723 bits (loss 20.620, data 19.548) 0.00029 lr
Epoch 59 Iter 2400, train entropy gap 1.3861 bits (loss 20.934, data 19.548) 0.00029 lr
Epoch 59 Iter 2600, train entropy gap 1.2595 bits (loss 20.807, data 19.548) 0.00029 lr
Epoch 59 Iter 2800, train entropy gap 1.9702 bits (loss 21.518, data 19.548) 0.00029 lr
Epoch 59 Iter 3000, train entropy gap 2.4268 bits (loss 21.974, data 19.548) 0.00029 lr
Epoch 59 Iter 3200, train entropy gap 1.2803 bits (loss 20.828, data 19.548) 0.00029 lr
Epoch 59 Iter 3400, train entropy gap 1.4190 bits (loss 20.967, data 19.548) 0.00029 lr
Epoch 59 Iter 3600, train entropy gap 1.5122 bits (loss 21.060, data 19.548) 0.00029 lr
Epoch 59 Iter 3800, train entropy gap 1.6959 bits (loss 21.244, data 19.548) 0.00029 lr
Epoch 59 Iter 4000, train entropy gap 2.3972 bits (loss 21.945, data 19.548) 0.00029 lr
Epoch 59 Iter 4200, train entropy gap 1.5129 bits (loss 21.061, data 19.548) 0.00029 lr
Epoch 59 Iter 4400, train entropy gap 1.7625 bits (loss 21.310, data 19.548) 0.00029 lr
Epoch 59 Iter 4600, train entropy gap 1.4795 bits (loss 21.027, data 19.548) 0.00029 lr
Epoch 59 Iter 4800, train entropy gap 2.2601 bits (loss 21.808, data 19.548) 0.00029 lr
Epoch 59 Iter 5000, train entropy gap 2.3737 bits (loss 21.921, data 19.548) 0.00029 lr
Epoch 59 Iter 5200, train entropy gap 1.3187 bits (loss 20.866, data 19.548) 0.00029 lr
Epoch 59 Iter 5400, train entropy gap 2.5563 bits (loss 22.104, data 19.548) 0.00029 lr
Epoch 59 Iter 5600, train entropy gap 1.4907 bits (loss 21.038, data 19.548) 0.00029 lr
Epoch 59 Iter 5800, train entropy gap 1.4582 bits (loss 21.006, data 19.548) 0.00029 lr
Epoch 59 Iter 6000, train entropy gap 1.3764 bits (loss 20.924, data 19.548) 0.00029 lr
epoch 59 train loss 14.7436 nats / 21.2706 bits
time since start: 8449.9 secs
Epoch 60 Iter 0, train entropy gap 1.9899 bits (loss 21.538, data 19.548) 0.00029 lr
Epoch 60 Iter 200, train entropy gap 1.3806 bits (loss 20.928, data 19.548) 0.00029 lr
Epoch 60 Iter 400, train entropy gap 1.5317 bits (loss 21.079, data 19.548) 0.00029 lr
Epoch 60 Iter 600, train entropy gap 1.4262 bits (loss 20.974, data 19.548) 0.00029 lr
Epoch 60 Iter 800, train entropy gap 1.0315 bits (loss 20.579, data 19.548) 0.00029 lr
Epoch 60 Iter 1000, train entropy gap 0.6139 bits (loss 20.162, data 19.548) 0.00029 lr
Epoch 60 Iter 1200, train entropy gap 2.1947 bits (loss 21.742, data 19.548) 0.00029 lr
Epoch 60 Iter 1400, train entropy gap 1.5969 bits (loss 21.145, data 19.548) 0.00029 lr
Epoch 60 Iter 1600, train entropy gap 1.0174 bits (loss 20.565, data 19.548) 0.00029 lr
Epoch 60 Iter 1800, train entropy gap 2.8014 bits (loss 22.349, data 19.548) 0.00029 lr
Epoch 60 Iter 2000, train entropy gap 2.5570 bits (loss 22.105, data 19.548) 0.00029 lr
Epoch 60 Iter 2200, train entropy gap 1.3584 bits (loss 20.906, data 19.548) 0.00029 lr
Epoch 60 Iter 2400, train entropy gap 1.6659 bits (loss 21.214, data 19.548) 0.00029 lr
Epoch 60 Iter 2600, train entropy gap 1.7663 bits (loss 21.314, data 19.548) 0.00029 lr
Epoch 60 Iter 2800, train entropy gap 1.6227 bits (loss 21.170, data 19.548) 0.00029 lr
Epoch 60 Iter 3000, train entropy gap 1.7782 bits (loss 21.326, data 19.548) 0.00029 lr
Epoch 60 Iter 3200, train entropy gap 1.9015 bits (loss 21.449, data 19.548) 0.00029 lr
Epoch 60 Iter 3400, train entropy gap 1.6825 bits (loss 21.230, data 19.548) 0.00029 lr
Epoch 60 Iter 3600, train entropy gap 1.6298 bits (loss 21.178, data 19.548) 0.00029 lr
Epoch 60 Iter 3800, train entropy gap 1.5329 bits (loss 21.081, data 19.548) 0.00029 lr
Epoch 60 Iter 4000, train entropy gap 1.9724 bits (loss 21.520, data 19.548) 0.00029 lr
Epoch 60 Iter 4200, train entropy gap 1.1749 bits (loss 20.723, data 19.548) 0.00029 lr
Epoch 60 Iter 4400, train entropy gap 1.1460 bits (loss 20.694, data 19.548) 0.00029 lr
Epoch 60 Iter 4600, train entropy gap 1.6819 bits (loss 21.230, data 19.548) 0.00029 lr
Epoch 60 Iter 4800, train entropy gap 1.3324 bits (loss 20.880, data 19.548) 0.00029 lr
Epoch 60 Iter 5000, train entropy gap 1.1736 bits (loss 20.721, data 19.548) 0.00029 lr
Epoch 60 Iter 5200, train entropy gap 2.2154 bits (loss 21.763, data 19.548) 0.00029 lr
Epoch 60 Iter 5400, train entropy gap 1.9364 bits (loss 21.484, data 19.548) 0.00029 lr
Epoch 60 Iter 5600, train entropy gap 2.1680 bits (loss 21.716, data 19.548) 0.00029 lr
Epoch 60 Iter 5800, train entropy gap 2.2591 bits (loss 21.807, data 19.548) 0.00029 lr
Epoch 60 Iter 6000, train entropy gap 2.0626 bits (loss 21.610, data 19.548) 0.00029 lr
epoch 60 train loss 14.7306 nats / 21.2518 bits
time since start: 8590.6 secs
Epoch 61 Iter 0, train entropy gap 1.6466 bits (loss 21.194, data 19.548) 0.00029 lr
Epoch 61 Iter 200, train entropy gap 1.2300 bits (loss 20.778, data 19.548) 0.00029 lr
Epoch 61 Iter 400, train entropy gap 2.7990 bits (loss 22.347, data 19.548) 0.00029 lr
Epoch 61 Iter 600, train entropy gap 1.7506 bits (loss 21.298, data 19.548) 0.00029 lr
Epoch 61 Iter 800, train entropy gap 1.7523 bits (loss 21.300, data 19.548) 0.00029 lr
Epoch 61 Iter 1000, train entropy gap 1.0713 bits (loss 20.619, data 19.548) 0.00029 lr
Epoch 61 Iter 1200, train entropy gap 1.7430 bits (loss 21.291, data 19.548) 0.00029 lr
Epoch 61 Iter 1400, train entropy gap 0.7205 bits (loss 20.268, data 19.548) 0.00029 lr
Epoch 61 Iter 1600, train entropy gap 2.0759 bits (loss 21.624, data 19.548) 0.00029 lr
Epoch 61 Iter 1800, train entropy gap 2.1768 bits (loss 21.724, data 19.548) 0.00029 lr
Epoch 61 Iter 2000, train entropy gap 2.3550 bits (loss 21.903, data 19.548) 0.00029 lr
Epoch 61 Iter 2200, train entropy gap 1.5727 bits (loss 21.120, data 19.548) 0.00029 lr
Epoch 61 Iter 2400, train entropy gap 1.9521 bits (loss 21.500, data 19.548) 0.00029 lr
Epoch 61 Iter 2600, train entropy gap 1.8215 bits (loss 21.369, data 19.548) 0.00029 lr
Epoch 61 Iter 2800, train entropy gap 1.7590 bits (loss 21.307, data 19.548) 0.00029 lr
Epoch 61 Iter 3000, train entropy gap 1.4222 bits (loss 20.970, data 19.548) 0.00029 lr
Epoch 61 Iter 3200, train entropy gap 1.4393 bits (loss 20.987, data 19.548) 0.00029 lr
Epoch 61 Iter 3400, train entropy gap 1.4684 bits (loss 21.016, data 19.548) 0.00029 lr
Epoch 61 Iter 3600, train entropy gap 1.4630 bits (loss 21.011, data 19.548) 0.00029 lr
Epoch 61 Iter 3800, train entropy gap 1.3872 bits (loss 20.935, data 19.548) 0.00029 lr
Epoch 61 Iter 4000, train entropy gap 2.9443 bits (loss 22.492, data 19.548) 0.00029 lr
Epoch 61 Iter 4200, train entropy gap 2.6097 bits (loss 22.157, data 19.548) 0.00029 lr
Epoch 61 Iter 4400, train entropy gap 1.3391 bits (loss 20.887, data 19.548) 0.00029 lr
Epoch 61 Iter 4600, train entropy gap 1.6982 bits (loss 21.246, data 19.548) 0.00029 lr
Epoch 61 Iter 4800, train entropy gap 2.0599 bits (loss 21.608, data 19.548) 0.00029 lr
Epoch 61 Iter 5000, train entropy gap 2.4519 bits (loss 22.000, data 19.548) 0.00029 lr
Epoch 61 Iter 5200, train entropy gap 2.2973 bits (loss 21.845, data 19.548) 0.00029 lr
Epoch 61 Iter 5400, train entropy gap 1.4353 bits (loss 20.983, data 19.548) 0.00029 lr
Epoch 61 Iter 5600, train entropy gap 1.2417 bits (loss 20.789, data 19.548) 0.00029 lr
Epoch 61 Iter 5800, train entropy gap 1.0628 bits (loss 20.611, data 19.548) 0.00029 lr
Epoch 61 Iter 6000, train entropy gap 0.7400 bits (loss 20.288, data 19.548) 0.00029 lr
epoch 61 train loss 14.7415 nats / 21.2676 bits
time since start: 8731.5 secs
Epoch 62 Iter 0, train entropy gap 1.6896 bits (loss 21.237, data 19.548) 0.00029 lr
Epoch 62 Iter 200, train entropy gap 1.5365 bits (loss 21.084, data 19.548) 0.00029 lr
Epoch 62 Iter 400, train entropy gap 1.7500 bits (loss 21.298, data 19.548) 0.00029 lr
Epoch 62 Iter 600, train entropy gap 1.1853 bits (loss 20.733, data 19.548) 0.00029 lr
Epoch 62 Iter 800, train entropy gap 1.7755 bits (loss 21.323, data 19.548) 0.00029 lr
Epoch 62 Iter 1000, train entropy gap 1.4979 bits (loss 21.046, data 19.548) 0.00029 lr
Epoch 62 Iter 1200, train entropy gap 1.4539 bits (loss 21.002, data 19.548) 0.00029 lr
Epoch 62 Iter 1400, train entropy gap 1.6738 bits (loss 21.222, data 19.548) 0.00029 lr
Epoch 62 Iter 1600, train entropy gap 1.6191 bits (loss 21.167, data 19.548) 0.00029 lr
Epoch 62 Iter 1800, train entropy gap 1.9055 bits (loss 21.453, data 19.548) 0.00029 lr
Epoch 62 Iter 2000, train entropy gap 1.1097 bits (loss 20.657, data 19.548) 0.00029 lr
Epoch 62 Iter 2200, train entropy gap 1.5290 bits (loss 21.077, data 19.548) 0.00029 lr
Epoch 62 Iter 2400, train entropy gap 1.5449 bits (loss 21.093, data 19.548) 0.00029 lr
Epoch 62 Iter 2600, train entropy gap 1.6648 bits (loss 21.213, data 19.548) 0.00029 lr
Epoch 62 Iter 2800, train entropy gap 1.2779 bits (loss 20.826, data 19.548) 0.00028 lr
Epoch 62 Iter 3000, train entropy gap 1.1196 bits (loss 20.667, data 19.548) 0.00028 lr
Epoch 62 Iter 3200, train entropy gap 1.4170 bits (loss 20.965, data 19.548) 0.00028 lr
Epoch 62 Iter 3400, train entropy gap 1.6727 bits (loss 21.220, data 19.548) 0.00028 lr
Epoch 62 Iter 3600, train entropy gap 1.4605 bits (loss 21.008, data 19.548) 0.00028 lr
Epoch 62 Iter 3800, train entropy gap 1.1802 bits (loss 20.728, data 19.548) 0.00028 lr
Epoch 62 Iter 4000, train entropy gap 1.9496 bits (loss 21.497, data 19.548) 0.00028 lr
Epoch 62 Iter 4200, train entropy gap 2.0383 bits (loss 21.586, data 19.548) 0.00028 lr
Epoch 62 Iter 4400, train entropy gap 1.3211 bits (loss 20.869, data 19.548) 0.00028 lr
Epoch 62 Iter 4600, train entropy gap 1.2979 bits (loss 20.846, data 19.548) 0.00028 lr
Epoch 62 Iter 4800, train entropy gap 1.7662 bits (loss 21.314, data 19.548) 0.00028 lr
Epoch 62 Iter 5000, train entropy gap 3.1816 bits (loss 22.729, data 19.548) 0.00028 lr
Epoch 62 Iter 5200, train entropy gap 1.6843 bits (loss 21.232, data 19.548) 0.00028 lr
Epoch 62 Iter 5400, train entropy gap 1.8544 bits (loss 21.402, data 19.548) 0.00028 lr
Epoch 62 Iter 5600, train entropy gap 1.5020 bits (loss 21.050, data 19.548) 0.00028 lr
Epoch 62 Iter 5800, train entropy gap 1.0420 bits (loss 20.590, data 19.548) 0.00028 lr
Epoch 62 Iter 6000, train entropy gap 2.1349 bits (loss 21.683, data 19.548) 0.00028 lr
epoch 62 train loss 14.7311 nats / 21.2525 bits
time since start: 8872.2 secs
Epoch 63 Iter 0, train entropy gap 2.4877 bits (loss 22.035, data 19.548) 0.00028 lr
Epoch 63 Iter 200, train entropy gap 2.4340 bits (loss 21.982, data 19.548) 0.00028 lr
Epoch 63 Iter 400, train entropy gap 1.8976 bits (loss 21.445, data 19.548) 0.00028 lr
Epoch 63 Iter 600, train entropy gap 2.5013 bits (loss 22.049, data 19.548) 0.00028 lr
Epoch 63 Iter 800, train entropy gap 1.7030 bits (loss 21.251, data 19.548) 0.00028 lr
Epoch 63 Iter 1000, train entropy gap 1.0516 bits (loss 20.599, data 19.548) 0.00028 lr
Epoch 63 Iter 1200, train entropy gap 0.8081 bits (loss 20.356, data 19.548) 0.00028 lr
Epoch 63 Iter 1400, train entropy gap 2.4013 bits (loss 21.949, data 19.548) 0.00028 lr
Epoch 63 Iter 1600, train entropy gap 1.1935 bits (loss 20.741, data 19.548) 0.00028 lr
Epoch 63 Iter 1800, train entropy gap 2.9084 bits (loss 22.456, data 19.548) 0.00028 lr
Epoch 63 Iter 2000, train entropy gap 1.8531 bits (loss 21.401, data 19.548) 0.00028 lr
Epoch 63 Iter 2200, train entropy gap 0.8547 bits (loss 20.402, data 19.548) 0.00028 lr
Epoch 63 Iter 2400, train entropy gap 0.9248 bits (loss 20.473, data 19.548) 0.00028 lr
Epoch 63 Iter 2600, train entropy gap 1.7781 bits (loss 21.326, data 19.548) 0.00028 lr
Epoch 63 Iter 2800, train entropy gap 0.9531 bits (loss 20.501, data 19.548) 0.00028 lr
Epoch 63 Iter 3000, train entropy gap 3.1297 bits (loss 22.677, data 19.548) 0.00028 lr
Epoch 63 Iter 3200, train entropy gap 1.5389 bits (loss 21.087, data 19.548) 0.00028 lr
Epoch 63 Iter 3400, train entropy gap 1.7780 bits (loss 21.326, data 19.548) 0.00028 lr
Epoch 63 Iter 3600, train entropy gap 2.0621 bits (loss 21.610, data 19.548) 0.00028 lr
Epoch 63 Iter 3800, train entropy gap 2.0977 bits (loss 21.645, data 19.548) 0.00028 lr
Epoch 63 Iter 4000, train entropy gap 1.2272 bits (loss 20.775, data 19.548) 0.00028 lr
Epoch 63 Iter 4200, train entropy gap 1.3963 bits (loss 20.944, data 19.548) 0.00028 lr
Epoch 63 Iter 4400, train entropy gap 1.2267 bits (loss 20.774, data 19.548) 0.00028 lr
Epoch 63 Iter 4600, train entropy gap 0.9356 bits (loss 20.483, data 19.548) 0.00028 lr
Epoch 63 Iter 4800, train entropy gap 2.1532 bits (loss 21.701, data 19.548) 0.00028 lr
Epoch 63 Iter 5000, train entropy gap 1.5546 bits (loss 21.102, data 19.548) 0.00028 lr
Epoch 63 Iter 5200, train entropy gap 1.6594 bits (loss 21.207, data 19.548) 0.00028 lr
Epoch 63 Iter 5400, train entropy gap 2.0124 bits (loss 21.560, data 19.548) 0.00028 lr
Epoch 63 Iter 5600, train entropy gap 2.0801 bits (loss 21.628, data 19.548) 0.00028 lr
Epoch 63 Iter 5800, train entropy gap 1.6993 bits (loss 21.247, data 19.548) 0.00028 lr
Epoch 63 Iter 6000, train entropy gap 0.8603 bits (loss 20.408, data 19.548) 0.00028 lr
epoch 63 train loss 14.7388 nats / 21.2637 bits
time since start: 9013.1 secs
Epoch 64 Iter 0, train entropy gap 2.1874 bits (loss 21.735, data 19.548) 0.00028 lr
Epoch 64 Iter 200, train entropy gap 1.9540 bits (loss 21.502, data 19.548) 0.00028 lr
Epoch 64 Iter 400, train entropy gap 1.2287 bits (loss 20.776, data 19.548) 0.00028 lr
Epoch 64 Iter 600, train entropy gap 2.0871 bits (loss 21.635, data 19.548) 0.00028 lr
Epoch 64 Iter 800, train entropy gap 1.5901 bits (loss 21.138, data 19.548) 0.00028 lr
Epoch 64 Iter 1000, train entropy gap 1.2335 bits (loss 20.781, data 19.548) 0.00028 lr
Epoch 64 Iter 1200, train entropy gap 2.0499 bits (loss 21.598, data 19.548) 0.00028 lr
Epoch 64 Iter 1400, train entropy gap 2.3871 bits (loss 21.935, data 19.548) 0.00028 lr
Epoch 64 Iter 1600, train entropy gap 1.4289 bits (loss 20.977, data 19.548) 0.00028 lr
Epoch 64 Iter 1800, train entropy gap 1.8852 bits (loss 21.433, data 19.548) 0.00028 lr
Epoch 64 Iter 2000, train entropy gap 1.0589 bits (loss 20.607, data 19.548) 0.00028 lr
Epoch 64 Iter 2200, train entropy gap 2.6081 bits (loss 22.156, data 19.548) 0.00028 lr
Epoch 64 Iter 2400, train entropy gap 1.3061 bits (loss 20.854, data 19.548) 0.00028 lr
Epoch 64 Iter 2600, train entropy gap 1.3789 bits (loss 20.927, data 19.548) 0.00028 lr
Epoch 64 Iter 2800, train entropy gap 1.6846 bits (loss 21.232, data 19.548) 0.00028 lr
Epoch 64 Iter 3000, train entropy gap 1.5471 bits (loss 21.095, data 19.548) 0.00028 lr
Epoch 64 Iter 3200, train entropy gap 1.0939 bits (loss 20.642, data 19.548) 0.00028 lr
Epoch 64 Iter 3400, train entropy gap 1.1233 bits (loss 20.671, data 19.548) 0.00028 lr
Epoch 64 Iter 3600, train entropy gap 1.6130 bits (loss 21.161, data 19.548) 0.00028 lr
Epoch 64 Iter 3800, train entropy gap 1.4977 bits (loss 21.045, data 19.548) 0.00028 lr
Epoch 64 Iter 4000, train entropy gap 3.0069 bits (loss 22.555, data 19.548) 0.00028 lr
Epoch 64 Iter 4200, train entropy gap 2.0287 bits (loss 21.576, data 19.548) 0.00028 lr
Epoch 64 Iter 4400, train entropy gap 1.2899 bits (loss 20.838, data 19.548) 0.00028 lr
Epoch 64 Iter 4600, train entropy gap 1.9358 bits (loss 21.484, data 19.548) 0.00028 lr
Epoch 64 Iter 4800, train entropy gap 1.0001 bits (loss 20.548, data 19.548) 0.00028 lr
Epoch 64 Iter 5000, train entropy gap 1.7901 bits (loss 21.338, data 19.548) 0.00028 lr
Epoch 64 Iter 5200, train entropy gap 1.4108 bits (loss 20.959, data 19.548) 0.00028 lr
Epoch 64 Iter 5400, train entropy gap 2.2732 bits (loss 21.821, data 19.548) 0.00028 lr
Epoch 64 Iter 5600, train entropy gap 1.8727 bits (loss 21.420, data 19.548) 0.00028 lr
Epoch 64 Iter 5800, train entropy gap 1.6220 bits (loss 21.170, data 19.548) 0.00028 lr
Epoch 64 Iter 6000, train entropy gap 1.7356 bits (loss 21.283, data 19.548) 0.00028 lr
epoch 64 train loss 14.7305 nats / 21.2516 bits
time since start: 9153.9 secs
Epoch 65 Iter 0, train entropy gap 2.4996 bits (loss 22.047, data 19.548) 0.00028 lr
Epoch 65 Iter 200, train entropy gap 1.2549 bits (loss 20.803, data 19.548) 0.00028 lr
Epoch 65 Iter 400, train entropy gap 2.1499 bits (loss 21.698, data 19.548) 0.00028 lr
Epoch 65 Iter 600, train entropy gap 1.3958 bits (loss 20.944, data 19.548) 0.00028 lr
Epoch 65 Iter 800, train entropy gap 1.4753 bits (loss 21.023, data 19.548) 0.00028 lr
Epoch 65 Iter 1000, train entropy gap 1.6106 bits (loss 21.158, data 19.548) 0.00028 lr
Epoch 65 Iter 1200, train entropy gap 1.7059 bits (loss 21.254, data 19.548) 0.00028 lr
Epoch 65 Iter 1400, train entropy gap 1.3527 bits (loss 20.900, data 19.548) 0.00028 lr
Epoch 65 Iter 1600, train entropy gap 1.0694 bits (loss 20.617, data 19.548) 0.00028 lr
Epoch 65 Iter 1800, train entropy gap 1.6852 bits (loss 21.233, data 19.548) 0.00028 lr
Epoch 65 Iter 2000, train entropy gap 1.0402 bits (loss 20.588, data 19.548) 0.00028 lr
Epoch 65 Iter 2200, train entropy gap 1.6162 bits (loss 21.164, data 19.548) 0.00028 lr
Epoch 65 Iter 2400, train entropy gap 1.2119 bits (loss 20.760, data 19.548) 0.00028 lr
Epoch 65 Iter 2600, train entropy gap 0.8436 bits (loss 20.391, data 19.548) 0.00028 lr
Epoch 65 Iter 2800, train entropy gap 1.6126 bits (loss 21.160, data 19.548) 0.00028 lr
Epoch 65 Iter 3000, train entropy gap 1.2975 bits (loss 20.845, data 19.548) 0.00028 lr
Epoch 65 Iter 3200, train entropy gap 0.9549 bits (loss 20.503, data 19.548) 0.00028 lr
Epoch 65 Iter 3400, train entropy gap 2.0176 bits (loss 21.565, data 19.548) 0.00028 lr
Epoch 65 Iter 3600, train entropy gap 2.3632 bits (loss 21.911, data 19.548) 0.00028 lr
Epoch 65 Iter 3800, train entropy gap 1.0185 bits (loss 20.566, data 19.548) 0.00028 lr
Epoch 65 Iter 4000, train entropy gap 1.3820 bits (loss 20.930, data 19.548) 0.00028 lr
Epoch 65 Iter 4200, train entropy gap 2.3393 bits (loss 21.887, data 19.548) 0.00028 lr
Epoch 65 Iter 4400, train entropy gap 1.0932 bits (loss 20.641, data 19.548) 0.00028 lr
Epoch 65 Iter 4600, train entropy gap 1.2136 bits (loss 20.761, data 19.548) 0.00028 lr
Epoch 65 Iter 4800, train entropy gap 1.6622 bits (loss 21.210, data 19.548) 0.00028 lr
Epoch 65 Iter 5000, train entropy gap 1.4252 bits (loss 20.973, data 19.548) 0.00028 lr
Epoch 65 Iter 5200, train entropy gap 1.6401 bits (loss 21.188, data 19.548) 0.00028 lr
Epoch 65 Iter 5400, train entropy gap 1.2483 bits (loss 20.796, data 19.548) 0.00028 lr
Epoch 65 Iter 5600, train entropy gap 1.7422 bits (loss 21.290, data 19.548) 0.00028 lr
Epoch 65 Iter 5800, train entropy gap 1.2755 bits (loss 20.823, data 19.548) 0.00028 lr
Epoch 65 Iter 6000, train entropy gap 1.7220 bits (loss 21.270, data 19.548) 0.00028 lr
epoch 65 train loss 14.7258 nats / 21.2449 bits
time since start: 9295.0 secs
Epoch 66 Iter 0, train entropy gap 1.3929 bits (loss 20.941, data 19.548) 0.00028 lr
Epoch 66 Iter 200, train entropy gap 1.7350 bits (loss 21.283, data 19.548) 0.00028 lr
Epoch 66 Iter 400, train entropy gap 1.0992 bits (loss 20.647, data 19.548) 0.00028 lr
Epoch 66 Iter 600, train entropy gap 2.0018 bits (loss 21.550, data 19.548) 0.00028 lr
Epoch 66 Iter 800, train entropy gap 1.4511 bits (loss 20.999, data 19.548) 0.00028 lr
Epoch 66 Iter 1000, train entropy gap 0.8790 bits (loss 20.427, data 19.548) 0.00028 lr
Epoch 66 Iter 1200, train entropy gap 2.5380 bits (loss 22.086, data 19.548) 0.00028 lr
Epoch 66 Iter 1400, train entropy gap 1.8018 bits (loss 21.349, data 19.548) 0.00028 lr
Epoch 66 Iter 1600, train entropy gap 3.1038 bits (loss 22.651, data 19.548) 0.00028 lr
Epoch 66 Iter 1800, train entropy gap 2.3822 bits (loss 21.930, data 19.548) 0.00028 lr
Epoch 66 Iter 2000, train entropy gap 1.2351 bits (loss 20.783, data 19.548) 0.00028 lr
Epoch 66 Iter 2200, train entropy gap 1.2744 bits (loss 20.822, data 19.548) 0.00028 lr
Epoch 66 Iter 2400, train entropy gap 1.8769 bits (loss 21.425, data 19.548) 0.00028 lr
Epoch 66 Iter 2600, train entropy gap 1.1622 bits (loss 20.710, data 19.548) 0.00028 lr
Epoch 66 Iter 2800, train entropy gap 1.9375 bits (loss 21.485, data 19.548) 0.00028 lr
Epoch 66 Iter 3000, train entropy gap 1.1020 bits (loss 20.650, data 19.548) 0.00028 lr
Epoch 66 Iter 3200, train entropy gap 2.0390 bits (loss 21.587, data 19.548) 0.00028 lr
Epoch 66 Iter 3400, train entropy gap 1.5541 bits (loss 21.102, data 19.548) 0.00028 lr
Epoch 66 Iter 3600, train entropy gap 1.8339 bits (loss 21.382, data 19.548) 0.00028 lr
Epoch 66 Iter 3800, train entropy gap 2.4144 bits (loss 21.962, data 19.548) 0.00028 lr
Epoch 66 Iter 4000, train entropy gap 2.7182 bits (loss 22.266, data 19.548) 0.00028 lr
Epoch 66 Iter 4200, train entropy gap 1.2396 bits (loss 20.787, data 19.548) 0.00028 lr
Epoch 66 Iter 4400, train entropy gap 1.2719 bits (loss 20.820, data 19.548) 0.00028 lr
Epoch 66 Iter 4600, train entropy gap 0.9686 bits (loss 20.516, data 19.548) 0.00028 lr
Epoch 66 Iter 4800, train entropy gap 1.0313 bits (loss 20.579, data 19.548) 0.00028 lr
Epoch 66 Iter 5000, train entropy gap 2.0734 bits (loss 21.621, data 19.548) 0.00028 lr
Epoch 66 Iter 5200, train entropy gap 2.2900 bits (loss 21.838, data 19.548) 0.00028 lr
Epoch 66 Iter 5400, train entropy gap 1.0864 bits (loss 20.634, data 19.548) 0.00028 lr
Epoch 66 Iter 5600, train entropy gap 1.7452 bits (loss 21.293, data 19.548) 0.00028 lr
Epoch 66 Iter 5800, train entropy gap 1.6054 bits (loss 21.153, data 19.548) 0.00028 lr
Epoch 66 Iter 6000, train entropy gap 1.2788 bits (loss 20.826, data 19.548) 0.00028 lr
epoch 66 train loss 14.7349 nats / 21.2580 bits
time since start: 9436.2 secs
Epoch 67 Iter 0, train entropy gap 1.1374 bits (loss 20.685, data 19.548) 0.00028 lr
Epoch 67 Iter 200, train entropy gap 0.9106 bits (loss 20.458, data 19.548) 0.00028 lr
Epoch 67 Iter 400, train entropy gap 2.5007 bits (loss 22.048, data 19.548) 0.00027 lr
Epoch 67 Iter 600, train entropy gap 1.8722 bits (loss 21.420, data 19.548) 0.00027 lr
Epoch 67 Iter 800, train entropy gap 1.3283 bits (loss 20.876, data 19.548) 0.00027 lr
Epoch 67 Iter 1000, train entropy gap 2.6407 bits (loss 22.188, data 19.548) 0.00027 lr
Epoch 67 Iter 1200, train entropy gap 1.8221 bits (loss 21.370, data 19.548) 0.00027 lr
Epoch 67 Iter 1400, train entropy gap 2.0378 bits (loss 21.586, data 19.548) 0.00027 lr
Epoch 67 Iter 1600, train entropy gap 1.5323 bits (loss 21.080, data 19.548) 0.00027 lr
Epoch 67 Iter 1800, train entropy gap 2.2402 bits (loss 21.788, data 19.548) 0.00027 lr
Epoch 67 Iter 2000, train entropy gap 1.7660 bits (loss 21.314, data 19.548) 0.00027 lr
Epoch 67 Iter 2200, train entropy gap 2.4288 bits (loss 21.976, data 19.548) 0.00027 lr
Epoch 67 Iter 2400, train entropy gap 1.4213 bits (loss 20.969, data 19.548) 0.00027 lr
Epoch 67 Iter 2600, train entropy gap 1.5462 bits (loss 21.094, data 19.548) 0.00027 lr
Epoch 67 Iter 2800, train entropy gap 2.8358 bits (loss 22.383, data 19.548) 0.00027 lr
Epoch 67 Iter 3000, train entropy gap 1.6572 bits (loss 21.205, data 19.548) 0.00027 lr
Epoch 67 Iter 3200, train entropy gap 1.0139 bits (loss 20.562, data 19.548) 0.00027 lr
Epoch 67 Iter 3400, train entropy gap 1.5584 bits (loss 21.106, data 19.548) 0.00027 lr
Epoch 67 Iter 3600, train entropy gap 1.6889 bits (loss 21.237, data 19.548) 0.00027 lr
Epoch 67 Iter 3800, train entropy gap 2.0929 bits (loss 21.641, data 19.548) 0.00027 lr
Epoch 67 Iter 4000, train entropy gap 1.7169 bits (loss 21.265, data 19.548) 0.00027 lr
Epoch 67 Iter 4200, train entropy gap 2.1420 bits (loss 21.690, data 19.548) 0.00027 lr
Epoch 67 Iter 4400, train entropy gap 1.3875 bits (loss 20.935, data 19.548) 0.00027 lr
Epoch 67 Iter 4600, train entropy gap 2.4702 bits (loss 22.018, data 19.548) 0.00027 lr
Epoch 67 Iter 4800, train entropy gap 2.5318 bits (loss 22.080, data 19.548) 0.00027 lr
Epoch 67 Iter 5000, train entropy gap 1.3824 bits (loss 20.930, data 19.548) 0.00027 lr
Epoch 67 Iter 5200, train entropy gap 2.5669 bits (loss 22.115, data 19.548) 0.00027 lr
Epoch 67 Iter 5400, train entropy gap 2.1082 bits (loss 21.656, data 19.548) 0.00027 lr
Epoch 67 Iter 5600, train entropy gap 1.8419 bits (loss 21.390, data 19.548) 0.00027 lr
Epoch 67 Iter 5800, train entropy gap 1.3127 bits (loss 20.860, data 19.548) 0.00027 lr
Epoch 67 Iter 6000, train entropy gap 1.4722 bits (loss 21.020, data 19.548) 0.00027 lr
epoch 67 train loss 14.7277 nats / 21.2476 bits
time since start: 9577.5 secs
Epoch 68 Iter 0, train entropy gap 2.1824 bits (loss 21.730, data 19.548) 0.00027 lr
Epoch 68 Iter 200, train entropy gap 2.4981 bits (loss 22.046, data 19.548) 0.00027 lr
Epoch 68 Iter 400, train entropy gap 1.3133 bits (loss 20.861, data 19.548) 0.00027 lr
Epoch 68 Iter 600, train entropy gap 2.1546 bits (loss 21.702, data 19.548) 0.00027 lr
Epoch 68 Iter 800, train entropy gap 1.4317 bits (loss 20.979, data 19.548) 0.00027 lr
Epoch 68 Iter 1000, train entropy gap 1.5521 bits (loss 21.100, data 19.548) 0.00027 lr
Epoch 68 Iter 1200, train entropy gap 0.8805 bits (loss 20.428, data 19.548) 0.00027 lr
Epoch 68 Iter 1400, train entropy gap 2.6677 bits (loss 22.215, data 19.548) 0.00027 lr
Epoch 68 Iter 1600, train entropy gap 1.5202 bits (loss 21.068, data 19.548) 0.00027 lr
Epoch 68 Iter 1800, train entropy gap 1.1322 bits (loss 20.680, data 19.548) 0.00027 lr
Epoch 68 Iter 2000, train entropy gap 0.9690 bits (loss 20.517, data 19.548) 0.00027 lr
Epoch 68 Iter 2200, train entropy gap 2.5091 bits (loss 22.057, data 19.548) 0.00027 lr
Epoch 68 Iter 2400, train entropy gap 2.3339 bits (loss 21.882, data 19.548) 0.00027 lr
Epoch 68 Iter 2600, train entropy gap 1.3950 bits (loss 20.943, data 19.548) 0.00027 lr
Epoch 68 Iter 2800, train entropy gap 1.6767 bits (loss 21.224, data 19.548) 0.00027 lr
Epoch 68 Iter 3000, train entropy gap 1.3781 bits (loss 20.926, data 19.548) 0.00027 lr
Epoch 68 Iter 3200, train entropy gap 1.5804 bits (loss 21.128, data 19.548) 0.00027 lr
Epoch 68 Iter 3400, train entropy gap 0.8956 bits (loss 20.443, data 19.548) 0.00027 lr
Epoch 68 Iter 3600, train entropy gap 2.1860 bits (loss 21.734, data 19.548) 0.00027 lr
Epoch 68 Iter 3800, train entropy gap 2.0789 bits (loss 21.627, data 19.548) 0.00027 lr
Epoch 68 Iter 4000, train entropy gap 2.1007 bits (loss 21.648, data 19.548) 0.00027 lr
Epoch 68 Iter 4200, train entropy gap 1.9639 bits (loss 21.512, data 19.548) 0.00027 lr
Epoch 68 Iter 4400, train entropy gap 1.1373 bits (loss 20.685, data 19.548) 0.00027 lr
Epoch 68 Iter 4600, train entropy gap 2.8828 bits (loss 22.430, data 19.548) 0.00027 lr
Epoch 68 Iter 4800, train entropy gap 2.2096 bits (loss 21.757, data 19.548) 0.00027 lr
Epoch 68 Iter 5000, train entropy gap 2.4806 bits (loss 22.028, data 19.548) 0.00027 lr
Epoch 68 Iter 5200, train entropy gap 2.0410 bits (loss 21.589, data 19.548) 0.00027 lr
Epoch 68 Iter 5400, train entropy gap 2.3268 bits (loss 21.875, data 19.548) 0.00027 lr
Epoch 68 Iter 5600, train entropy gap 1.6103 bits (loss 21.158, data 19.548) 0.00027 lr
Epoch 68 Iter 5800, train entropy gap 1.4925 bits (loss 21.040, data 19.548) 0.00027 lr
Epoch 68 Iter 6000, train entropy gap 2.3829 bits (loss 21.931, data 19.548) 0.00027 lr
epoch 68 train loss 14.7336 nats / 21.2561 bits
time since start: 9718.5 secs
Epoch 69 Iter 0, train entropy gap 2.6531 bits (loss 22.201, data 19.548) 0.00027 lr
Epoch 69 Iter 200, train entropy gap 2.1115 bits (loss 21.659, data 19.548) 0.00027 lr
Epoch 69 Iter 400, train entropy gap 1.6567 bits (loss 21.204, data 19.548) 0.00027 lr
Epoch 69 Iter 600, train entropy gap 1.1019 bits (loss 20.650, data 19.548) 0.00027 lr
Epoch 69 Iter 800, train entropy gap 1.3779 bits (loss 20.926, data 19.548) 0.00027 lr
Epoch 69 Iter 1000, train entropy gap 1.3157 bits (loss 20.863, data 19.548) 0.00027 lr
Epoch 69 Iter 1200, train entropy gap 1.3263 bits (loss 20.874, data 19.548) 0.00027 lr
Epoch 69 Iter 1400, train entropy gap 2.2963 bits (loss 21.844, data 19.548) 0.00027 lr
Epoch 69 Iter 1600, train entropy gap 0.9796 bits (loss 20.527, data 19.548) 0.00027 lr
Epoch 69 Iter 1800, train entropy gap 1.2929 bits (loss 20.841, data 19.548) 0.00027 lr
Epoch 69 Iter 2000, train entropy gap 1.5407 bits (loss 21.088, data 19.548) 0.00027 lr
Epoch 69 Iter 2200, train entropy gap 1.7477 bits (loss 21.295, data 19.548) 0.00027 lr
Epoch 69 Iter 2400, train entropy gap 1.3644 bits (loss 20.912, data 19.548) 0.00027 lr
Epoch 69 Iter 2600, train entropy gap 1.3142 bits (loss 20.862, data 19.548) 0.00027 lr
Epoch 69 Iter 2800, train entropy gap 0.9324 bits (loss 20.480, data 19.548) 0.00027 lr
Epoch 69 Iter 3000, train entropy gap 2.0793 bits (loss 21.627, data 19.548) 0.00027 lr
Epoch 69 Iter 3200, train entropy gap 1.5442 bits (loss 21.092, data 19.548) 0.00027 lr
Epoch 69 Iter 3400, train entropy gap 1.3093 bits (loss 20.857, data 19.548) 0.00027 lr
Epoch 69 Iter 3600, train entropy gap 1.6009 bits (loss 21.149, data 19.548) 0.00027 lr
Epoch 69 Iter 3800, train entropy gap 1.0299 bits (loss 20.578, data 19.548) 0.00027 lr
Epoch 69 Iter 4000, train entropy gap 1.6611 bits (loss 21.209, data 19.548) 0.00027 lr
Epoch 69 Iter 4200, train entropy gap 1.8421 bits (loss 21.390, data 19.548) 0.00027 lr
Epoch 69 Iter 4400, train entropy gap 2.3602 bits (loss 21.908, data 19.548) 0.00027 lr
Epoch 69 Iter 4600, train entropy gap 1.5935 bits (loss 21.141, data 19.548) 0.00027 lr
Epoch 69 Iter 4800, train entropy gap 1.8110 bits (loss 21.359, data 19.548) 0.00027 lr
Epoch 69 Iter 5000, train entropy gap 1.8485 bits (loss 21.396, data 19.548) 0.00027 lr
Epoch 69 Iter 5200, train entropy gap 1.1492 bits (loss 20.697, data 19.548) 0.00027 lr
Epoch 69 Iter 5400, train entropy gap 1.5960 bits (loss 21.144, data 19.548) 0.00027 lr
Epoch 69 Iter 5600, train entropy gap 2.2439 bits (loss 21.792, data 19.548) 0.00027 lr
Epoch 69 Iter 5800, train entropy gap 0.9802 bits (loss 20.528, data 19.548) 0.00027 lr
Epoch 69 Iter 6000, train entropy gap 2.2050 bits (loss 21.753, data 19.548) 0.00027 lr
epoch 69 train loss 14.7317 nats / 21.2534 bits
time since start: 9859.2 secs
Epoch 70 Iter 0, train entropy gap 1.1712 bits (loss 20.719, data 19.548) 0.00027 lr
Epoch 70 Iter 200, train entropy gap 1.8915 bits (loss 21.439, data 19.548) 0.00027 lr
Epoch 70 Iter 400, train entropy gap 1.4468 bits (loss 20.995, data 19.548) 0.00027 lr
Epoch 70 Iter 600, train entropy gap 1.2982 bits (loss 20.846, data 19.548) 0.00027 lr
Epoch 70 Iter 800, train entropy gap 0.8678 bits (loss 20.415, data 19.548) 0.00027 lr
Epoch 70 Iter 1000, train entropy gap 1.1283 bits (loss 20.676, data 19.548) 0.00027 lr
Epoch 70 Iter 1200, train entropy gap 1.1574 bits (loss 20.705, data 19.548) 0.00027 lr
Epoch 70 Iter 1400, train entropy gap 2.8666 bits (loss 22.414, data 19.548) 0.00027 lr
Epoch 70 Iter 1600, train entropy gap 1.2524 bits (loss 20.800, data 19.548) 0.00027 lr
Epoch 70 Iter 1800, train entropy gap 1.9461 bits (loss 21.494, data 19.548) 0.00027 lr
Epoch 70 Iter 2000, train entropy gap 1.2730 bits (loss 20.821, data 19.548) 0.00027 lr
Epoch 70 Iter 2200, train entropy gap 1.5170 bits (loss 21.065, data 19.548) 0.00027 lr
Epoch 70 Iter 2400, train entropy gap 1.7463 bits (loss 21.294, data 19.548) 0.00027 lr
Epoch 70 Iter 2600, train entropy gap 1.7894 bits (loss 21.337, data 19.548) 0.00027 lr
Epoch 70 Iter 2800, train entropy gap 1.6792 bits (loss 21.227, data 19.548) 0.00027 lr
Epoch 70 Iter 3000, train entropy gap 1.2128 bits (loss 20.761, data 19.548) 0.00027 lr
Epoch 70 Iter 3200, train entropy gap 2.3230 bits (loss 21.871, data 19.548) 0.00027 lr
Epoch 70 Iter 3400, train entropy gap 0.9875 bits (loss 20.535, data 19.548) 0.00027 lr
Epoch 70 Iter 3600, train entropy gap 2.2352 bits (loss 21.783, data 19.548) 0.00027 lr
Epoch 70 Iter 3800, train entropy gap 2.0365 bits (loss 21.584, data 19.548) 0.00027 lr
Epoch 70 Iter 4000, train entropy gap 1.5164 bits (loss 21.064, data 19.548) 0.00027 lr
Epoch 70 Iter 4200, train entropy gap 0.9935 bits (loss 20.541, data 19.548) 0.00027 lr
Epoch 70 Iter 4400, train entropy gap 2.3347 bits (loss 21.882, data 19.548) 0.00027 lr
Epoch 70 Iter 4600, train entropy gap 2.1134 bits (loss 21.661, data 19.548) 0.00027 lr
Epoch 70 Iter 4800, train entropy gap 2.9118 bits (loss 22.460, data 19.548) 0.00027 lr
Epoch 70 Iter 5000, train entropy gap 1.5497 bits (loss 21.097, data 19.548) 0.00027 lr
Epoch 70 Iter 5200, train entropy gap 2.5051 bits (loss 22.053, data 19.548) 0.00027 lr
Epoch 70 Iter 5400, train entropy gap 0.9611 bits (loss 20.509, data 19.548) 0.00027 lr
Epoch 70 Iter 5600, train entropy gap 2.7977 bits (loss 22.345, data 19.548) 0.00027 lr
Epoch 70 Iter 5800, train entropy gap 1.7495 bits (loss 21.297, data 19.548) 0.00027 lr
Epoch 70 Iter 6000, train entropy gap 1.4803 bits (loss 21.028, data 19.548) 0.00027 lr
epoch 70 train loss 14.7287 nats / 21.2490 bits
time since start: 9999.7 secs
Epoch 71 Iter 0, train entropy gap 2.1486 bits (loss 21.696, data 19.548) 0.00027 lr
Epoch 71 Iter 200, train entropy gap 1.3451 bits (loss 20.893, data 19.548) 0.00027 lr
Epoch 71 Iter 400, train entropy gap 1.0848 bits (loss 20.633, data 19.548) 0.00027 lr
Epoch 71 Iter 600, train entropy gap 0.7565 bits (loss 20.304, data 19.548) 0.00027 lr
Epoch 71 Iter 800, train entropy gap 2.3763 bits (loss 21.924, data 19.548) 0.00027 lr
Epoch 71 Iter 1000, train entropy gap 2.4461 bits (loss 21.994, data 19.548) 0.00027 lr
Epoch 71 Iter 1200, train entropy gap 2.9446 bits (loss 22.492, data 19.548) 0.00027 lr
Epoch 71 Iter 1400, train entropy gap 2.9023 bits (loss 22.450, data 19.548) 0.00027 lr
Epoch 71 Iter 1600, train entropy gap 1.1666 bits (loss 20.714, data 19.548) 0.00027 lr
Epoch 71 Iter 1800, train entropy gap 1.8854 bits (loss 21.433, data 19.548) 0.00027 lr
Epoch 71 Iter 2000, train entropy gap 2.1429 bits (loss 21.691, data 19.548) 0.00027 lr
Epoch 71 Iter 2200, train entropy gap 1.7541 bits (loss 21.302, data 19.548) 0.00027 lr
Epoch 71 Iter 2400, train entropy gap 1.2323 bits (loss 20.780, data 19.548) 0.00027 lr
Epoch 71 Iter 2600, train entropy gap 2.2536 bits (loss 21.801, data 19.548) 0.00027 lr
Epoch 71 Iter 2800, train entropy gap 1.2797 bits (loss 20.827, data 19.548) 0.00027 lr
Epoch 71 Iter 3000, train entropy gap 1.7865 bits (loss 21.334, data 19.548) 0.00027 lr
Epoch 71 Iter 3200, train entropy gap 1.1357 bits (loss 20.683, data 19.548) 0.00027 lr
Epoch 71 Iter 3400, train entropy gap 2.2965 bits (loss 21.844, data 19.548) 0.00027 lr
Epoch 71 Iter 3600, train entropy gap 1.6957 bits (loss 21.243, data 19.548) 0.00027 lr
Epoch 71 Iter 3800, train entropy gap 1.6384 bits (loss 21.186, data 19.548) 0.00027 lr
Epoch 71 Iter 4000, train entropy gap 1.5756 bits (loss 21.123, data 19.548) 0.00027 lr
Epoch 71 Iter 4200, train entropy gap 2.2258 bits (loss 21.774, data 19.548) 0.00027 lr
Epoch 71 Iter 4400, train entropy gap 2.1389 bits (loss 21.687, data 19.548) 0.00027 lr
Epoch 71 Iter 4600, train entropy gap 1.7702 bits (loss 21.318, data 19.548) 0.00027 lr
Epoch 71 Iter 4800, train entropy gap 1.3913 bits (loss 20.939, data 19.548) 0.00027 lr
Epoch 71 Iter 5000, train entropy gap 1.1608 bits (loss 20.708, data 19.548) 0.00027 lr
Epoch 71 Iter 5200, train entropy gap 1.8336 bits (loss 21.381, data 19.548) 0.00027 lr
Epoch 71 Iter 5400, train entropy gap 2.3059 bits (loss 21.854, data 19.548) 0.00027 lr
Epoch 71 Iter 5600, train entropy gap 1.2874 bits (loss 20.835, data 19.548) 0.00027 lr
Epoch 71 Iter 5800, train entropy gap 1.3127 bits (loss 20.860, data 19.548) 0.00027 lr
Epoch 71 Iter 6000, train entropy gap 2.3171 bits (loss 21.865, data 19.548) 0.00027 lr
epoch 71 train loss 14.7339 nats / 21.2566 bits
time since start: 10139.9 secs
Epoch 72 Iter 0, train entropy gap 1.8706 bits (loss 21.418, data 19.548) 0.00027 lr
Epoch 72 Iter 200, train entropy gap 1.5187 bits (loss 21.066, data 19.548) 0.00027 lr
Epoch 72 Iter 400, train entropy gap 1.6308 bits (loss 21.178, data 19.548) 0.00027 lr
Epoch 72 Iter 600, train entropy gap 1.3335 bits (loss 20.881, data 19.548) 0.00027 lr
Epoch 72 Iter 800, train entropy gap 2.0659 bits (loss 21.614, data 19.548) 0.00027 lr
Epoch 72 Iter 1000, train entropy gap 2.5796 bits (loss 22.127, data 19.548) 0.00027 lr
Epoch 72 Iter 1200, train entropy gap 1.7969 bits (loss 21.345, data 19.548) 0.00027 lr
Epoch 72 Iter 1400, train entropy gap 3.1239 bits (loss 22.672, data 19.548) 0.00026 lr
Epoch 72 Iter 1600, train entropy gap 1.4743 bits (loss 21.022, data 19.548) 0.00026 lr
Epoch 72 Iter 1800, train entropy gap 1.5184 bits (loss 21.066, data 19.548) 0.00026 lr
Epoch 72 Iter 2000, train entropy gap 1.2520 bits (loss 20.800, data 19.548) 0.00026 lr
Epoch 72 Iter 2200, train entropy gap 2.7998 bits (loss 22.347, data 19.548) 0.00026 lr
Epoch 72 Iter 2400, train entropy gap 2.5861 bits (loss 22.134, data 19.548) 0.00026 lr
Epoch 72 Iter 2600, train entropy gap 1.5266 bits (loss 21.074, data 19.548) 0.00026 lr
Epoch 72 Iter 2800, train entropy gap 1.9585 bits (loss 21.506, data 19.548) 0.00026 lr
Epoch 72 Iter 3000, train entropy gap 1.0401 bits (loss 20.588, data 19.548) 0.00026 lr
Epoch 72 Iter 3200, train entropy gap 2.9840 bits (loss 22.532, data 19.548) 0.00026 lr
Epoch 72 Iter 3400, train entropy gap 2.9080 bits (loss 22.456, data 19.548) 0.00026 lr
Epoch 72 Iter 3600, train entropy gap 2.1905 bits (loss 21.738, data 19.548) 0.00026 lr
Epoch 72 Iter 3800, train entropy gap 0.9818 bits (loss 20.530, data 19.548) 0.00026 lr
Epoch 72 Iter 4000, train entropy gap 2.1202 bits (loss 21.668, data 19.548) 0.00026 lr
Epoch 72 Iter 4200, train entropy gap 1.6311 bits (loss 21.179, data 19.548) 0.00026 lr
Epoch 72 Iter 4400, train entropy gap 1.5371 bits (loss 21.085, data 19.548) 0.00026 lr
Epoch 72 Iter 4600, train entropy gap 1.4318 bits (loss 20.980, data 19.548) 0.00026 lr
Epoch 72 Iter 4800, train entropy gap 1.3518 bits (loss 20.899, data 19.548) 0.00026 lr
Epoch 72 Iter 5000, train entropy gap 1.4768 bits (loss 21.025, data 19.548) 0.00026 lr
Epoch 72 Iter 5200, train entropy gap 1.3908 bits (loss 20.938, data 19.548) 0.00026 lr
Epoch 72 Iter 5400, train entropy gap 1.2394 bits (loss 20.787, data 19.548) 0.00026 lr
Epoch 72 Iter 5600, train entropy gap 1.2764 bits (loss 20.824, data 19.548) 0.00026 lr
Epoch 72 Iter 5800, train entropy gap 1.4915 bits (loss 21.039, data 19.548) 0.00026 lr
Epoch 72 Iter 6000, train entropy gap 2.3982 bits (loss 21.946, data 19.548) 0.00026 lr
epoch 72 train loss 14.7258 nats / 21.2449 bits
time since start: 10280.4 secs
Epoch 73 Iter 0, train entropy gap 1.5157 bits (loss 21.063, data 19.548) 0.00026 lr
Epoch 73 Iter 200, train entropy gap 1.5238 bits (loss 21.072, data 19.548) 0.00026 lr
Epoch 73 Iter 400, train entropy gap 1.6181 bits (loss 21.166, data 19.548) 0.00026 lr
Epoch 73 Iter 600, train entropy gap 1.0739 bits (loss 20.622, data 19.548) 0.00026 lr
Epoch 73 Iter 800, train entropy gap 1.7066 bits (loss 21.254, data 19.548) 0.00026 lr
Epoch 73 Iter 1000, train entropy gap 3.2300 bits (loss 22.778, data 19.548) 0.00026 lr
Epoch 73 Iter 1200, train entropy gap 1.8154 bits (loss 21.363, data 19.548) 0.00026 lr
Epoch 73 Iter 1400, train entropy gap 1.1187 bits (loss 20.666, data 19.548) 0.00026 lr
Epoch 73 Iter 1600, train entropy gap 1.6621 bits (loss 21.210, data 19.548) 0.00026 lr
Epoch 73 Iter 1800, train entropy gap 1.1941 bits (loss 20.742, data 19.548) 0.00026 lr
Epoch 73 Iter 2000, train entropy gap 1.3801 bits (loss 20.928, data 19.548) 0.00026 lr
Epoch 73 Iter 2200, train entropy gap 1.7099 bits (loss 21.258, data 19.548) 0.00026 lr
Epoch 73 Iter 2400, train entropy gap 1.8589 bits (loss 21.407, data 19.548) 0.00026 lr
Epoch 73 Iter 2600, train entropy gap 1.6413 bits (loss 21.189, data 19.548) 0.00026 lr
Epoch 73 Iter 2800, train entropy gap 1.0371 bits (loss 20.585, data 19.548) 0.00026 lr
Epoch 73 Iter 3000, train entropy gap 1.6534 bits (loss 21.201, data 19.548) 0.00026 lr
Epoch 73 Iter 3200, train entropy gap 1.1538 bits (loss 20.702, data 19.548) 0.00026 lr
Epoch 73 Iter 3400, train entropy gap 2.9558 bits (loss 22.503, data 19.548) 0.00026 lr
Epoch 73 Iter 3600, train entropy gap 1.4078 bits (loss 20.956, data 19.548) 0.00026 lr
Epoch 73 Iter 3800, train entropy gap 2.5107 bits (loss 22.058, data 19.548) 0.00026 lr
Epoch 73 Iter 4000, train entropy gap 1.3140 bits (loss 20.862, data 19.548) 0.00026 lr
Epoch 73 Iter 4200, train entropy gap 1.6594 bits (loss 21.207, data 19.548) 0.00026 lr
Epoch 73 Iter 4400, train entropy gap 1.2105 bits (loss 20.758, data 19.548) 0.00026 lr
Epoch 73 Iter 4600, train entropy gap 1.8274 bits (loss 21.375, data 19.548) 0.00026 lr
Epoch 73 Iter 4800, train entropy gap 1.9471 bits (loss 21.495, data 19.548) 0.00026 lr
Epoch 73 Iter 5000, train entropy gap 1.3418 bits (loss 20.890, data 19.548) 0.00026 lr
Epoch 73 Iter 5200, train entropy gap 1.9440 bits (loss 21.492, data 19.548) 0.00026 lr
Epoch 73 Iter 5400, train entropy gap 2.6071 bits (loss 22.155, data 19.548) 0.00026 lr
Epoch 73 Iter 5600, train entropy gap 1.2129 bits (loss 20.761, data 19.548) 0.00026 lr
Epoch 73 Iter 5800, train entropy gap 2.3278 bits (loss 21.875, data 19.548) 0.00026 lr
Epoch 73 Iter 6000, train entropy gap 2.3178 bits (loss 21.865, data 19.548) 0.00026 lr
epoch 73 train loss 14.7329 nats / 21.2551 bits
time since start: 10420.7 secs
Epoch 74 Iter 0, train entropy gap 2.2771 bits (loss 21.825, data 19.548) 0.00026 lr
Epoch 74 Iter 200, train entropy gap 1.9451 bits (loss 21.493, data 19.548) 0.00026 lr
Epoch 74 Iter 400, train entropy gap 1.4883 bits (loss 21.036, data 19.548) 0.00026 lr
Epoch 74 Iter 600, train entropy gap 1.7854 bits (loss 21.333, data 19.548) 0.00026 lr
Epoch 74 Iter 800, train entropy gap 2.0066 bits (loss 21.554, data 19.548) 0.00026 lr
Epoch 74 Iter 1000, train entropy gap 1.9384 bits (loss 21.486, data 19.548) 0.00026 lr
Epoch 74 Iter 1200, train entropy gap 1.1969 bits (loss 20.745, data 19.548) 0.00026 lr
Epoch 74 Iter 1400, train entropy gap 1.2084 bits (loss 20.756, data 19.548) 0.00026 lr
Epoch 74 Iter 1600, train entropy gap 1.7544 bits (loss 21.302, data 19.548) 0.00026 lr
Epoch 74 Iter 1800, train entropy gap 1.5060 bits (loss 21.054, data 19.548) 0.00026 lr
Epoch 74 Iter 2000, train entropy gap 0.8437 bits (loss 20.391, data 19.548) 0.00026 lr
Epoch 74 Iter 2200, train entropy gap 1.6287 bits (loss 21.176, data 19.548) 0.00026 lr
Epoch 74 Iter 2400, train entropy gap 2.4744 bits (loss 22.022, data 19.548) 0.00026 lr
Epoch 74 Iter 2600, train entropy gap 1.3231 bits (loss 20.871, data 19.548) 0.00026 lr
Epoch 74 Iter 2800, train entropy gap 1.0650 bits (loss 20.613, data 19.548) 0.00026 lr
Epoch 74 Iter 3000, train entropy gap 1.6317 bits (loss 21.179, data 19.548) 0.00026 lr
Epoch 74 Iter 3200, train entropy gap 1.1079 bits (loss 20.656, data 19.548) 0.00026 lr
Epoch 74 Iter 3400, train entropy gap 1.9760 bits (loss 21.524, data 19.548) 0.00026 lr
Epoch 74 Iter 3600, train entropy gap 1.1737 bits (loss 20.721, data 19.548) 0.00026 lr
Epoch 74 Iter 3800, train entropy gap 1.2700 bits (loss 20.818, data 19.548) 0.00026 lr
Epoch 74 Iter 4000, train entropy gap 1.6166 bits (loss 21.164, data 19.548) 0.00026 lr
Epoch 74 Iter 4200, train entropy gap 1.1460 bits (loss 20.694, data 19.548) 0.00026 lr
Epoch 74 Iter 4400, train entropy gap 1.1658 bits (loss 20.714, data 19.548) 0.00026 lr
Epoch 74 Iter 4600, train entropy gap 2.8903 bits (loss 22.438, data 19.548) 0.00026 lr
Epoch 74 Iter 4800, train entropy gap 1.7989 bits (loss 21.347, data 19.548) 0.00026 lr
Epoch 74 Iter 5000, train entropy gap 1.5653 bits (loss 21.113, data 19.548) 0.00026 lr
Epoch 74 Iter 5200, train entropy gap 0.8470 bits (loss 20.395, data 19.548) 0.00026 lr
Epoch 74 Iter 5400, train entropy gap 1.3538 bits (loss 20.902, data 19.548) 0.00026 lr
Epoch 74 Iter 5600, train entropy gap 1.0927 bits (loss 20.640, data 19.548) 0.00026 lr
Epoch 74 Iter 5800, train entropy gap 1.3912 bits (loss 20.939, data 19.548) 0.00026 lr
Epoch 74 Iter 6000, train entropy gap 1.5416 bits (loss 21.089, data 19.548) 0.00026 lr
epoch 74 train loss 14.7405 nats / 21.2660 bits
time since start: 10561.6 secs
Epoch 75 Iter 0, train entropy gap 1.2978 bits (loss 20.845, data 19.548) 0.00026 lr
Epoch 75 Iter 200, train entropy gap 1.4570 bits (loss 21.005, data 19.548) 0.00026 lr
Epoch 75 Iter 400, train entropy gap 1.0770 bits (loss 20.625, data 19.548) 0.00026 lr
Epoch 75 Iter 600, train entropy gap 1.3491 bits (loss 20.897, data 19.548) 0.00026 lr
Epoch 75 Iter 800, train entropy gap 3.1014 bits (loss 22.649, data 19.548) 0.00026 lr
Epoch 75 Iter 1000, train entropy gap 2.1882 bits (loss 21.736, data 19.548) 0.00026 lr
Epoch 75 Iter 1200, train entropy gap 2.1073 bits (loss 21.655, data 19.548) 0.00026 lr
Epoch 75 Iter 1400, train entropy gap 1.4429 bits (loss 20.991, data 19.548) 0.00026 lr
Epoch 75 Iter 1600, train entropy gap 1.5589 bits (loss 21.107, data 19.548) 0.00026 lr
Epoch 75 Iter 1800, train entropy gap 2.1859 bits (loss 21.734, data 19.548) 0.00026 lr
Epoch 75 Iter 2000, train entropy gap 1.2044 bits (loss 20.752, data 19.548) 0.00026 lr
Epoch 75 Iter 2200, train entropy gap 1.3215 bits (loss 20.869, data 19.548) 0.00026 lr
Epoch 75 Iter 2400, train entropy gap 2.3325 bits (loss 21.880, data 19.548) 0.00026 lr
Epoch 75 Iter 2600, train entropy gap 2.1775 bits (loss 21.725, data 19.548) 0.00026 lr
Epoch 75 Iter 2800, train entropy gap 1.4133 bits (loss 20.961, data 19.548) 0.00026 lr
Epoch 75 Iter 3000, train entropy gap 2.3827 bits (loss 21.930, data 19.548) 0.00026 lr
Epoch 75 Iter 3200, train entropy gap 1.8492 bits (loss 21.397, data 19.548) 0.00026 lr
Epoch 75 Iter 3400, train entropy gap 1.4352 bits (loss 20.983, data 19.548) 0.00026 lr
Epoch 75 Iter 3600, train entropy gap 1.8361 bits (loss 21.384, data 19.548) 0.00026 lr
Epoch 75 Iter 3800, train entropy gap 1.2927 bits (loss 20.840, data 19.548) 0.00026 lr
Epoch 75 Iter 4000, train entropy gap 1.2944 bits (loss 20.842, data 19.548) 0.00026 lr
Epoch 75 Iter 4200, train entropy gap 1.5990 bits (loss 21.147, data 19.548) 0.00026 lr
Epoch 75 Iter 4400, train entropy gap 1.4230 bits (loss 20.971, data 19.548) 0.00026 lr
Epoch 75 Iter 4600, train entropy gap 1.4452 bits (loss 20.993, data 19.548) 0.00026 lr
Epoch 75 Iter 4800, train entropy gap 1.5948 bits (loss 21.143, data 19.548) 0.00026 lr
Epoch 75 Iter 5000, train entropy gap 1.1173 bits (loss 20.665, data 19.548) 0.00026 lr
Epoch 75 Iter 5200, train entropy gap 1.7832 bits (loss 21.331, data 19.548) 0.00026 lr
Epoch 75 Iter 5400, train entropy gap 2.1416 bits (loss 21.689, data 19.548) 0.00026 lr
Epoch 75 Iter 5600, train entropy gap 1.4122 bits (loss 20.960, data 19.548) 0.00026 lr
Epoch 75 Iter 5800, train entropy gap 1.9285 bits (loss 21.476, data 19.548) 0.00026 lr
Epoch 75 Iter 6000, train entropy gap 1.3777 bits (loss 20.925, data 19.548) 0.00026 lr
epoch 75 train loss 14.7383 nats / 21.2629 bits
time since start: 10701.4 secs
Epoch 76 Iter 0, train entropy gap 1.9023 bits (loss 21.450, data 19.548) 0.00026 lr
Epoch 76 Iter 200, train entropy gap 1.5476 bits (loss 21.095, data 19.548) 0.00026 lr
Epoch 76 Iter 400, train entropy gap 1.2641 bits (loss 20.812, data 19.548) 0.00026 lr
Epoch 76 Iter 600, train entropy gap 1.1091 bits (loss 20.657, data 19.548) 0.00026 lr
Epoch 76 Iter 800, train entropy gap 2.2122 bits (loss 21.760, data 19.548) 0.00026 lr
Epoch 76 Iter 1000, train entropy gap 1.4001 bits (loss 20.948, data 19.548) 0.00026 lr
Epoch 76 Iter 1200, train entropy gap 1.6959 bits (loss 21.244, data 19.548) 0.00026 lr
Epoch 76 Iter 1400, train entropy gap 1.3646 bits (loss 20.912, data 19.548) 0.00026 lr
Epoch 76 Iter 1600, train entropy gap 1.9736 bits (loss 21.521, data 19.548) 0.00026 lr
Epoch 76 Iter 1800, train entropy gap 1.7814 bits (loss 21.329, data 19.548) 0.00026 lr
Epoch 76 Iter 2000, train entropy gap 2.0392 bits (loss 21.587, data 19.548) 0.00026 lr
Epoch 76 Iter 2200, train entropy gap 2.5728 bits (loss 22.121, data 19.548) 0.00026 lr
Epoch 76 Iter 2400, train entropy gap 1.7833 bits (loss 21.331, data 19.548) 0.00026 lr
Epoch 76 Iter 2600, train entropy gap 2.2279 bits (loss 21.776, data 19.548) 0.00026 lr
Epoch 76 Iter 2800, train entropy gap 1.1564 bits (loss 20.704, data 19.548) 0.00026 lr
Epoch 76 Iter 3000, train entropy gap 2.1362 bits (loss 21.684, data 19.548) 0.00026 lr
Epoch 76 Iter 3200, train entropy gap 2.2029 bits (loss 21.751, data 19.548) 0.00026 lr
Epoch 76 Iter 3400, train entropy gap 2.7024 bits (loss 22.250, data 19.548) 0.00026 lr
Epoch 76 Iter 3600, train entropy gap 2.9501 bits (loss 22.498, data 19.548) 0.00026 lr
Epoch 76 Iter 3800, train entropy gap 1.4143 bits (loss 20.962, data 19.548) 0.00026 lr
Epoch 76 Iter 4000, train entropy gap 1.3083 bits (loss 20.856, data 19.548) 0.00026 lr
Epoch 76 Iter 4200, train entropy gap 1.7867 bits (loss 21.334, data 19.548) 0.00026 lr
Epoch 76 Iter 4400, train entropy gap 1.7442 bits (loss 21.292, data 19.548) 0.00026 lr
Epoch 76 Iter 4600, train entropy gap 1.9559 bits (loss 21.504, data 19.548) 0.00026 lr
Epoch 76 Iter 4800, train entropy gap 1.9597 bits (loss 21.507, data 19.548) 0.00026 lr
Epoch 76 Iter 5000, train entropy gap 2.6575 bits (loss 22.205, data 19.548) 0.00026 lr
Epoch 76 Iter 5200, train entropy gap 2.0621 bits (loss 21.610, data 19.548) 0.00026 lr
Epoch 76 Iter 5400, train entropy gap 1.4726 bits (loss 21.020, data 19.548) 0.00026 lr
Epoch 76 Iter 5600, train entropy gap 2.4222 bits (loss 21.970, data 19.548) 0.00026 lr
Epoch 76 Iter 5800, train entropy gap 1.1803 bits (loss 20.728, data 19.548) 0.00026 lr
Epoch 76 Iter 6000, train entropy gap 1.8163 bits (loss 21.364, data 19.548) 0.00026 lr
epoch 76 train loss 14.7370 nats / 21.2609 bits
time since start: 10842.2 secs
Epoch 77 Iter 0, train entropy gap 2.4589 bits (loss 22.007, data 19.548) 0.00026 lr
Epoch 77 Iter 200, train entropy gap 1.2892 bits (loss 20.837, data 19.548) 0.00026 lr
Epoch 77 Iter 400, train entropy gap 0.8268 bits (loss 20.375, data 19.548) 0.00026 lr
Epoch 77 Iter 600, train entropy gap 1.0951 bits (loss 20.643, data 19.548) 0.00026 lr
Epoch 77 Iter 800, train entropy gap 1.9262 bits (loss 21.474, data 19.548) 0.00026 lr
Epoch 77 Iter 1000, train entropy gap 2.0518 bits (loss 21.599, data 19.548) 0.00026 lr
Epoch 77 Iter 1200, train entropy gap 1.4044 bits (loss 20.952, data 19.548) 0.00026 lr
Epoch 77 Iter 1400, train entropy gap 1.5580 bits (loss 21.106, data 19.548) 0.00026 lr
Epoch 77 Iter 1600, train entropy gap 1.4967 bits (loss 21.044, data 19.548) 0.00026 lr
Epoch 77 Iter 1800, train entropy gap 1.2279 bits (loss 20.776, data 19.548) 0.00026 lr
Epoch 77 Iter 2000, train entropy gap 2.0011 bits (loss 21.549, data 19.548) 0.00026 lr
Epoch 77 Iter 2200, train entropy gap 1.1373 bits (loss 20.685, data 19.548) 0.00026 lr
Epoch 77 Iter 2400, train entropy gap 1.6797 bits (loss 21.227, data 19.548) 0.00026 lr
Epoch 77 Iter 2600, train entropy gap 1.1394 bits (loss 20.687, data 19.548) 0.00026 lr
Epoch 77 Iter 2800, train entropy gap 2.5366 bits (loss 22.084, data 19.548) 0.00026 lr
Epoch 77 Iter 3000, train entropy gap 1.3218 bits (loss 20.869, data 19.548) 0.00026 lr
Epoch 77 Iter 3200, train entropy gap 1.8924 bits (loss 21.440, data 19.548) 0.00026 lr
Epoch 77 Iter 3400, train entropy gap 2.0971 bits (loss 21.645, data 19.548) 0.00026 lr
Epoch 77 Iter 3600, train entropy gap 1.1491 bits (loss 20.697, data 19.548) 0.00026 lr
Epoch 77 Iter 3800, train entropy gap 2.1591 bits (loss 21.707, data 19.548) 0.00026 lr
Epoch 77 Iter 4000, train entropy gap 1.8213 bits (loss 21.369, data 19.548) 0.00026 lr
Epoch 77 Iter 4200, train entropy gap 2.2285 bits (loss 21.776, data 19.548) 0.00026 lr
Epoch 77 Iter 4400, train entropy gap 1.4138 bits (loss 20.962, data 19.548) 0.00026 lr
Epoch 77 Iter 4600, train entropy gap 1.2222 bits (loss 20.770, data 19.548) 0.00026 lr
Epoch 77 Iter 4800, train entropy gap 0.7305 bits (loss 20.278, data 19.548) 0.00026 lr
Epoch 77 Iter 5000, train entropy gap 1.7088 bits (loss 21.256, data 19.548) 0.00026 lr
Epoch 77 Iter 5200, train entropy gap 1.9173 bits (loss 21.465, data 19.548) 0.00026 lr
Epoch 77 Iter 5400, train entropy gap 1.6255 bits (loss 21.173, data 19.548) 0.00026 lr
Epoch 77 Iter 5600, train entropy gap 2.3192 bits (loss 21.867, data 19.548) 0.00026 lr
Epoch 77 Iter 5800, train entropy gap 1.2652 bits (loss 20.813, data 19.548) 0.00026 lr
Epoch 77 Iter 6000, train entropy gap 1.9952 bits (loss 21.543, data 19.548) 0.00026 lr
epoch 77 train loss 14.7377 nats / 21.2620 bits
time since start: 10983.4 secs
Epoch 78 Iter 0, train entropy gap 1.9216 bits (loss 21.469, data 19.548) 0.00025 lr
Epoch 78 Iter 200, train entropy gap 1.7933 bits (loss 21.341, data 19.548) 0.00025 lr
Epoch 78 Iter 400, train entropy gap 2.6250 bits (loss 22.173, data 19.548) 0.00025 lr
Epoch 78 Iter 600, train entropy gap 2.1756 bits (loss 21.723, data 19.548) 0.00025 lr
Epoch 78 Iter 800, train entropy gap 2.3404 bits (loss 21.888, data 19.548) 0.00025 lr
Epoch 78 Iter 1000, train entropy gap 1.2168 bits (loss 20.764, data 19.548) 0.00025 lr
Epoch 78 Iter 1200, train entropy gap 1.2138 bits (loss 20.761, data 19.548) 0.00025 lr
Epoch 78 Iter 1400, train entropy gap 1.5061 bits (loss 21.054, data 19.548) 0.00025 lr
Epoch 78 Iter 1600, train entropy gap 1.7617 bits (loss 21.309, data 19.548) 0.00025 lr
Epoch 78 Iter 1800, train entropy gap 1.3725 bits (loss 20.920, data 19.548) 0.00025 lr
Epoch 78 Iter 2000, train entropy gap 2.8497 bits (loss 22.397, data 19.548) 0.00025 lr
Epoch 78 Iter 2200, train entropy gap 1.2011 bits (loss 20.749, data 19.548) 0.00025 lr
Epoch 78 Iter 2400, train entropy gap 2.5757 bits (loss 22.123, data 19.548) 0.00025 lr
Epoch 78 Iter 2600, train entropy gap 0.9023 bits (loss 20.450, data 19.548) 0.00025 lr
Epoch 78 Iter 2800, train entropy gap 0.7839 bits (loss 20.332, data 19.548) 0.00025 lr
Epoch 78 Iter 3000, train entropy gap 2.1539 bits (loss 21.702, data 19.548) 0.00025 lr
Epoch 78 Iter 3200, train entropy gap 2.2204 bits (loss 21.768, data 19.548) 0.00025 lr
Epoch 78 Iter 3400, train entropy gap 1.1130 bits (loss 20.661, data 19.548) 0.00025 lr
Epoch 78 Iter 3600, train entropy gap 1.8598 bits (loss 21.407, data 19.548) 0.00025 lr
Epoch 78 Iter 3800, train entropy gap 1.2078 bits (loss 20.756, data 19.548) 0.00025 lr
Epoch 78 Iter 4000, train entropy gap 1.5895 bits (loss 21.137, data 19.548) 0.00025 lr
Epoch 78 Iter 4200, train entropy gap 0.9347 bits (loss 20.482, data 19.548) 0.00025 lr
Epoch 78 Iter 4400, train entropy gap 3.0782 bits (loss 22.626, data 19.548) 0.00025 lr
Epoch 78 Iter 4600, train entropy gap 1.8491 bits (loss 21.397, data 19.548) 0.00025 lr
Epoch 78 Iter 4800, train entropy gap 1.6727 bits (loss 21.220, data 19.548) 0.00025 lr
Epoch 78 Iter 5000, train entropy gap 1.2557 bits (loss 20.803, data 19.548) 0.00025 lr
Epoch 78 Iter 5200, train entropy gap 1.4289 bits (loss 20.977, data 19.548) 0.00025 lr
Epoch 78 Iter 5400, train entropy gap 1.9168 bits (loss 21.465, data 19.548) 0.00025 lr
Epoch 78 Iter 5600, train entropy gap 1.2131 bits (loss 20.761, data 19.548) 0.00025 lr
Epoch 78 Iter 5800, train entropy gap 0.8546 bits (loss 20.402, data 19.548) 0.00025 lr
Epoch 78 Iter 6000, train entropy gap 2.0913 bits (loss 21.639, data 19.548) 0.00025 lr
epoch 78 train loss 14.7275 nats / 21.2473 bits
time since start: 11124.0 secs
Epoch 79 Iter 0, train entropy gap 0.9651 bits (loss 20.513, data 19.548) 0.00025 lr
Epoch 79 Iter 200, train entropy gap 2.6582 bits (loss 22.206, data 19.548) 0.00025 lr
Epoch 79 Iter 400, train entropy gap 1.4424 bits (loss 20.990, data 19.548) 0.00025 lr
Epoch 79 Iter 600, train entropy gap 0.8610 bits (loss 20.409, data 19.548) 0.00025 lr
Epoch 79 Iter 800, train entropy gap 2.1551 bits (loss 21.703, data 19.548) 0.00025 lr
Epoch 79 Iter 1000, train entropy gap 2.7784 bits (loss 22.326, data 19.548) 0.00025 lr
Epoch 79 Iter 1200, train entropy gap 2.6456 bits (loss 22.193, data 19.548) 0.00025 lr
Epoch 79 Iter 1400, train entropy gap 1.5885 bits (loss 21.136, data 19.548) 0.00025 lr
Epoch 79 Iter 1600, train entropy gap 2.2107 bits (loss 21.758, data 19.548) 0.00025 lr
Epoch 79 Iter 1800, train entropy gap 1.8476 bits (loss 21.395, data 19.548) 0.00025 lr
Epoch 79 Iter 2000, train entropy gap 0.9609 bits (loss 20.509, data 19.548) 0.00025 lr
Epoch 79 Iter 2200, train entropy gap 2.6336 bits (loss 22.181, data 19.548) 0.00025 lr
Epoch 79 Iter 2400, train entropy gap 1.5817 bits (loss 21.129, data 19.548) 0.00025 lr
Epoch 79 Iter 2600, train entropy gap 2.0887 bits (loss 21.636, data 19.548) 0.00025 lr
Epoch 79 Iter 2800, train entropy gap 1.5983 bits (loss 21.146, data 19.548) 0.00025 lr
Epoch 79 Iter 3000, train entropy gap 2.1767 bits (loss 21.724, data 19.548) 0.00025 lr
Epoch 79 Iter 3200, train entropy gap 1.6197 bits (loss 21.167, data 19.548) 0.00025 lr
Epoch 79 Iter 3400, train entropy gap 1.5818 bits (loss 21.130, data 19.548) 0.00025 lr
Epoch 79 Iter 3600, train entropy gap 1.2955 bits (loss 20.843, data 19.548) 0.00025 lr
Epoch 79 Iter 3800, train entropy gap 1.8507 bits (loss 21.398, data 19.548) 0.00025 lr
Epoch 79 Iter 4000, train entropy gap 2.1834 bits (loss 21.731, data 19.548) 0.00025 lr
Epoch 79 Iter 4200, train entropy gap 0.8984 bits (loss 20.446, data 19.548) 0.00025 lr
Epoch 79 Iter 4400, train entropy gap 1.7247 bits (loss 21.272, data 19.548) 0.00025 lr
Epoch 79 Iter 4600, train entropy gap 1.9232 bits (loss 21.471, data 19.548) 0.00025 lr
Epoch 79 Iter 4800, train entropy gap 2.5522 bits (loss 22.100, data 19.548) 0.00025 lr
Epoch 79 Iter 5000, train entropy gap 1.6095 bits (loss 21.157, data 19.548) 0.00025 lr
Epoch 79 Iter 5200, train entropy gap 2.4993 bits (loss 22.047, data 19.548) 0.00025 lr
Epoch 79 Iter 5400, train entropy gap 1.7008 bits (loss 21.249, data 19.548) 0.00025 lr
Epoch 79 Iter 5600, train entropy gap 1.9218 bits (loss 21.470, data 19.548) 0.00025 lr
Epoch 79 Iter 5800, train entropy gap 1.7988 bits (loss 21.346, data 19.548) 0.00025 lr
Epoch 79 Iter 6000, train entropy gap 1.0757 bits (loss 20.623, data 19.548) 0.00025 lr
epoch 79 train loss 14.7353 nats / 21.2586 bits
time since start: 11264.4 secs
Epoch 80 Iter 0, train entropy gap 2.1835 bits (loss 21.731, data 19.548) 0.00025 lr
Epoch 80 Iter 200, train entropy gap 2.0009 bits (loss 21.549, data 19.548) 0.00025 lr
Epoch 80 Iter 400, train entropy gap 1.6127 bits (loss 21.160, data 19.548) 0.00025 lr
Epoch 80 Iter 600, train entropy gap 2.3691 bits (loss 21.917, data 19.548) 0.00025 lr
Epoch 80 Iter 800, train entropy gap 1.8016 bits (loss 21.349, data 19.548) 0.00025 lr
Epoch 80 Iter 1000, train entropy gap 2.1562 bits (loss 21.704, data 19.548) 0.00025 lr
Epoch 80 Iter 1200, train entropy gap 2.1013 bits (loss 21.649, data 19.548) 0.00025 lr
Epoch 80 Iter 1400, train entropy gap 0.9191 bits (loss 20.467, data 19.548) 0.00025 lr
Epoch 80 Iter 1600, train entropy gap 3.1156 bits (loss 22.663, data 19.548) 0.00025 lr
Epoch 80 Iter 1800, train entropy gap 1.1448 bits (loss 20.693, data 19.548) 0.00025 lr
Epoch 80 Iter 2000, train entropy gap 0.9157 bits (loss 20.463, data 19.548) 0.00025 lr
Epoch 80 Iter 2200, train entropy gap 1.8248 bits (loss 21.372, data 19.548) 0.00025 lr
Epoch 80 Iter 2400, train entropy gap 2.0747 bits (loss 21.622, data 19.548) 0.00025 lr
Epoch 80 Iter 2600, train entropy gap 2.3741 bits (loss 21.922, data 19.548) 0.00025 lr
Epoch 80 Iter 2800, train entropy gap 1.1440 bits (loss 20.692, data 19.548) 0.00025 lr
Epoch 80 Iter 3000, train entropy gap 1.4198 bits (loss 20.968, data 19.548) 0.00025 lr
Epoch 80 Iter 3200, train entropy gap 2.6488 bits (loss 22.197, data 19.548) 0.00025 lr
Epoch 80 Iter 3400, train entropy gap 1.3392 bits (loss 20.887, data 19.548) 0.00025 lr
Epoch 80 Iter 3600, train entropy gap 1.1510 bits (loss 20.699, data 19.548) 0.00025 lr
Epoch 80 Iter 3800, train entropy gap 2.1223 bits (loss 21.670, data 19.548) 0.00025 lr
Epoch 80 Iter 4000, train entropy gap 1.6673 bits (loss 21.215, data 19.548) 0.00025 lr
Epoch 80 Iter 4200, train entropy gap 2.6265 bits (loss 22.174, data 19.548) 0.00025 lr
Epoch 80 Iter 4400, train entropy gap 1.7855 bits (loss 21.333, data 19.548) 0.00025 lr
Epoch 80 Iter 4600, train entropy gap 1.6356 bits (loss 21.183, data 19.548) 0.00025 lr
Epoch 80 Iter 4800, train entropy gap 1.1905 bits (loss 20.738, data 19.548) 0.00025 lr
Epoch 80 Iter 5000, train entropy gap 2.5432 bits (loss 22.091, data 19.548) 0.00025 lr
Epoch 80 Iter 5200, train entropy gap 1.9364 bits (loss 21.484, data 19.548) 0.00025 lr
Epoch 80 Iter 5400, train entropy gap 0.9075 bits (loss 20.455, data 19.548) 0.00025 lr
Epoch 80 Iter 5600, train entropy gap 0.9821 bits (loss 20.530, data 19.548) 0.00025 lr
Epoch 80 Iter 5800, train entropy gap 1.9752 bits (loss 21.523, data 19.548) 0.00025 lr
Epoch 80 Iter 6000, train entropy gap 1.5122 bits (loss 21.060, data 19.548) 0.00025 lr
epoch 80 train loss 14.7311 nats / 21.2524 bits
time since start: 11404.9 secs
Epoch 81 Iter 0, train entropy gap 1.9296 bits (loss 21.477, data 19.548) 0.00025 lr
Epoch 81 Iter 200, train entropy gap 1.8481 bits (loss 21.396, data 19.548) 0.00025 lr
Epoch 81 Iter 400, train entropy gap 1.6118 bits (loss 21.160, data 19.548) 0.00025 lr
Epoch 81 Iter 600, train entropy gap 1.3622 bits (loss 20.910, data 19.548) 0.00025 lr
Epoch 81 Iter 800, train entropy gap 0.9398 bits (loss 20.488, data 19.548) 0.00025 lr
Epoch 81 Iter 1000, train entropy gap 2.9217 bits (loss 22.469, data 19.548) 0.00025 lr
Epoch 81 Iter 1200, train entropy gap 2.3489 bits (loss 21.897, data 19.548) 0.00025 lr
Epoch 81 Iter 1400, train entropy gap 1.4067 bits (loss 20.954, data 19.548) 0.00025 lr
Epoch 81 Iter 1600, train entropy gap 1.6788 bits (loss 21.227, data 19.548) 0.00025 lr
Epoch 81 Iter 1800, train entropy gap 1.6020 bits (loss 21.150, data 19.548) 0.00025 lr
Epoch 81 Iter 2000, train entropy gap 2.3044 bits (loss 21.852, data 19.548) 0.00025 lr
Epoch 81 Iter 2200, train entropy gap 1.6838 bits (loss 21.232, data 19.548) 0.00025 lr
Epoch 81 Iter 2400, train entropy gap 1.2229 bits (loss 20.771, data 19.548) 0.00025 lr
Epoch 81 Iter 2600, train entropy gap 1.5185 bits (loss 21.066, data 19.548) 0.00025 lr
Epoch 81 Iter 2800, train entropy gap 1.5787 bits (loss 21.126, data 19.548) 0.00025 lr
Epoch 81 Iter 3000, train entropy gap 1.2109 bits (loss 20.759, data 19.548) 0.00025 lr
Epoch 81 Iter 3200, train entropy gap 2.3324 bits (loss 21.880, data 19.548) 0.00025 lr
Epoch 81 Iter 3400, train entropy gap 1.9932 bits (loss 21.541, data 19.548) 0.00025 lr
Epoch 81 Iter 3600, train entropy gap 1.5464 bits (loss 21.094, data 19.548) 0.00025 lr
Epoch 81 Iter 3800, train entropy gap 1.3426 bits (loss 20.890, data 19.548) 0.00025 lr
Epoch 81 Iter 4000, train entropy gap 2.7013 bits (loss 22.249, data 19.548) 0.00025 lr
Epoch 81 Iter 4200, train entropy gap 2.3457 bits (loss 21.893, data 19.548) 0.00025 lr
Epoch 81 Iter 4400, train entropy gap 1.2380 bits (loss 20.786, data 19.548) 0.00025 lr
Epoch 81 Iter 4600, train entropy gap 2.4767 bits (loss 22.024, data 19.548) 0.00025 lr
Epoch 81 Iter 4800, train entropy gap 1.8063 bits (loss 21.354, data 19.548) 0.00025 lr
Epoch 81 Iter 5000, train entropy gap 1.2706 bits (loss 20.818, data 19.548) 0.00025 lr
Epoch 81 Iter 5200, train entropy gap 1.5141 bits (loss 21.062, data 19.548) 0.00025 lr
Epoch 81 Iter 5400, train entropy gap 1.3512 bits (loss 20.899, data 19.548) 0.00025 lr
Epoch 81 Iter 5600, train entropy gap 2.4101 bits (loss 21.958, data 19.548) 0.00025 lr
Epoch 81 Iter 5800, train entropy gap 1.0481 bits (loss 20.596, data 19.548) 0.00025 lr
Epoch 81 Iter 6000, train entropy gap 2.4602 bits (loss 22.008, data 19.548) 0.00025 lr
epoch 81 train loss 14.7312 nats / 21.2526 bits
time since start: 11545.7 secs
Epoch 82 Iter 0, train entropy gap 1.2479 bits (loss 20.796, data 19.548) 0.00025 lr
Epoch 82 Iter 200, train entropy gap 1.2018 bits (loss 20.749, data 19.548) 0.00025 lr
Epoch 82 Iter 400, train entropy gap 2.3263 bits (loss 21.874, data 19.548) 0.00025 lr
Epoch 82 Iter 600, train entropy gap 3.1408 bits (loss 22.689, data 19.548) 0.00025 lr
Epoch 82 Iter 800, train entropy gap 1.7342 bits (loss 21.282, data 19.548) 0.00025 lr
Epoch 82 Iter 1000, train entropy gap 1.3743 bits (loss 20.922, data 19.548) 0.00025 lr
Epoch 82 Iter 1200, train entropy gap 1.2463 bits (loss 20.794, data 19.548) 0.00025 lr
Epoch 82 Iter 1400, train entropy gap 1.1454 bits (loss 20.693, data 19.548) 0.00025 lr
Epoch 82 Iter 1600, train entropy gap 1.8454 bits (loss 21.393, data 19.548) 0.00025 lr
Epoch 82 Iter 1800, train entropy gap 1.0554 bits (loss 20.603, data 19.548) 0.00025 lr
Epoch 82 Iter 2000, train entropy gap 1.2350 bits (loss 20.783, data 19.548) 0.00025 lr
Epoch 82 Iter 2200, train entropy gap 1.6887 bits (loss 21.236, data 19.548) 0.00025 lr
Epoch 82 Iter 2400, train entropy gap 1.1161 bits (loss 20.664, data 19.548) 0.00025 lr
Epoch 82 Iter 2600, train entropy gap 2.2005 bits (loss 21.748, data 19.548) 0.00025 lr
Epoch 82 Iter 2800, train entropy gap 1.1166 bits (loss 20.664, data 19.548) 0.00025 lr
Epoch 82 Iter 3000, train entropy gap 2.6005 bits (loss 22.148, data 19.548) 0.00025 lr
Epoch 82 Iter 3200, train entropy gap 2.0591 bits (loss 21.607, data 19.548) 0.00025 lr
Epoch 82 Iter 3400, train entropy gap 1.7128 bits (loss 21.261, data 19.548) 0.00025 lr
Epoch 82 Iter 3600, train entropy gap 2.0041 bits (loss 21.552, data 19.548) 0.00025 lr
Epoch 82 Iter 3800, train entropy gap 1.6846 bits (loss 21.232, data 19.548) 0.00025 lr
Epoch 82 Iter 4000, train entropy gap 2.2737 bits (loss 21.821, data 19.548) 0.00025 lr
Epoch 82 Iter 4200, train entropy gap 1.3797 bits (loss 20.927, data 19.548) 0.00025 lr
Epoch 82 Iter 4400, train entropy gap 1.2361 bits (loss 20.784, data 19.548) 0.00025 lr
Epoch 82 Iter 4600, train entropy gap 1.8164 bits (loss 21.364, data 19.548) 0.00025 lr
Epoch 82 Iter 4800, train entropy gap 1.3055 bits (loss 20.853, data 19.548) 0.00025 lr
Epoch 82 Iter 5000, train entropy gap 1.7582 bits (loss 21.306, data 19.548) 0.00025 lr
Epoch 82 Iter 5200, train entropy gap 1.7480 bits (loss 21.296, data 19.548) 0.00025 lr
Epoch 82 Iter 5400, train entropy gap 1.2130 bits (loss 20.761, data 19.548) 0.00025 lr
Epoch 82 Iter 5600, train entropy gap 1.2555 bits (loss 20.803, data 19.548) 0.00025 lr
Epoch 82 Iter 5800, train entropy gap 2.2452 bits (loss 21.793, data 19.548) 0.00025 lr
Epoch 82 Iter 6000, train entropy gap 1.4696 bits (loss 21.017, data 19.548) 0.00025 lr
epoch 82 train loss 14.7308 nats / 21.2520 bits
time since start: 11686.2 secs
Epoch 83 Iter 0, train entropy gap 2.5971 bits (loss 22.145, data 19.548) 0.00025 lr
Epoch 83 Iter 200, train entropy gap 1.8237 bits (loss 21.371, data 19.548) 0.00025 lr
Epoch 83 Iter 400, train entropy gap 1.6166 bits (loss 21.164, data 19.548) 0.00025 lr
Epoch 83 Iter 600, train entropy gap 1.2004 bits (loss 20.748, data 19.548) 0.00025 lr
Epoch 83 Iter 800, train entropy gap 2.7474 bits (loss 22.295, data 19.548) 0.00025 lr
Epoch 83 Iter 1000, train entropy gap 1.4542 bits (loss 21.002, data 19.548) 0.00025 lr
Epoch 83 Iter 1200, train entropy gap 2.2698 bits (loss 21.818, data 19.548) 0.00025 lr
Epoch 83 Iter 1400, train entropy gap 2.6371 bits (loss 22.185, data 19.548) 0.00025 lr
Epoch 83 Iter 1600, train entropy gap 1.3520 bits (loss 20.900, data 19.548) 0.00025 lr
Epoch 83 Iter 1800, train entropy gap 2.0206 bits (loss 21.568, data 19.548) 0.00025 lr
Epoch 83 Iter 2000, train entropy gap 1.7256 bits (loss 21.273, data 19.548) 0.00025 lr
Epoch 83 Iter 2200, train entropy gap 1.6463 bits (loss 21.194, data 19.548) 0.00025 lr
Epoch 83 Iter 2400, train entropy gap 1.5250 bits (loss 21.073, data 19.548) 0.00025 lr
Epoch 83 Iter 2600, train entropy gap 0.8380 bits (loss 20.386, data 19.548) 0.00025 lr
Epoch 83 Iter 2800, train entropy gap 1.3908 bits (loss 20.939, data 19.548) 0.00025 lr
Epoch 83 Iter 3000, train entropy gap 0.9950 bits (loss 20.543, data 19.548) 0.00025 lr
Epoch 83 Iter 3200, train entropy gap 2.3120 bits (loss 21.860, data 19.548) 0.00025 lr
Epoch 83 Iter 3400, train entropy gap 1.2688 bits (loss 20.817, data 19.548) 0.00025 lr
Epoch 83 Iter 3600, train entropy gap 1.2078 bits (loss 20.756, data 19.548) 0.00025 lr
Epoch 83 Iter 3800, train entropy gap 2.3131 bits (loss 21.861, data 19.548) 0.00025 lr
Epoch 83 Iter 4000, train entropy gap 2.3578 bits (loss 21.906, data 19.548) 0.00025 lr
Epoch 83 Iter 4200, train entropy gap 1.7099 bits (loss 21.258, data 19.548) 0.00025 lr
Epoch 83 Iter 4400, train entropy gap 1.2340 bits (loss 20.782, data 19.548) 0.00025 lr
Epoch 83 Iter 4600, train entropy gap 3.2437 bits (loss 22.791, data 19.548) 0.00025 lr
Epoch 83 Iter 4800, train entropy gap 1.3009 bits (loss 20.849, data 19.548) 0.00025 lr
Epoch 83 Iter 5000, train entropy gap 2.0809 bits (loss 21.629, data 19.548) 0.00025 lr
Epoch 83 Iter 5200, train entropy gap 1.7595 bits (loss 21.307, data 19.548) 0.00025 lr
Epoch 83 Iter 5400, train entropy gap 2.6314 bits (loss 22.179, data 19.548) 0.00025 lr
Epoch 83 Iter 5600, train entropy gap 1.9778 bits (loss 21.525, data 19.548) 0.00025 lr
Epoch 83 Iter 5800, train entropy gap 2.0297 bits (loss 21.577, data 19.548) 0.00025 lr
Epoch 83 Iter 6000, train entropy gap 1.7954 bits (loss 21.343, data 19.548) 0.00025 lr
epoch 83 train loss 14.7293 nats / 21.2498 bits
time since start: 11827.3 secs
Epoch 84 Iter 0, train entropy gap 1.4982 bits (loss 21.046, data 19.548) 0.00025 lr
Epoch 84 Iter 200, train entropy gap 1.0396 bits (loss 20.587, data 19.548) 0.00025 lr
Epoch 84 Iter 400, train entropy gap 1.2078 bits (loss 20.756, data 19.548) 0.00025 lr
Epoch 84 Iter 600, train entropy gap 1.3747 bits (loss 20.922, data 19.548) 0.00025 lr
Epoch 84 Iter 800, train entropy gap 1.4427 bits (loss 20.990, data 19.548) 0.00025 lr
Epoch 84 Iter 1000, train entropy gap 1.2470 bits (loss 20.795, data 19.548) 0.00025 lr
Epoch 84 Iter 1200, train entropy gap 1.1530 bits (loss 20.701, data 19.548) 0.00025 lr
Epoch 84 Iter 1400, train entropy gap 1.0234 bits (loss 20.571, data 19.548) 0.00025 lr
Epoch 84 Iter 1600, train entropy gap 1.0032 bits (loss 20.551, data 19.548) 0.00025 lr
Epoch 84 Iter 1800, train entropy gap 3.0034 bits (loss 22.551, data 19.548) 0.00025 lr
Epoch 84 Iter 2000, train entropy gap 1.4503 bits (loss 20.998, data 19.548) 0.00025 lr
Epoch 84 Iter 2200, train entropy gap 1.9433 bits (loss 21.491, data 19.548) 0.00025 lr
Epoch 84 Iter 2400, train entropy gap 1.9146 bits (loss 21.462, data 19.548) 0.00025 lr
Epoch 84 Iter 2600, train entropy gap 1.6059 bits (loss 21.154, data 19.548) 0.00025 lr
Epoch 84 Iter 2800, train entropy gap 1.9432 bits (loss 21.491, data 19.548) 0.00025 lr
Epoch 84 Iter 3000, train entropy gap 1.0205 bits (loss 20.568, data 19.548) 0.00024 lr
Epoch 84 Iter 3200, train entropy gap 2.1606 bits (loss 21.708, data 19.548) 0.00024 lr
Epoch 84 Iter 3400, train entropy gap 1.2449 bits (loss 20.793, data 19.548) 0.00024 lr
Epoch 84 Iter 3600, train entropy gap 2.2595 bits (loss 21.807, data 19.548) 0.00024 lr
Epoch 84 Iter 3800, train entropy gap 2.2170 bits (loss 21.765, data 19.548) 0.00024 lr
Epoch 84 Iter 4000, train entropy gap 1.0408 bits (loss 20.588, data 19.548) 0.00024 lr
Epoch 84 Iter 4200, train entropy gap 2.3717 bits (loss 21.919, data 19.548) 0.00024 lr
Epoch 84 Iter 4400, train entropy gap 1.6459 bits (loss 21.194, data 19.548) 0.00024 lr
Epoch 84 Iter 4600, train entropy gap 2.2738 bits (loss 21.822, data 19.548) 0.00024 lr
Epoch 84 Iter 4800, train entropy gap 1.3511 bits (loss 20.899, data 19.548) 0.00024 lr
Epoch 84 Iter 5000, train entropy gap 2.1418 bits (loss 21.690, data 19.548) 0.00024 lr
Epoch 84 Iter 5200, train entropy gap 1.6414 bits (loss 21.189, data 19.548) 0.00024 lr
Epoch 84 Iter 5400, train entropy gap 2.6094 bits (loss 22.157, data 19.548) 0.00024 lr
Epoch 84 Iter 5600, train entropy gap 1.1762 bits (loss 20.724, data 19.548) 0.00024 lr
Epoch 84 Iter 5800, train entropy gap 2.1524 bits (loss 21.700, data 19.548) 0.00024 lr
Epoch 84 Iter 6000, train entropy gap 2.5233 bits (loss 22.071, data 19.548) 0.00024 lr
epoch 84 train loss 14.7360 nats / 21.2596 bits
time since start: 11967.9 secs
Epoch 85 Iter 0, train entropy gap 2.0520 bits (loss 21.600, data 19.548) 0.00024 lr
Epoch 85 Iter 200, train entropy gap 1.3015 bits (loss 20.849, data 19.548) 0.00024 lr
Epoch 85 Iter 400, train entropy gap 0.6957 bits (loss 20.243, data 19.548) 0.00024 lr
Epoch 85 Iter 600, train entropy gap 1.2023 bits (loss 20.750, data 19.548) 0.00024 lr
Epoch 85 Iter 800, train entropy gap 1.8011 bits (loss 21.349, data 19.548) 0.00024 lr
Epoch 85 Iter 1000, train entropy gap 1.0301 bits (loss 20.578, data 19.548) 0.00024 lr
Epoch 85 Iter 1200, train entropy gap 0.9335 bits (loss 20.481, data 19.548) 0.00024 lr
Epoch 85 Iter 1400, train entropy gap 1.4029 bits (loss 20.951, data 19.548) 0.00024 lr
Epoch 85 Iter 1600, train entropy gap 2.5264 bits (loss 22.074, data 19.548) 0.00024 lr
Epoch 85 Iter 1800, train entropy gap 2.4705 bits (loss 22.018, data 19.548) 0.00024 lr
Epoch 85 Iter 2000, train entropy gap 1.0014 bits (loss 20.549, data 19.548) 0.00024 lr
Epoch 85 Iter 2200, train entropy gap 1.8576 bits (loss 21.405, data 19.548) 0.00024 lr
Epoch 85 Iter 2400, train entropy gap 1.1861 bits (loss 20.734, data 19.548) 0.00024 lr
Epoch 85 Iter 2600, train entropy gap 1.3984 bits (loss 20.946, data 19.548) 0.00024 lr
Epoch 85 Iter 2800, train entropy gap 1.9913 bits (loss 21.539, data 19.548) 0.00024 lr
Epoch 85 Iter 3000, train entropy gap 1.3124 bits (loss 20.860, data 19.548) 0.00024 lr
Epoch 85 Iter 3200, train entropy gap 2.3682 bits (loss 21.916, data 19.548) 0.00024 lr
Epoch 85 Iter 3400, train entropy gap 1.6714 bits (loss 21.219, data 19.548) 0.00024 lr
Epoch 85 Iter 3600, train entropy gap 1.3836 bits (loss 20.931, data 19.548) 0.00024 lr
Epoch 85 Iter 3800, train entropy gap 1.5490 bits (loss 21.097, data 19.548) 0.00024 lr
Epoch 85 Iter 4000, train entropy gap 1.4784 bits (loss 21.026, data 19.548) 0.00024 lr
Epoch 85 Iter 4200, train entropy gap 1.5237 bits (loss 21.071, data 19.548) 0.00024 lr
Epoch 85 Iter 4400, train entropy gap 1.4375 bits (loss 20.985, data 19.548) 0.00024 lr
Epoch 85 Iter 4600, train entropy gap 1.4697 bits (loss 21.017, data 19.548) 0.00024 lr
Epoch 85 Iter 4800, train entropy gap 1.2827 bits (loss 20.830, data 19.548) 0.00024 lr
Epoch 85 Iter 5000, train entropy gap 2.6518 bits (loss 22.200, data 19.548) 0.00024 lr
Epoch 85 Iter 5200, train entropy gap 1.8422 bits (loss 21.390, data 19.548) 0.00024 lr
Epoch 85 Iter 5400, train entropy gap 1.3252 bits (loss 20.873, data 19.548) 0.00024 lr
Epoch 85 Iter 5600, train entropy gap 2.1148 bits (loss 21.662, data 19.548) 0.00024 lr
Epoch 85 Iter 5800, train entropy gap 1.9015 bits (loss 21.449, data 19.548) 0.00024 lr
Epoch 85 Iter 6000, train entropy gap 2.2838 bits (loss 21.832, data 19.548) 0.00024 lr
epoch 85 train loss 14.7215 nats / 21.2387 bits
time since start: 12108.9 secs
Epoch 86 Iter 0, train entropy gap 1.5275 bits (loss 21.075, data 19.548) 0.00024 lr
Epoch 86 Iter 200, train entropy gap 0.6906 bits (loss 20.238, data 19.548) 0.00024 lr
Epoch 86 Iter 400, train entropy gap 0.9302 bits (loss 20.478, data 19.548) 0.00024 lr
Epoch 86 Iter 600, train entropy gap 1.3658 bits (loss 20.914, data 19.548) 0.00024 lr
Epoch 86 Iter 800, train entropy gap 1.1194 bits (loss 20.667, data 19.548) 0.00024 lr
Epoch 86 Iter 1000, train entropy gap 1.4713 bits (loss 21.019, data 19.548) 0.00024 lr
Epoch 86 Iter 1200, train entropy gap 1.3322 bits (loss 20.880, data 19.548) 0.00024 lr
Epoch 86 Iter 1400, train entropy gap 1.8212 bits (loss 21.369, data 19.548) 0.00024 lr
Epoch 86 Iter 1600, train entropy gap 1.2310 bits (loss 20.779, data 19.548) 0.00024 lr
Epoch 86 Iter 1800, train entropy gap 2.8499 bits (loss 22.398, data 19.548) 0.00024 lr
Epoch 86 Iter 2000, train entropy gap 1.9927 bits (loss 21.540, data 19.548) 0.00024 lr
Epoch 86 Iter 2200, train entropy gap 1.5419 bits (loss 21.090, data 19.548) 0.00024 lr
Epoch 86 Iter 2400, train entropy gap 2.9586 bits (loss 22.506, data 19.548) 0.00024 lr
Epoch 86 Iter 2600, train entropy gap 1.2423 bits (loss 20.790, data 19.548) 0.00024 lr
Epoch 86 Iter 2800, train entropy gap 1.4502 bits (loss 20.998, data 19.548) 0.00024 lr
Epoch 86 Iter 3000, train entropy gap 1.1224 bits (loss 20.670, data 19.548) 0.00024 lr
Epoch 86 Iter 3200, train entropy gap 1.5113 bits (loss 21.059, data 19.548) 0.00024 lr
Epoch 86 Iter 3400, train entropy gap 1.8010 bits (loss 21.349, data 19.548) 0.00024 lr
Epoch 86 Iter 3600, train entropy gap 1.3329 bits (loss 20.881, data 19.548) 0.00024 lr
Epoch 86 Iter 3800, train entropy gap 2.0576 bits (loss 21.605, data 19.548) 0.00024 lr
Epoch 86 Iter 4000, train entropy gap 1.2884 bits (loss 20.836, data 19.548) 0.00024 lr
Epoch 86 Iter 4200, train entropy gap 1.6362 bits (loss 21.184, data 19.548) 0.00024 lr
Epoch 86 Iter 4400, train entropy gap 1.7565 bits (loss 21.304, data 19.548) 0.00024 lr
Epoch 86 Iter 4600, train entropy gap 1.9100 bits (loss 21.458, data 19.548) 0.00024 lr
Epoch 86 Iter 4800, train entropy gap 2.1096 bits (loss 21.657, data 19.548) 0.00024 lr
Epoch 86 Iter 5000, train entropy gap 2.7940 bits (loss 22.342, data 19.548) 0.00024 lr
Epoch 86 Iter 5200, train entropy gap 2.2323 bits (loss 21.780, data 19.548) 0.00024 lr
Epoch 86 Iter 5400, train entropy gap 1.2603 bits (loss 20.808, data 19.548) 0.00024 lr
Epoch 86 Iter 5600, train entropy gap 0.8334 bits (loss 20.381, data 19.548) 0.00024 lr
Epoch 86 Iter 5800, train entropy gap 2.8211 bits (loss 22.369, data 19.548) 0.00024 lr
Epoch 86 Iter 6000, train entropy gap 2.3866 bits (loss 21.934, data 19.548) 0.00024 lr
epoch 86 train loss 14.7325 nats / 21.2545 bits
time since start: 12249.2 secs
Epoch 87 Iter 0, train entropy gap 1.0853 bits (loss 20.633, data 19.548) 0.00024 lr
Epoch 87 Iter 200, train entropy gap 1.0669 bits (loss 20.615, data 19.548) 0.00024 lr
Epoch 87 Iter 400, train entropy gap 1.7157 bits (loss 21.263, data 19.548) 0.00024 lr
Epoch 87 Iter 600, train entropy gap 1.7104 bits (loss 21.258, data 19.548) 0.00024 lr
Epoch 87 Iter 800, train entropy gap 1.8823 bits (loss 21.430, data 19.548) 0.00024 lr
Epoch 87 Iter 1000, train entropy gap 2.1582 bits (loss 21.706, data 19.548) 0.00024 lr
Epoch 87 Iter 1200, train entropy gap 1.3842 bits (loss 20.932, data 19.548) 0.00024 lr
Epoch 87 Iter 1400, train entropy gap 0.8233 bits (loss 20.371, data 19.548) 0.00024 lr
Epoch 87 Iter 1600, train entropy gap 2.2339 bits (loss 21.782, data 19.548) 0.00024 lr
Epoch 87 Iter 1800, train entropy gap 1.4834 bits (loss 21.031, data 19.548) 0.00024 lr
Epoch 87 Iter 2000, train entropy gap 2.2758 bits (loss 21.823, data 19.548) 0.00024 lr
Epoch 87 Iter 2200, train entropy gap 1.4259 bits (loss 20.974, data 19.548) 0.00024 lr
Epoch 87 Iter 2400, train entropy gap 1.5595 bits (loss 21.107, data 19.548) 0.00024 lr
Epoch 87 Iter 2600, train entropy gap 0.8725 bits (loss 20.420, data 19.548) 0.00024 lr
Epoch 87 Iter 2800, train entropy gap 1.3815 bits (loss 20.929, data 19.548) 0.00024 lr
Epoch 87 Iter 3000, train entropy gap 1.3120 bits (loss 20.860, data 19.548) 0.00024 lr
Epoch 87 Iter 3200, train entropy gap 1.5590 bits (loss 21.107, data 19.548) 0.00024 lr
Epoch 87 Iter 3400, train entropy gap 2.6345 bits (loss 22.182, data 19.548) 0.00024 lr
Epoch 87 Iter 3600, train entropy gap 1.8206 bits (loss 21.368, data 19.548) 0.00024 lr
Epoch 87 Iter 3800, train entropy gap 1.4541 bits (loss 21.002, data 19.548) 0.00024 lr
Epoch 87 Iter 4000, train entropy gap 1.1099 bits (loss 20.658, data 19.548) 0.00024 lr
Epoch 87 Iter 4200, train entropy gap 2.2638 bits (loss 21.811, data 19.548) 0.00024 lr
Epoch 87 Iter 4400, train entropy gap 1.3871 bits (loss 20.935, data 19.548) 0.00024 lr
Epoch 87 Iter 4600, train entropy gap 1.8086 bits (loss 21.356, data 19.548) 0.00024 lr
Epoch 87 Iter 4800, train entropy gap 1.6779 bits (loss 21.226, data 19.548) 0.00024 lr
Epoch 87 Iter 5000, train entropy gap 1.9228 bits (loss 21.471, data 19.548) 0.00024 lr
Epoch 87 Iter 5200, train entropy gap 1.7779 bits (loss 21.326, data 19.548) 0.00024 lr
Epoch 87 Iter 5400, train entropy gap 1.6250 bits (loss 21.173, data 19.548) 0.00024 lr
Epoch 87 Iter 5600, train entropy gap 1.3638 bits (loss 20.912, data 19.548) 0.00024 lr
Epoch 87 Iter 5800, train entropy gap 1.5942 bits (loss 21.142, data 19.548) 0.00024 lr
Epoch 87 Iter 6000, train entropy gap 1.6904 bits (loss 21.238, data 19.548) 0.00024 lr
epoch 87 train loss 14.7273 nats / 21.2469 bits
time since start: 12389.7 secs
Epoch 88 Iter 0, train entropy gap 1.6080 bits (loss 21.156, data 19.548) 0.00024 lr
Epoch 88 Iter 200, train entropy gap 1.3264 bits (loss 20.874, data 19.548) 0.00024 lr
Epoch 88 Iter 400, train entropy gap 2.1992 bits (loss 21.747, data 19.548) 0.00024 lr
Epoch 88 Iter 600, train entropy gap 1.3347 bits (loss 20.882, data 19.548) 0.00024 lr
Epoch 88 Iter 800, train entropy gap 1.3348 bits (loss 20.883, data 19.548) 0.00024 lr
Epoch 88 Iter 1000, train entropy gap 2.1314 bits (loss 21.679, data 19.548) 0.00024 lr
Epoch 88 Iter 1200, train entropy gap 2.4240 bits (loss 21.972, data 19.548) 0.00024 lr
Epoch 88 Iter 1400, train entropy gap 1.2352 bits (loss 20.783, data 19.548) 0.00024 lr
Epoch 88 Iter 1600, train entropy gap 1.4189 bits (loss 20.967, data 19.548) 0.00024 lr
Epoch 88 Iter 1800, train entropy gap 2.1175 bits (loss 21.665, data 19.548) 0.00024 lr
Epoch 88 Iter 2000, train entropy gap 1.2404 bits (loss 20.788, data 19.548) 0.00024 lr
Epoch 88 Iter 2200, train entropy gap 1.9074 bits (loss 21.455, data 19.548) 0.00024 lr
Epoch 88 Iter 2400, train entropy gap 1.3914 bits (loss 20.939, data 19.548) 0.00024 lr
Epoch 88 Iter 2600, train entropy gap 1.4409 bits (loss 20.989, data 19.548) 0.00024 lr
Epoch 88 Iter 2800, train entropy gap 1.6110 bits (loss 21.159, data 19.548) 0.00024 lr
Epoch 88 Iter 3000, train entropy gap 1.0505 bits (loss 20.598, data 19.548) 0.00024 lr
Epoch 88 Iter 3200, train entropy gap 1.3141 bits (loss 20.862, data 19.548) 0.00024 lr
Epoch 88 Iter 3400, train entropy gap 2.0161 bits (loss 21.564, data 19.548) 0.00024 lr
Epoch 88 Iter 3600, train entropy gap 1.4296 bits (loss 20.977, data 19.548) 0.00024 lr
Epoch 88 Iter 3800, train entropy gap 1.4191 bits (loss 20.967, data 19.548) 0.00024 lr
Epoch 88 Iter 4000, train entropy gap 2.7315 bits (loss 22.279, data 19.548) 0.00024 lr
Epoch 88 Iter 4200, train entropy gap 1.9338 bits (loss 21.482, data 19.548) 0.00024 lr
Epoch 88 Iter 4400, train entropy gap 2.3363 bits (loss 21.884, data 19.548) 0.00024 lr
Epoch 88 Iter 4600, train entropy gap 1.0282 bits (loss 20.576, data 19.548) 0.00024 lr
Epoch 88 Iter 4800, train entropy gap 1.4465 bits (loss 20.994, data 19.548) 0.00024 lr
Epoch 88 Iter 5000, train entropy gap 2.3351 bits (loss 21.883, data 19.548) 0.00024 lr
Epoch 88 Iter 5200, train entropy gap 1.5224 bits (loss 21.070, data 19.548) 0.00024 lr
Epoch 88 Iter 5400, train entropy gap 2.5630 bits (loss 22.111, data 19.548) 0.00024 lr
Epoch 88 Iter 5600, train entropy gap 2.7230 bits (loss 22.271, data 19.548) 0.00024 lr
Epoch 88 Iter 5800, train entropy gap 1.2588 bits (loss 20.807, data 19.548) 0.00024 lr
Epoch 88 Iter 6000, train entropy gap 1.5654 bits (loss 21.113, data 19.548) 0.00024 lr
epoch 88 train loss 14.7288 nats / 21.2492 bits
time since start: 12530.6 secs
Epoch 89 Iter 0, train entropy gap 2.4374 bits (loss 21.985, data 19.548) 0.00024 lr
Epoch 89 Iter 200, train entropy gap 2.5390 bits (loss 22.087, data 19.548) 0.00024 lr
Epoch 89 Iter 400, train entropy gap 1.1802 bits (loss 20.728, data 19.548) 0.00024 lr
Epoch 89 Iter 600, train entropy gap 2.0521 bits (loss 21.600, data 19.548) 0.00024 lr
Epoch 89 Iter 800, train entropy gap 1.4044 bits (loss 20.952, data 19.548) 0.00024 lr
Epoch 89 Iter 1000, train entropy gap 1.7482 bits (loss 21.296, data 19.548) 0.00024 lr
Epoch 89 Iter 1200, train entropy gap 1.6552 bits (loss 21.203, data 19.548) 0.00024 lr
Epoch 89 Iter 1400, train entropy gap 2.0432 bits (loss 21.591, data 19.548) 0.00024 lr
Epoch 89 Iter 1600, train entropy gap 1.2183 bits (loss 20.766, data 19.548) 0.00024 lr
Epoch 89 Iter 1800, train entropy gap 2.3481 bits (loss 21.896, data 19.548) 0.00024 lr
Epoch 89 Iter 2000, train entropy gap 1.2515 bits (loss 20.799, data 19.548) 0.00024 lr
Epoch 89 Iter 2200, train entropy gap 1.7768 bits (loss 21.325, data 19.548) 0.00024 lr
Epoch 89 Iter 2400, train entropy gap 2.1075 bits (loss 21.655, data 19.548) 0.00024 lr
Epoch 89 Iter 2600, train entropy gap 1.8209 bits (loss 21.369, data 19.548) 0.00024 lr
Epoch 89 Iter 2800, train entropy gap 1.5658 bits (loss 21.114, data 19.548) 0.00024 lr
Epoch 89 Iter 3000, train entropy gap 1.6729 bits (loss 21.221, data 19.548) 0.00024 lr
Epoch 89 Iter 3200, train entropy gap 1.6092 bits (loss 21.157, data 19.548) 0.00024 lr
Epoch 89 Iter 3400, train entropy gap 2.7591 bits (loss 22.307, data 19.548) 0.00024 lr
Epoch 89 Iter 3600, train entropy gap 1.7585 bits (loss 21.306, data 19.548) 0.00024 lr
Epoch 89 Iter 3800, train entropy gap 1.3862 bits (loss 20.934, data 19.548) 0.00024 lr
Epoch 89 Iter 4000, train entropy gap 2.1781 bits (loss 21.726, data 19.548) 0.00024 lr
Epoch 89 Iter 4200, train entropy gap 1.0079 bits (loss 20.556, data 19.548) 0.00024 lr
Epoch 89 Iter 4400, train entropy gap 1.3333 bits (loss 20.881, data 19.548) 0.00024 lr
Epoch 89 Iter 4600, train entropy gap 1.9991 bits (loss 21.547, data 19.548) 0.00024 lr
Epoch 89 Iter 4800, train entropy gap 2.6341 bits (loss 22.182, data 19.548) 0.00024 lr
Epoch 89 Iter 5000, train entropy gap 1.9366 bits (loss 21.484, data 19.548) 0.00024 lr
Epoch 89 Iter 5200, train entropy gap 2.5473 bits (loss 22.095, data 19.548) 0.00024 lr
Epoch 89 Iter 5400, train entropy gap 1.5515 bits (loss 21.099, data 19.548) 0.00024 lr
Epoch 89 Iter 5600, train entropy gap 2.2042 bits (loss 21.752, data 19.548) 0.00024 lr
Epoch 89 Iter 5800, train entropy gap 2.2211 bits (loss 21.769, data 19.548) 0.00024 lr
Epoch 89 Iter 6000, train entropy gap 1.2534 bits (loss 20.801, data 19.548) 0.00024 lr
epoch 89 train loss 14.7380 nats / 21.2625 bits
time since start: 12671.6 secs
Epoch 90 Iter 0, train entropy gap 1.4299 bits (loss 20.978, data 19.548) 0.00024 lr
Epoch 90 Iter 200, train entropy gap 2.0619 bits (loss 21.610, data 19.548) 0.00024 lr
Epoch 90 Iter 400, train entropy gap 1.0883 bits (loss 20.636, data 19.548) 0.00024 lr
Epoch 90 Iter 600, train entropy gap 2.0400 bits (loss 21.588, data 19.548) 0.00024 lr
Epoch 90 Iter 800, train entropy gap 1.9521 bits (loss 21.500, data 19.548) 0.00024 lr
Epoch 90 Iter 1000, train entropy gap 2.1440 bits (loss 21.692, data 19.548) 0.00024 lr
Epoch 90 Iter 1200, train entropy gap 2.8933 bits (loss 22.441, data 19.548) 0.00024 lr
Epoch 90 Iter 1400, train entropy gap 2.2493 bits (loss 21.797, data 19.548) 0.00024 lr
Epoch 90 Iter 1600, train entropy gap 2.6017 bits (loss 22.149, data 19.548) 0.00024 lr
Epoch 90 Iter 1800, train entropy gap 1.1117 bits (loss 20.659, data 19.548) 0.00024 lr
Epoch 90 Iter 2000, train entropy gap 2.3323 bits (loss 21.880, data 19.548) 0.00024 lr
Epoch 90 Iter 2200, train entropy gap 3.1828 bits (loss 22.731, data 19.548) 0.00024 lr
Epoch 90 Iter 2400, train entropy gap 1.4859 bits (loss 21.034, data 19.548) 0.00024 lr
Epoch 90 Iter 2600, train entropy gap 0.7116 bits (loss 20.259, data 19.548) 0.00024 lr
Epoch 90 Iter 2800, train entropy gap 1.0466 bits (loss 20.594, data 19.548) 0.00024 lr
Epoch 90 Iter 3000, train entropy gap 1.9546 bits (loss 21.502, data 19.548) 0.00024 lr
Epoch 90 Iter 3200, train entropy gap 2.5261 bits (loss 22.074, data 19.548) 0.00024 lr
Epoch 90 Iter 3400, train entropy gap 1.4545 bits (loss 21.002, data 19.548) 0.00024 lr
Epoch 90 Iter 3600, train entropy gap 1.1716 bits (loss 20.719, data 19.548) 0.00024 lr
Epoch 90 Iter 3800, train entropy gap 1.4068 bits (loss 20.955, data 19.548) 0.00024 lr
Epoch 90 Iter 4000, train entropy gap 1.7785 bits (loss 21.326, data 19.548) 0.00024 lr
Epoch 90 Iter 4200, train entropy gap 1.1875 bits (loss 20.735, data 19.548) 0.00024 lr
Epoch 90 Iter 4400, train entropy gap 1.3717 bits (loss 20.919, data 19.548) 0.00024 lr
Epoch 90 Iter 4600, train entropy gap 1.3155 bits (loss 20.863, data 19.548) 0.00024 lr
Epoch 90 Iter 4800, train entropy gap 2.1867 bits (loss 21.734, data 19.548) 0.00024 lr
Epoch 90 Iter 5000, train entropy gap 2.4231 bits (loss 21.971, data 19.548) 0.00024 lr
Epoch 90 Iter 5200, train entropy gap 1.7357 bits (loss 21.283, data 19.548) 0.00024 lr
Epoch 90 Iter 5400, train entropy gap 1.6478 bits (loss 21.196, data 19.548) 0.00024 lr
Epoch 90 Iter 5600, train entropy gap 1.4790 bits (loss 21.027, data 19.548) 0.00024 lr
Epoch 90 Iter 5800, train entropy gap 2.7087 bits (loss 22.256, data 19.548) 0.00024 lr
Epoch 90 Iter 6000, train entropy gap 1.4032 bits (loss 20.951, data 19.548) 0.00024 lr
epoch 90 train loss 14.7303 nats / 21.2514 bits
time since start: 12806.6 secs
Epoch 91 Iter 0, train entropy gap 3.1993 bits (loss 22.747, data 19.548) 0.00024 lr
Epoch 91 Iter 200, train entropy gap 1.2510 bits (loss 20.799, data 19.548) 0.00024 lr
Epoch 91 Iter 400, train entropy gap 2.1400 bits (loss 21.688, data 19.548) 0.00024 lr
Epoch 91 Iter 600, train entropy gap 1.6894 bits (loss 21.237, data 19.548) 0.00024 lr
Epoch 91 Iter 800, train entropy gap 1.2292 bits (loss 20.777, data 19.548) 0.00024 lr
Epoch 91 Iter 1000, train entropy gap 2.5326 bits (loss 22.080, data 19.548) 0.00024 lr
Epoch 91 Iter 1200, train entropy gap 1.1924 bits (loss 20.740, data 19.548) 0.00024 lr
Epoch 91 Iter 1400, train entropy gap 1.8024 bits (loss 21.350, data 19.548) 0.00024 lr
Epoch 91 Iter 1600, train entropy gap 2.0862 bits (loss 21.634, data 19.548) 0.00024 lr
Epoch 91 Iter 1800, train entropy gap 2.5792 bits (loss 22.127, data 19.548) 0.00024 lr
Epoch 91 Iter 2000, train entropy gap 1.7467 bits (loss 21.294, data 19.548) 0.00024 lr
Epoch 91 Iter 2200, train entropy gap 1.1121 bits (loss 20.660, data 19.548) 0.00024 lr
Epoch 91 Iter 2400, train entropy gap 1.2630 bits (loss 20.811, data 19.548) 0.00024 lr
Epoch 91 Iter 2600, train entropy gap 1.6181 bits (loss 21.166, data 19.548) 0.00024 lr
Epoch 91 Iter 2800, train entropy gap 2.3868 bits (loss 21.935, data 19.548) 0.00024 lr
Epoch 91 Iter 3000, train entropy gap 1.1941 bits (loss 20.742, data 19.548) 0.00024 lr
Epoch 91 Iter 3200, train entropy gap 1.7688 bits (loss 21.317, data 19.548) 0.00024 lr
Epoch 91 Iter 3400, train entropy gap 2.4898 bits (loss 22.038, data 19.548) 0.00024 lr
Epoch 91 Iter 3600, train entropy gap 1.2336 bits (loss 20.781, data 19.548) 0.00024 lr
Epoch 91 Iter 3800, train entropy gap 1.6957 bits (loss 21.243, data 19.548) 0.00024 lr
Epoch 91 Iter 4000, train entropy gap 1.6257 bits (loss 21.173, data 19.548) 0.00024 lr
Epoch 91 Iter 4200, train entropy gap 2.5608 bits (loss 22.109, data 19.548) 0.00024 lr
Epoch 91 Iter 4400, train entropy gap 1.4218 bits (loss 20.969, data 19.548) 0.00024 lr
Epoch 91 Iter 4600, train entropy gap 0.9611 bits (loss 20.509, data 19.548) 0.00024 lr
Epoch 91 Iter 4800, train entropy gap 2.3586 bits (loss 21.906, data 19.548) 0.00024 lr
Epoch 91 Iter 5000, train entropy gap 0.9410 bits (loss 20.489, data 19.548) 0.00024 lr
Epoch 91 Iter 5200, train entropy gap 2.8602 bits (loss 22.408, data 19.548) 0.00023 lr
Epoch 91 Iter 5400, train entropy gap 1.8681 bits (loss 21.416, data 19.548) 0.00023 lr
Epoch 91 Iter 5600, train entropy gap 1.9647 bits (loss 21.512, data 19.548) 0.00023 lr
Epoch 91 Iter 5800, train entropy gap 2.0078 bits (loss 21.556, data 19.548) 0.00023 lr
Epoch 91 Iter 6000, train entropy gap 1.7521 bits (loss 21.300, data 19.548) 0.00023 lr
epoch 91 train loss 14.7240 nats / 21.2423 bits
time since start: 12947.7 secs
Epoch 92 Iter 0, train entropy gap 1.9228 bits (loss 21.470, data 19.548) 0.00023 lr
Epoch 92 Iter 200, train entropy gap 1.6165 bits (loss 21.164, data 19.548) 0.00023 lr
Epoch 92 Iter 400, train entropy gap 1.5118 bits (loss 21.059, data 19.548) 0.00023 lr
Epoch 92 Iter 600, train entropy gap 2.1258 bits (loss 21.674, data 19.548) 0.00023 lr
Epoch 92 Iter 800, train entropy gap 1.1833 bits (loss 20.731, data 19.548) 0.00023 lr
Epoch 92 Iter 1000, train entropy gap 2.1400 bits (loss 21.688, data 19.548) 0.00023 lr
Epoch 92 Iter 1200, train entropy gap 1.4167 bits (loss 20.964, data 19.548) 0.00023 lr
Epoch 92 Iter 1400, train entropy gap 1.8345 bits (loss 21.382, data 19.548) 0.00023 lr
Epoch 92 Iter 1600, train entropy gap 0.9770 bits (loss 20.525, data 19.548) 0.00023 lr
Epoch 92 Iter 1800, train entropy gap 1.5955 bits (loss 21.143, data 19.548) 0.00023 lr
Epoch 92 Iter 2000, train entropy gap 1.4120 bits (loss 20.960, data 19.548) 0.00023 lr
Epoch 92 Iter 2200, train entropy gap 1.9948 bits (loss 21.543, data 19.548) 0.00023 lr
Epoch 92 Iter 2400, train entropy gap 1.8065 bits (loss 21.354, data 19.548) 0.00023 lr
Epoch 92 Iter 2600, train entropy gap 1.2794 bits (loss 20.827, data 19.548) 0.00023 lr
Epoch 92 Iter 2800, train entropy gap 0.9345 bits (loss 20.482, data 19.548) 0.00023 lr
Epoch 92 Iter 3000, train entropy gap 2.1067 bits (loss 21.654, data 19.548) 0.00023 lr
Epoch 92 Iter 3200, train entropy gap 1.3508 bits (loss 20.899, data 19.548) 0.00023 lr
Epoch 92 Iter 3400, train entropy gap 1.4951 bits (loss 21.043, data 19.548) 0.00023 lr
Epoch 92 Iter 3600, train entropy gap 1.5391 bits (loss 21.087, data 19.548) 0.00023 lr
Epoch 92 Iter 3800, train entropy gap 1.6758 bits (loss 21.223, data 19.548) 0.00023 lr
Epoch 92 Iter 4000, train entropy gap 1.7486 bits (loss 21.296, data 19.548) 0.00023 lr
Epoch 92 Iter 4200, train entropy gap 1.4959 bits (loss 21.044, data 19.548) 0.00023 lr
Epoch 92 Iter 4400, train entropy gap 1.1993 bits (loss 20.747, data 19.548) 0.00023 lr
Epoch 92 Iter 4600, train entropy gap 1.1774 bits (loss 20.725, data 19.548) 0.00023 lr
Epoch 92 Iter 4800, train entropy gap 2.1815 bits (loss 21.729, data 19.548) 0.00023 lr
Epoch 92 Iter 5000, train entropy gap 1.2223 bits (loss 20.770, data 19.548) 0.00023 lr
Epoch 92 Iter 5200, train entropy gap 1.5630 bits (loss 21.111, data 19.548) 0.00023 lr
Epoch 92 Iter 5400, train entropy gap 2.4503 bits (loss 21.998, data 19.548) 0.00023 lr
Epoch 92 Iter 5600, train entropy gap 2.6679 bits (loss 22.216, data 19.548) 0.00023 lr
Epoch 92 Iter 5800, train entropy gap 2.4824 bits (loss 22.030, data 19.548) 0.00023 lr
Epoch 92 Iter 6000, train entropy gap 1.4084 bits (loss 20.956, data 19.548) 0.00023 lr
epoch 92 train loss 14.7384 nats / 21.2631 bits
time since start: 13088.8 secs
Epoch 93 Iter 0, train entropy gap 0.9683 bits (loss 20.516, data 19.548) 0.00023 lr
Epoch 93 Iter 200, train entropy gap 2.0494 bits (loss 21.597, data 19.548) 0.00023 lr
Epoch 93 Iter 400, train entropy gap 1.4513 bits (loss 20.999, data 19.548) 0.00023 lr
Epoch 93 Iter 600, train entropy gap 1.2593 bits (loss 20.807, data 19.548) 0.00023 lr
Epoch 93 Iter 800, train entropy gap 1.5181 bits (loss 21.066, data 19.548) 0.00023 lr
Epoch 93 Iter 1000, train entropy gap 2.0991 bits (loss 21.647, data 19.548) 0.00023 lr
Epoch 93 Iter 1200, train entropy gap 2.0499 bits (loss 21.598, data 19.548) 0.00023 lr
Epoch 93 Iter 1400, train entropy gap 1.6627 bits (loss 21.210, data 19.548) 0.00023 lr
Epoch 93 Iter 1600, train entropy gap 1.4549 bits (loss 21.003, data 19.548) 0.00023 lr
Epoch 93 Iter 1800, train entropy gap 1.4181 bits (loss 20.966, data 19.548) 0.00023 lr
Epoch 93 Iter 2000, train entropy gap 1.9254 bits (loss 21.473, data 19.548) 0.00023 lr
Epoch 93 Iter 2200, train entropy gap 0.9424 bits (loss 20.490, data 19.548) 0.00023 lr
Epoch 93 Iter 2400, train entropy gap 0.9614 bits (loss 20.509, data 19.548) 0.00023 lr
Epoch 93 Iter 2600, train entropy gap 1.8239 bits (loss 21.372, data 19.548) 0.00023 lr
Epoch 93 Iter 2800, train entropy gap 1.2557 bits (loss 20.803, data 19.548) 0.00023 lr
Epoch 93 Iter 3000, train entropy gap 1.4273 bits (loss 20.975, data 19.548) 0.00023 lr
Epoch 93 Iter 3200, train entropy gap 1.8718 bits (loss 21.420, data 19.548) 0.00023 lr
Epoch 93 Iter 3400, train entropy gap 2.0218 bits (loss 21.569, data 19.548) 0.00023 lr
Epoch 93 Iter 3600, train entropy gap 1.4879 bits (loss 21.036, data 19.548) 0.00023 lr
Epoch 93 Iter 3800, train entropy gap 1.3892 bits (loss 20.937, data 19.548) 0.00023 lr
Epoch 93 Iter 4000, train entropy gap 2.0404 bits (loss 21.588, data 19.548) 0.00023 lr
Epoch 93 Iter 4200, train entropy gap 1.5875 bits (loss 21.135, data 19.548) 0.00023 lr
Epoch 93 Iter 4400, train entropy gap 1.4176 bits (loss 20.965, data 19.548) 0.00023 lr
Epoch 93 Iter 4600, train entropy gap 1.1138 bits (loss 20.661, data 19.548) 0.00023 lr
Epoch 93 Iter 4800, train entropy gap 1.4996 bits (loss 21.047, data 19.548) 0.00023 lr
Epoch 93 Iter 5000, train entropy gap 1.1841 bits (loss 20.732, data 19.548) 0.00023 lr
Epoch 93 Iter 5200, train entropy gap 2.0567 bits (loss 21.604, data 19.548) 0.00023 lr
Epoch 93 Iter 5400, train entropy gap 1.0385 bits (loss 20.586, data 19.548) 0.00023 lr
Epoch 93 Iter 5600, train entropy gap 2.0637 bits (loss 21.611, data 19.548) 0.00023 lr
Epoch 93 Iter 5800, train entropy gap 1.8139 bits (loss 21.362, data 19.548) 0.00023 lr
Epoch 93 Iter 6000, train entropy gap 1.1460 bits (loss 20.694, data 19.548) 0.00023 lr
epoch 93 train loss 14.7279 nats / 21.2479 bits
time since start: 13229.4 secs
Epoch 94 Iter 0, train entropy gap 1.1301 bits (loss 20.678, data 19.548) 0.00023 lr
Epoch 94 Iter 200, train entropy gap 1.1148 bits (loss 20.662, data 19.548) 0.00023 lr
Epoch 94 Iter 400, train entropy gap 1.5033 bits (loss 21.051, data 19.548) 0.00023 lr
Epoch 94 Iter 600, train entropy gap 1.8193 bits (loss 21.367, data 19.548) 0.00023 lr
Epoch 94 Iter 800, train entropy gap 1.2872 bits (loss 20.835, data 19.548) 0.00023 lr
Epoch 94 Iter 1000, train entropy gap 1.2127 bits (loss 20.760, data 19.548) 0.00023 lr
Epoch 94 Iter 1200, train entropy gap 1.4923 bits (loss 21.040, data 19.548) 0.00023 lr
Epoch 94 Iter 1400, train entropy gap 2.6164 bits (loss 22.164, data 19.548) 0.00023 lr
Epoch 94 Iter 1600, train entropy gap 1.4467 bits (loss 20.994, data 19.548) 0.00023 lr
Epoch 94 Iter 1800, train entropy gap 1.7759 bits (loss 21.324, data 19.548) 0.00023 lr
Epoch 94 Iter 2000, train entropy gap 1.5824 bits (loss 21.130, data 19.548) 0.00023 lr
Epoch 94 Iter 2200, train entropy gap 0.9924 bits (loss 20.540, data 19.548) 0.00023 lr
Epoch 94 Iter 2400, train entropy gap 1.9489 bits (loss 21.497, data 19.548) 0.00023 lr
Epoch 94 Iter 2600, train entropy gap 1.5843 bits (loss 21.132, data 19.548) 0.00023 lr
Epoch 94 Iter 2800, train entropy gap 1.3923 bits (loss 20.940, data 19.548) 0.00023 lr
Epoch 94 Iter 3000, train entropy gap 1.8077 bits (loss 21.355, data 19.548) 0.00023 lr
Epoch 94 Iter 3200, train entropy gap 1.8014 bits (loss 21.349, data 19.548) 0.00023 lr
Epoch 94 Iter 3400, train entropy gap 1.8613 bits (loss 21.409, data 19.548) 0.00023 lr
Epoch 94 Iter 3600, train entropy gap 1.2358 bits (loss 20.783, data 19.548) 0.00023 lr
Epoch 94 Iter 3800, train entropy gap 2.3972 bits (loss 21.945, data 19.548) 0.00023 lr
Epoch 94 Iter 4000, train entropy gap 1.3888 bits (loss 20.937, data 19.548) 0.00023 lr
Epoch 94 Iter 4200, train entropy gap 1.5581 bits (loss 21.106, data 19.548) 0.00023 lr
Epoch 94 Iter 4400, train entropy gap 2.2475 bits (loss 21.795, data 19.548) 0.00023 lr
Epoch 94 Iter 4600, train entropy gap 1.9661 bits (loss 21.514, data 19.548) 0.00023 lr
Epoch 94 Iter 4800, train entropy gap 1.4616 bits (loss 21.009, data 19.548) 0.00023 lr
Epoch 94 Iter 5000, train entropy gap 2.4142 bits (loss 21.962, data 19.548) 0.00023 lr
Epoch 94 Iter 5200, train entropy gap 0.8986 bits (loss 20.446, data 19.548) 0.00023 lr
Epoch 94 Iter 5400, train entropy gap 1.4196 bits (loss 20.967, data 19.548) 0.00023 lr
Epoch 94 Iter 5600, train entropy gap 1.1966 bits (loss 20.744, data 19.548) 0.00023 lr
Epoch 94 Iter 5800, train entropy gap 2.1679 bits (loss 21.716, data 19.548) 0.00023 lr
Epoch 94 Iter 6000, train entropy gap 1.5821 bits (loss 21.130, data 19.548) 0.00023 lr
epoch 94 train loss 14.7347 nats / 21.2576 bits
time since start: 13370.0 secs
Epoch 95 Iter 0, train entropy gap 2.8313 bits (loss 22.379, data 19.548) 0.00023 lr
Epoch 95 Iter 200, train entropy gap 1.7735 bits (loss 21.321, data 19.548) 0.00023 lr
Epoch 95 Iter 400, train entropy gap 1.5553 bits (loss 21.103, data 19.548) 0.00023 lr
Epoch 95 Iter 600, train entropy gap 2.7432 bits (loss 22.291, data 19.548) 0.00023 lr
Epoch 95 Iter 800, train entropy gap 1.9580 bits (loss 21.506, data 19.548) 0.00023 lr
Epoch 95 Iter 1000, train entropy gap 1.0581 bits (loss 20.606, data 19.548) 0.00023 lr
Epoch 95 Iter 1200, train entropy gap 1.6192 bits (loss 21.167, data 19.548) 0.00023 lr
Epoch 95 Iter 1400, train entropy gap 1.6428 bits (loss 21.191, data 19.548) 0.00023 lr
Epoch 95 Iter 1600, train entropy gap 1.6345 bits (loss 21.182, data 19.548) 0.00023 lr
Epoch 95 Iter 1800, train entropy gap 2.0198 bits (loss 21.568, data 19.548) 0.00023 lr
Epoch 95 Iter 2000, train entropy gap 1.2280 bits (loss 20.776, data 19.548) 0.00023 lr
Epoch 95 Iter 2200, train entropy gap 1.6773 bits (loss 21.225, data 19.548) 0.00023 lr
Epoch 95 Iter 2400, train entropy gap 1.6055 bits (loss 21.153, data 19.548) 0.00023 lr
Epoch 95 Iter 2600, train entropy gap 2.1268 bits (loss 21.675, data 19.548) 0.00023 lr
Epoch 95 Iter 2800, train entropy gap 1.6017 bits (loss 21.149, data 19.548) 0.00023 lr
Epoch 95 Iter 3000, train entropy gap 1.7452 bits (loss 21.293, data 19.548) 0.00023 lr
Epoch 95 Iter 3200, train entropy gap 1.8668 bits (loss 21.415, data 19.548) 0.00023 lr
Epoch 95 Iter 3400, train entropy gap 1.9558 bits (loss 21.504, data 19.548) 0.00023 lr
Epoch 95 Iter 3600, train entropy gap 1.1732 bits (loss 20.721, data 19.548) 0.00023 lr
Epoch 95 Iter 3800, train entropy gap 1.8470 bits (loss 21.395, data 19.548) 0.00023 lr
Epoch 95 Iter 4000, train entropy gap 2.0153 bits (loss 21.563, data 19.548) 0.00023 lr
Epoch 95 Iter 4200, train entropy gap 1.8812 bits (loss 21.429, data 19.548) 0.00023 lr
Epoch 95 Iter 4400, train entropy gap 1.4742 bits (loss 21.022, data 19.548) 0.00023 lr
Epoch 95 Iter 4600, train entropy gap 2.2822 bits (loss 21.830, data 19.548) 0.00023 lr
Epoch 95 Iter 4800, train entropy gap 1.4985 bits (loss 21.046, data 19.548) 0.00023 lr
Epoch 95 Iter 5000, train entropy gap 1.4680 bits (loss 21.016, data 19.548) 0.00023 lr
Epoch 95 Iter 5200, train entropy gap 2.2309 bits (loss 21.779, data 19.548) 0.00023 lr
Epoch 95 Iter 5400, train entropy gap 1.1102 bits (loss 20.658, data 19.548) 0.00023 lr
Epoch 95 Iter 5600, train entropy gap 1.0377 bits (loss 20.585, data 19.548) 0.00023 lr
Epoch 95 Iter 5800, train entropy gap 1.3757 bits (loss 20.923, data 19.548) 0.00023 lr
Epoch 95 Iter 6000, train entropy gap 1.4126 bits (loss 20.960, data 19.548) 0.00023 lr
epoch 95 train loss 14.7337 nats / 21.2563 bits
time since start: 13511.0 secs
Epoch 96 Iter 0, train entropy gap 1.3954 bits (loss 20.943, data 19.548) 0.00023 lr
Epoch 96 Iter 200, train entropy gap 1.4766 bits (loss 21.024, data 19.548) 0.00023 lr
Epoch 96 Iter 400, train entropy gap 1.8667 bits (loss 21.414, data 19.548) 0.00023 lr
Epoch 96 Iter 600, train entropy gap 1.2539 bits (loss 20.802, data 19.548) 0.00023 lr
Epoch 96 Iter 800, train entropy gap 1.4924 bits (loss 21.040, data 19.548) 0.00023 lr
Epoch 96 Iter 1000, train entropy gap 2.2099 bits (loss 21.758, data 19.548) 0.00023 lr
Epoch 96 Iter 1200, train entropy gap 2.1656 bits (loss 21.713, data 19.548) 0.00023 lr
Epoch 96 Iter 1400, train entropy gap 1.6252 bits (loss 21.173, data 19.548) 0.00023 lr
Epoch 96 Iter 1600, train entropy gap 2.1710 bits (loss 21.719, data 19.548) 0.00023 lr
Epoch 96 Iter 1800, train entropy gap 1.4103 bits (loss 20.958, data 19.548) 0.00023 lr
Epoch 96 Iter 2000, train entropy gap 2.2592 bits (loss 21.807, data 19.548) 0.00023 lr
Epoch 96 Iter 2200, train entropy gap 1.8515 bits (loss 21.399, data 19.548) 0.00023 lr
Epoch 96 Iter 2400, train entropy gap 2.1719 bits (loss 21.720, data 19.548) 0.00023 lr
Epoch 96 Iter 2600, train entropy gap 1.7324 bits (loss 21.280, data 19.548) 0.00023 lr
Epoch 96 Iter 2800, train entropy gap 1.4472 bits (loss 20.995, data 19.548) 0.00023 lr
Epoch 96 Iter 3000, train entropy gap 2.7283 bits (loss 22.276, data 19.548) 0.00023 lr
Epoch 96 Iter 3200, train entropy gap 1.0491 bits (loss 20.597, data 19.548) 0.00023 lr
Epoch 96 Iter 3400, train entropy gap 1.7810 bits (loss 21.329, data 19.548) 0.00023 lr
Epoch 96 Iter 3600, train entropy gap 1.3269 bits (loss 20.875, data 19.548) 0.00023 lr
Epoch 96 Iter 3800, train entropy gap 1.7331 bits (loss 21.281, data 19.548) 0.00023 lr
Epoch 96 Iter 4000, train entropy gap 1.9926 bits (loss 21.540, data 19.548) 0.00023 lr
Epoch 96 Iter 4200, train entropy gap 2.0860 bits (loss 21.634, data 19.548) 0.00023 lr
Epoch 96 Iter 4400, train entropy gap 1.1322 bits (loss 20.680, data 19.548) 0.00023 lr
Epoch 96 Iter 4600, train entropy gap 2.4093 bits (loss 21.957, data 19.548) 0.00023 lr
Epoch 96 Iter 4800, train entropy gap 1.1028 bits (loss 20.651, data 19.548) 0.00023 lr
Epoch 96 Iter 5000, train entropy gap 1.2123 bits (loss 20.760, data 19.548) 0.00023 lr
Epoch 96 Iter 5200, train entropy gap 1.5260 bits (loss 21.074, data 19.548) 0.00023 lr
Epoch 96 Iter 5400, train entropy gap 2.2864 bits (loss 21.834, data 19.548) 0.00023 lr
Epoch 96 Iter 5600, train entropy gap 1.8816 bits (loss 21.429, data 19.548) 0.00023 lr
Epoch 96 Iter 5800, train entropy gap 0.8859 bits (loss 20.434, data 19.548) 0.00023 lr
Epoch 96 Iter 6000, train entropy gap 1.2140 bits (loss 20.762, data 19.548) 0.00023 lr
epoch 96 train loss 14.7296 nats / 21.2504 bits
time since start: 13651.7 secs
Epoch 97 Iter 0, train entropy gap 2.5568 bits (loss 22.105, data 19.548) 0.00023 lr
Epoch 97 Iter 200, train entropy gap 1.7788 bits (loss 21.326, data 19.548) 0.00023 lr
Epoch 97 Iter 400, train entropy gap 1.0190 bits (loss 20.567, data 19.548) 0.00023 lr
Epoch 97 Iter 600, train entropy gap 2.8461 bits (loss 22.394, data 19.548) 0.00023 lr
Epoch 97 Iter 800, train entropy gap 2.1765 bits (loss 21.724, data 19.548) 0.00023 lr
Epoch 97 Iter 1000, train entropy gap 2.1254 bits (loss 21.673, data 19.548) 0.00023 lr
Epoch 97 Iter 1200, train entropy gap 1.2145 bits (loss 20.762, data 19.548) 0.00023 lr
Epoch 97 Iter 1400, train entropy gap 1.0335 bits (loss 20.581, data 19.548) 0.00023 lr
Epoch 97 Iter 1600, train entropy gap 0.9615 bits (loss 20.509, data 19.548) 0.00023 lr
Epoch 97 Iter 1800, train entropy gap 2.0122 bits (loss 21.560, data 19.548) 0.00023 lr
Epoch 97 Iter 2000, train entropy gap 2.2216 bits (loss 21.769, data 19.548) 0.00023 lr
Epoch 97 Iter 2200, train entropy gap 1.8575 bits (loss 21.405, data 19.548) 0.00023 lr
Epoch 97 Iter 2400, train entropy gap 2.4092 bits (loss 21.957, data 19.548) 0.00023 lr
Epoch 97 Iter 2600, train entropy gap 1.1809 bits (loss 20.729, data 19.548) 0.00023 lr
Epoch 97 Iter 2800, train entropy gap 2.6295 bits (loss 22.177, data 19.548) 0.00023 lr
Epoch 97 Iter 3000, train entropy gap 1.2491 bits (loss 20.797, data 19.548) 0.00023 lr
Epoch 97 Iter 3200, train entropy gap 2.2168 bits (loss 21.765, data 19.548) 0.00023 lr
Epoch 97 Iter 3400, train entropy gap 2.8130 bits (loss 22.361, data 19.548) 0.00023 lr
Epoch 97 Iter 3600, train entropy gap 1.3536 bits (loss 20.901, data 19.548) 0.00023 lr
Epoch 97 Iter 3800, train entropy gap 2.2897 bits (loss 21.837, data 19.548) 0.00023 lr
Epoch 97 Iter 4000, train entropy gap 1.0426 bits (loss 20.590, data 19.548) 0.00023 lr
Epoch 97 Iter 4200, train entropy gap 0.8238 bits (loss 20.372, data 19.548) 0.00023 lr
Epoch 97 Iter 4400, train entropy gap 1.4050 bits (loss 20.953, data 19.548) 0.00023 lr
Epoch 97 Iter 4600, train entropy gap 0.8951 bits (loss 20.443, data 19.548) 0.00023 lr
Epoch 97 Iter 4800, train entropy gap 2.2363 bits (loss 21.784, data 19.548) 0.00023 lr
Epoch 97 Iter 5000, train entropy gap 1.3025 bits (loss 20.850, data 19.548) 0.00023 lr
Epoch 97 Iter 5200, train entropy gap 1.3920 bits (loss 20.940, data 19.548) 0.00023 lr
Epoch 97 Iter 5400, train entropy gap 2.2156 bits (loss 21.763, data 19.548) 0.00023 lr
Epoch 97 Iter 5600, train entropy gap 2.1128 bits (loss 21.661, data 19.548) 0.00023 lr
Epoch 97 Iter 5800, train entropy gap 0.9691 bits (loss 20.517, data 19.548) 0.00023 lr
Epoch 97 Iter 6000, train entropy gap 3.3969 bits (loss 22.945, data 19.548) 0.00023 lr
epoch 97 train loss 14.7345 nats / 21.2574 bits
time since start: 13792.3 secs
Epoch 98 Iter 0, train entropy gap 0.9303 bits (loss 20.478, data 19.548) 0.00023 lr
Epoch 98 Iter 200, train entropy gap 1.6799 bits (loss 21.228, data 19.548) 0.00023 lr
Epoch 98 Iter 400, train entropy gap 1.7682 bits (loss 21.316, data 19.548) 0.00023 lr
Epoch 98 Iter 600, train entropy gap 1.7334 bits (loss 21.281, data 19.548) 0.00023 lr
Epoch 98 Iter 800, train entropy gap 1.6405 bits (loss 21.188, data 19.548) 0.00023 lr
Epoch 98 Iter 1000, train entropy gap 2.1057 bits (loss 21.653, data 19.548) 0.00023 lr
Epoch 98 Iter 1200, train entropy gap 1.5592 bits (loss 21.107, data 19.548) 0.00023 lr
Epoch 98 Iter 1400, train entropy gap 2.6235 bits (loss 22.171, data 19.548) 0.00023 lr
Epoch 98 Iter 1600, train entropy gap 2.9987 bits (loss 22.546, data 19.548) 0.00023 lr
Epoch 98 Iter 1800, train entropy gap 1.5880 bits (loss 21.136, data 19.548) 0.00023 lr
Epoch 98 Iter 2000, train entropy gap 1.3681 bits (loss 20.916, data 19.548) 0.00023 lr
Epoch 98 Iter 2200, train entropy gap 1.6993 bits (loss 21.247, data 19.548) 0.00023 lr
Epoch 98 Iter 2400, train entropy gap 1.4320 bits (loss 20.980, data 19.548) 0.00023 lr
Epoch 98 Iter 2600, train entropy gap 1.6517 bits (loss 21.199, data 19.548) 0.00023 lr
Epoch 98 Iter 2800, train entropy gap 1.2186 bits (loss 20.766, data 19.548) 0.00023 lr
Epoch 98 Iter 3000, train entropy gap 1.6841 bits (loss 21.232, data 19.548) 0.00023 lr
Epoch 98 Iter 3200, train entropy gap 1.3176 bits (loss 20.865, data 19.548) 0.00023 lr
Epoch 98 Iter 3400, train entropy gap 1.3461 bits (loss 20.894, data 19.548) 0.00023 lr
Epoch 98 Iter 3600, train entropy gap 1.8008 bits (loss 21.348, data 19.548) 0.00023 lr
Epoch 98 Iter 3800, train entropy gap 2.2121 bits (loss 21.760, data 19.548) 0.00023 lr
Epoch 98 Iter 4000, train entropy gap 1.4417 bits (loss 20.989, data 19.548) 0.00023 lr
Epoch 98 Iter 4200, train entropy gap 1.5274 bits (loss 21.075, data 19.548) 0.00023 lr
Epoch 98 Iter 4400, train entropy gap 2.0564 bits (loss 21.604, data 19.548) 0.00023 lr
Epoch 98 Iter 4600, train entropy gap 1.5429 bits (loss 21.091, data 19.548) 0.00023 lr
Epoch 98 Iter 4800, train entropy gap 1.1309 bits (loss 20.679, data 19.548) 0.00023 lr
Epoch 98 Iter 5000, train entropy gap 1.9657 bits (loss 21.513, data 19.548) 0.00023 lr
Epoch 98 Iter 5200, train entropy gap 2.2904 bits (loss 21.838, data 19.548) 0.00023 lr
Epoch 98 Iter 5400, train entropy gap 1.5656 bits (loss 21.113, data 19.548) 0.00023 lr
Epoch 98 Iter 5600, train entropy gap 1.5518 bits (loss 21.099, data 19.548) 0.00023 lr
Epoch 98 Iter 5800, train entropy gap 1.6138 bits (loss 21.161, data 19.548) 0.00023 lr
Epoch 98 Iter 6000, train entropy gap 1.0306 bits (loss 20.578, data 19.548) 0.00023 lr
epoch 98 train loss 14.7297 nats / 21.2505 bits
time since start: 13933.1 secs
Epoch 99 Iter 0, train entropy gap 2.0026 bits (loss 21.550, data 19.548) 0.00023 lr
Epoch 99 Iter 200, train entropy gap 1.5176 bits (loss 21.065, data 19.548) 0.00023 lr
Epoch 99 Iter 400, train entropy gap 1.9472 bits (loss 21.495, data 19.548) 0.00023 lr
Epoch 99 Iter 600, train entropy gap 1.9933 bits (loss 21.541, data 19.548) 0.00023 lr
Epoch 99 Iter 800, train entropy gap 1.8965 bits (loss 21.444, data 19.548) 0.00023 lr
Epoch 99 Iter 1000, train entropy gap 1.3716 bits (loss 20.919, data 19.548) 0.00023 lr
Epoch 99 Iter 1200, train entropy gap 1.6000 bits (loss 21.148, data 19.548) 0.00023 lr
Epoch 99 Iter 1400, train entropy gap 1.1706 bits (loss 20.718, data 19.548) 0.00023 lr
Epoch 99 Iter 1600, train entropy gap 1.0318 bits (loss 20.579, data 19.548) 0.00023 lr
Epoch 99 Iter 1800, train entropy gap 0.9919 bits (loss 20.540, data 19.548) 0.00023 lr
Epoch 99 Iter 2000, train entropy gap 1.1922 bits (loss 20.740, data 19.548) 0.00023 lr
Epoch 99 Iter 2200, train entropy gap 1.9122 bits (loss 21.460, data 19.548) 0.00023 lr
Epoch 99 Iter 2400, train entropy gap 1.4667 bits (loss 21.014, data 19.548) 0.00023 lr
Epoch 99 Iter 2600, train entropy gap 1.2461 bits (loss 20.794, data 19.548) 0.00023 lr
Epoch 99 Iter 2800, train entropy gap 0.9702 bits (loss 20.518, data 19.548) 0.00023 lr
Epoch 99 Iter 3000, train entropy gap 1.8747 bits (loss 21.422, data 19.548) 0.00023 lr
Epoch 99 Iter 3200, train entropy gap 1.0579 bits (loss 20.606, data 19.548) 0.00023 lr
Epoch 99 Iter 3400, train entropy gap 0.4837 bits (loss 20.031, data 19.548) 0.00023 lr
Epoch 99 Iter 3600, train entropy gap 1.7682 bits (loss 21.316, data 19.548) 0.00023 lr
Epoch 99 Iter 3800, train entropy gap 1.0922 bits (loss 20.640, data 19.548) 0.00023 lr
Epoch 99 Iter 4000, train entropy gap 1.7793 bits (loss 21.327, data 19.548) 0.00023 lr
Epoch 99 Iter 4200, train entropy gap 1.7832 bits (loss 21.331, data 19.548) 0.00023 lr
Epoch 99 Iter 4400, train entropy gap 2.1671 bits (loss 21.715, data 19.548) 0.00023 lr
Epoch 99 Iter 4600, train entropy gap 1.1751 bits (loss 20.723, data 19.548) 0.00023 lr
Epoch 99 Iter 4800, train entropy gap 2.1836 bits (loss 21.731, data 19.548) 0.00023 lr
Epoch 99 Iter 5000, train entropy gap 1.4326 bits (loss 20.980, data 19.548) 0.00023 lr
Epoch 99 Iter 5200, train entropy gap 1.4983 bits (loss 21.046, data 19.548) 0.00023 lr
Epoch 99 Iter 5400, train entropy gap 1.1589 bits (loss 20.707, data 19.548) 0.00023 lr
Epoch 99 Iter 5600, train entropy gap 1.9885 bits (loss 21.536, data 19.548) 0.00023 lr
Epoch 99 Iter 5800, train entropy gap 1.1528 bits (loss 20.700, data 19.548) 0.00023 lr
Epoch 99 Iter 6000, train entropy gap 0.9409 bits (loss 20.489, data 19.548) 0.00023 lr
epoch 99 train loss 14.7271 nats / 21.2467 bits
time since start: 14073.6 secs
Training done; evaluating likelihood on full data:
Epoch None Iter 0, test loss 16.9553 nats / 24.4613 bits
Epoch None Iter 500, test loss 12.2960 nats / 17.7393 bits
Epoch None Iter 1000, test loss 12.7172 nats / 18.3470 bits
Epoch None Iter 1500, test loss 13.0493 nats / 18.8262 bits
Epoch None Iter 2000, test loss 13.4893 nats / 19.4609 bits
Epoch None Iter 2500, test loss 13.1821 nats / 19.0178 bits
Epoch None Iter 3000, test loss 14.9670 nats / 21.5928 bits
Epoch None Iter 3500, test loss 15.5050 nats / 22.3690 bits
Epoch None Iter 4000, test loss 13.4288 nats / 19.3736 bits
Epoch None Iter 4500, test loss 13.6040 nats / 19.6264 bits
Epoch None Iter 5000, test loss 14.1337 nats / 20.3907 bits
Epoch None Iter 5500, test loss 13.3486 nats / 19.2580 bits
Epoch None Iter 6000, test loss 13.4608 nats / 19.4199 bits
Epoch None Iter 6500, test loss 13.9328 nats / 20.1007 bits
Epoch None Iter 7000, test loss 15.0939 nats / 21.7759 bits
Epoch None Iter 7500, test loss 14.7951 nats / 21.3448 bits
Epoch None Iter 8000, test loss 17.5955 nats / 25.3849 bits
Epoch None Iter 8500, test loss 12.4872 nats / 18.0152 bits
Epoch None Iter 9000, test loss 13.0580 nats / 18.8388 bits
Epoch None Iter 9500, test loss 12.2906 nats / 17.7316 bits
Epoch None Iter 10000, test loss 14.0786 nats / 20.3111 bits
Epoch None Iter 10500, test loss 12.8432 nats / 18.5288 bits
Epoch None Iter 11000, test loss 13.2435 nats / 19.1064 bits
Epoch None Iter 11500, test loss 12.4426 nats / 17.9509 bits
Epoch None Iter 12000, test loss 13.5880 nats / 19.6033 bits
Saved to:
models/dmv-3.6MB-model20.206-data19.548-made-hidden512_256_512_128_1024-emb32-directIo-embedInembedOut-inputNoEmbIfLeq-colmask-100epochs-seed0.pt
